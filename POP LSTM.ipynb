{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import random \n",
    "\n",
    "# https://github.com/petrosDemetrakopoulos/RNN-Beatles-lyrics-generator\n",
    "# https://github.com/starry91/Lyric-Generator#2-lyric-generator-based-on-word-level-rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssh -i \"ling380.pem\" ec2-user@ec2-3-21-233-161.us-east-2.compute.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "Country           20115\n",
      "Electronic         7009\n",
      "Folk               5777\n",
      "Hip-Hop           23045\n",
      "Indie              2971\n",
      "Jazz              12247\n",
      "Metal             29418\n",
      "Not Available     17582\n",
      "Other              3985\n",
      "Pop               43211\n",
      "R&B                7704\n",
      "Rap               10105\n",
      "Rock             110690\n",
      "Soul               4069\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Reading in language CSV \n",
    "data = pd.read_csv(\"language-processed-data.csv\")\n",
    "data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
    "data[\"genre\"].replace({\"country\": \"Country\", \"soul\": \"Soul\", \"jazz\":\"Jazz\", \n",
    "                            \"folk\":\"Folk\", \"pop\":\"Pop\", \"metal\":\"Metal\", \"rb\":\"R&B\", \n",
    "                            \"rock\":\"Rock\", \"rap\":\"Rap\"}, inplace=True)\n",
    "print(data.groupby(['genre']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297928, 6)\n",
      "            artist genre            title  \\\n",
      "0  beyonce-knowles   Pop        ego remix   \n",
      "1  beyonce-knowles   Pop     then tell me   \n",
      "2  beyonce-knowles   Pop          honesty   \n",
      "3  beyonce-knowles   Pop  you are my rock   \n",
      "4  beyonce-knowles   Pop    black culture   \n",
      "\n",
      "                                              lyrics  word_num language  \n",
      "0  Oh baby, how you doing?\\nYou know I'm gonna cu...       NaN       en  \n",
      "1  playin' everything so easy,\\nit's like you see...       NaN       en  \n",
      "2  If you search\\nFor tenderness\\nIt isn't hard t...       NaN       en  \n",
      "3  Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...       NaN       en  \n",
      "4  Party the people, the people the party it's po...       NaN       en  \n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User inputs a song title, and how many words they want the song to be. \n",
    "- Network does, for example, 100 predictions, and in the training phrase we know what word we need to generate. \n",
    "- (genre, song title); have a marker that it's the end of the title "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Level LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopChars = [',','(',')','.','-','[',']','\"']\n",
    "# preprocessing the corpus by converting all letters to lowercase, \n",
    "# replacing blank lines with blank string and removing special characters\n",
    "def preprocessText(text):\n",
    "#     text = text.replace('\\n', ' ').replace('\\t','')\n",
    "    processedText = text.lower()\n",
    "    for char in stopChars:\n",
    "        processedText = processedText.replace(char,'')\n",
    "    return processedText\n",
    "\n",
    "# tokenization \n",
    "def corpusToList(corpus):\n",
    "    corpusList = [w for w in corpus.split(' ')] \n",
    "    corpusList = [i for i in corpusList if i] #removing empty strings from list\n",
    "    return corpusList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(genre, sample_size):\n",
    "    random.seed(69)\n",
    "    data1 = data\n",
    "    data1 = data1[data1['genre'] == genre].sample(sample_size)\n",
    "    data1['lyrics'] = data1['lyrics'].astype(str)\n",
    "    data1['lyrics']= data1['lyrics'].apply(preprocessText)\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(data):\n",
    "    newlines = re.sub(\"\\n\", \" \\n \", data['lyrics'].str.cat(sep='\\n').lower())\n",
    "    exclamation = re.sub(\"!\", \" ! \", newlines)\n",
    "    question = re.sub(\"!\", \" ! \", exclamation)\n",
    "    DP_text = re.findall(r'\\S+|\\n', question)\n",
    "    print('corpus length:', len(DP_text))\n",
    "    return(DP_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of characters, see the index of characters.\n",
    "def dictionary_maker(words):\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(words))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(words))\n",
    "    return(char_to_int, int_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentences_and_next_chars(seq_length, DP_text, step):\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "\n",
    "    # Create Target and sentences window\n",
    "    for i in range(0, len(DP_text) - seq_length, step):\n",
    "        # range from current index to sequence length charaters\n",
    "        sentences.append(DP_text[i: i + seq_length])  \n",
    "        next_chars.append(DP_text[i + seq_length]) # the next character\n",
    "    \n",
    "    sentences = np.array(sentences)\n",
    "    next_chars = np.array(next_chars)\n",
    "    return(sentences, next_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 6)\n",
      "['Pop']\n"
     ]
    }
   ],
   "source": [
    "rap_data = sample_data('Pop', 6000)\n",
    "print(rap_data.shape)\n",
    "print(rap_data.genre.unique())\n",
    "#pop_data = sample_data('pop', 2000)\n",
    "#country_data = sample_data('country', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 1923686\n"
     ]
    }
   ],
   "source": [
    "DP_rap = tokenize_data(rap_data)\n",
    "#DP_pop = tokenize_data(pop_data)\n",
    "#DP_country = tokenize_data(country_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting characters appeared in all lyrics\n",
    "rap_words = sorted(list(set(DP_rap)))\n",
    "#pop_words = sorted(list(set(DP_pop)))\n",
    "#country_words = sorted(list(set(DP_country)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rap_char_to_int, rap_int_to_char = dictionary_maker(rap_words)\n",
    "#pop_char_to_int, pop_int_to_char = dictionary_maker(pop_words)\n",
    "#country_char_to_int, country_int_to_char = dictionary_maker(country_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rap_sentences, rap_next_chars = make_sentences_and_next_chars(16, DP_rap, 1)\n",
    "#pop_sentences, pop_next_chars = make_sentences_and_next_chars(16, DP_pop, 1)\n",
    "#country_sentences, country_next_chars = make_sentences_and_next_chars(16, DP_country, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transferring the character to index \n",
    "def getdata(sentences, next_chars, seq_length, char_to_int):\n",
    "    X = np.zeros((len(sentences),seq_length))\n",
    "    y = np.zeros((len(sentences)))\n",
    "    length = len(sentences)\n",
    "    index = 0\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t] = char_to_int[char]\n",
    "        y[i] = char_to_int[next_chars[i]]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple_LSTM(nn.Module):\n",
    "    def __init__(self,n_vocab,hidden_dim, embedding_dim,dropout = 0.2):\n",
    "        super(Simple_LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,dropout = dropout,num_layers = 2)\n",
    "        self.embeddings = nn.Embedding(n_vocab, embedding_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, n_vocab)\n",
    "    \n",
    "    def forward(self, seq_in):\n",
    "        # for LSTM, input should be (Sequnce_length,batchsize,hidden_layer), so we need to transpose the input\n",
    "        embedded = self.embeddings(seq_in.t()) \n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        # Only need to keep the last character \n",
    "        ht=lstm_out[-1] \n",
    "        out = self.fc(ht)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(sentences, next_chars, epoch_count, words, seq_length, char_to_int):\n",
    "    train_x, train_y = getdata(sentences, next_chars, seq_length, char_to_int)\n",
    "    \n",
    "    X_train_tensor = torch.tensor(train_x, dtype=torch.long).to(device)\n",
    "    Y_train_tensor = torch.tensor(train_y, dtype=torch.long).to(device)\n",
    "    \n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    train = torch.utils.data.TensorDataset(X_train_tensor,Y_train_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size = 128)\n",
    "    \n",
    "    model = Simple_LSTM(len(words),256,256).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.002)\n",
    "    \n",
    "    import time # Add time counter\n",
    "    avg_losses_f = []\n",
    "    n_epochs = epoch_count\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch: \", epoch)\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        avg_loss = 0.\n",
    "        for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        \n",
    "            y_pred = model(x_batch)\n",
    "        \n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "            avg_loss+= loss.item()/len(train_loader)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time \n",
    "        print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
    "            epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
    "    \n",
    "        avg_losses_f.append(avg_loss)    \n",
    "    \n",
    "    print('All \\t loss={:.4f} \\t '.format(np.average(avg_losses_f)))\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.plot(avg_losses_f)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss value')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch 1/20 \t loss=5.2589 \t time=1064.74s\n",
      "Epoch:  1\n",
      "Epoch 2/20 \t loss=4.7539 \t time=1069.45s\n",
      "Epoch:  2\n",
      "Epoch 3/20 \t loss=4.5586 \t time=1069.72s\n",
      "Epoch:  3\n",
      "Epoch 4/20 \t loss=4.4282 \t time=1068.89s\n",
      "Epoch:  4\n",
      "Epoch 5/20 \t loss=4.3259 \t time=1068.55s\n",
      "Epoch:  5\n",
      "Epoch 6/20 \t loss=4.2435 \t time=1068.63s\n",
      "Epoch:  6\n",
      "Epoch 7/20 \t loss=4.1723 \t time=1067.96s\n",
      "Epoch:  7\n",
      "Epoch 8/20 \t loss=4.1160 \t time=1067.88s\n",
      "Epoch:  8\n",
      "Epoch 9/20 \t loss=4.0652 \t time=1067.64s\n",
      "Epoch:  9\n",
      "Epoch 10/20 \t loss=4.0240 \t time=1067.89s\n",
      "Epoch:  10\n",
      "Epoch 11/20 \t loss=3.9854 \t time=1067.13s\n",
      "Epoch:  11\n",
      "Epoch 12/20 \t loss=3.9549 \t time=1066.31s\n",
      "Epoch:  12\n",
      "Epoch 13/20 \t loss=3.9278 \t time=1066.60s\n",
      "Epoch:  13\n",
      "Epoch 14/20 \t loss=3.9033 \t time=1066.71s\n",
      "Epoch:  14\n",
      "Epoch 15/20 \t loss=3.8828 \t time=543.63s\n",
      "Epoch:  15\n",
      "Epoch 16/20 \t loss=3.8621 \t time=526.57s\n",
      "Epoch:  16\n",
      "Epoch 17/20 \t loss=3.8424 \t time=527.54s\n",
      "Epoch:  17\n",
      "Epoch 18/20 \t loss=3.8255 \t time=527.99s\n",
      "Epoch:  18\n",
      "Epoch 19/20 \t loss=3.8106 \t time=528.13s\n",
      "Epoch:  19\n",
      "Epoch 20/20 \t loss=3.7988 \t time=528.42s\n",
      "All \t loss=4.1370 \t \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop done\n"
     ]
    }
   ],
   "source": [
    "pop_model = train_model(rap_sentences, rap_next_chars, 20, rap_words, 16, rap_char_to_int)\n",
    "torch.save(pop_model.state_dict(), 'big_pop_checkpoint.pth')\n",
    "print(\"pop done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pop_model = train_model(pop_sentences, pop_next_chars, 5, pop_words, 16, pop_char_to_int)\n",
    "# print(\"pop done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country_model = train_model(country_sentences, country_next_chars, 5, country_words, 16, country_char_to_int)\n",
    "# print(\"country done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on god i love the blow \n",
      " on god i love the pussy \n",
      " but more than love so tough \n",
      " i could die in a fairytale \n",
      " i was an ordinary girl \n",
      " i saw her \n",
      " and she was her first \n",
      " i was a fool \n",
      " was the kind of torture \n",
      " she said i could be \n",
      " i was right now \n",
      " i was somebody \n",
      " i knew that i was in love with you \n",
      " i knew that i'd never been \n",
      " i can't do it \n",
      " i don't want to let you down \n",
      " i know you need me \n",
      " i need you \n",
      " i need you \n",
      " i need you \n",
      " i need you \n",
      " i want you to love me \n",
      " i need you baby \n",
      " i need you \n",
      " i need you \n",
      " my love \n",
      " i need you \n",
      " i need you \n",
      " i need you \n",
      " i need you \n",
      " i need you \n",
      " i want you back \n",
      " i want you so much \n",
      " i need you at the end of love \n",
      " i need you \n",
      " fortunately i got to be \n",
      " chorus \n",
      " i want you back \n",
      " i'll be your blueberry lollipop \n",
      " i want to be with you \n",
      " i dedicate in my ear \n",
      " i dedicate to you \n",
      " i dedicate it \n",
      " i miss you \n",
      " i miss you \n",
      " i miss you \n",
      " i miss your love \n",
      " i miss you \n",
      " i miss you miss you \n",
      " i miss you \n",
      " i dedicate you \n",
      " i dedicate i miss you \n",
      " i miss you \n",
      " i miss you \n",
      " i dedicate you i love you \n",
      " i miss you \n",
      " i miss you \n",
      " i miss you \n",
      " i dedicate i miss you \n",
      " i miss you \n",
      " i dedicate you all over me \n",
      " i miss you \n",
      " i miss you \n",
      " i miss you miss you \n",
      " i miss you \n",
      " i miss you \n",
      " i miss you \n",
      " i miss you \n",
      " i miss you \n",
      " i miss you miss you \n",
      " i miss you \n",
      " i miss you miss you \n",
      " i miss you \n",
      " i miss you \n",
      " i dedicate you \n",
      " i miss you \n",
      " i miss you \n",
      " i miss you \n",
      " i miss you \n",
      " i miss you \n",
      " i miss you \n",
      " i miss you \n",
      " i miss you \n",
      " i miss you miss you \n",
      " chorus\n"
     ]
    }
   ],
   "source": [
    "# Define the start sentence\n",
    "# sentence = 'i read in the news\\nthat the average man\\nplease kis'\n",
    "seq_length = 16\n",
    "char_to_int = rap_char_to_int\n",
    "int_to_char = rap_int_to_char\n",
    "sentence = [\"on\", \"god\", \"i\", \"love\", \"the\", \"blow\", \"\\n\", \"on\", \"god\", \"i\",\n",
    "           \"love\", \"the\", \"pussy\", \"\\n\", \"but\", \"more\"]\n",
    "variance = .5\n",
    "generated = []\n",
    "original = sentence\n",
    "window = sentence\n",
    "\n",
    "for i in range(400):\n",
    "    x = np.zeros((1, seq_length))\n",
    "    for t, char in enumerate(window):\n",
    "        x[0, t] = char_to_int[char] # Change the sentence to index vector shape (1,50)\n",
    "        \n",
    "    x_in = Variable(torch.LongTensor(x).to(device))\n",
    "    pred = pop_model(x_in)\n",
    "    pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
    "    next_index = sample(pred, variance)\n",
    "    next_char = int_to_char[next_index] # index to char\n",
    "\n",
    "    generated = generated + [next_char]\n",
    "    window = window[1:] + [next_char] # Update Window for next char predict\n",
    "    \n",
    "print(\" \".join(original + generated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sentence:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sentence:  1\n",
      "In sentence:  2\n",
      "In sentence:  3\n",
      "In sentence:  4\n",
      "In sentence:  5\n",
      "In sentence:  6\n",
      "In sentence:  7\n",
      "In sentence:  8\n",
      "In sentence:  9\n",
      "In sentence:  10\n",
      "In sentence:  11\n",
      "In sentence:  12\n",
      "In sentence:  13\n",
      "In sentence:  14\n",
      "In sentence:  15\n",
      "In sentence:  16\n",
      "In sentence:  17\n",
      "In sentence:  18\n",
      "In sentence:  19\n",
      "                                             starter  \\\n",
      "0  [i, like, long, walks, on, the, beach, \\n, and...   \n",
      "1  [it, was, a, dark, day, when, he, died, \\n, my...   \n",
      "2  [yeah, \\n, yeah, \\n, yeah, \\n, this, is, the, ...   \n",
      "3  [drive, forever, \\n, baby, i, need, your, appl...   \n",
      "4  [the, way, that, you, love, me, \\n, is, hard, ...   \n",
      "\n",
      "                                              output  \n",
      "0  [i, i, would, die, \\n, i, can, hear, it, loud,...  \n",
      "1  [\\n, i, was, the, one, for, you, \\n, i, was, a...  \n",
      "2  [i, saw, your, face, \\n, i, knew, it, was, so,...  \n",
      "3  [day, \\n, i, had, a, heart, \\n, never, had, en...  \n",
      "4  [wilderness, \\n, i, thought, that, i, could, b...  \n"
     ]
    }
   ],
   "source": [
    "starters = [[\"i\", \"like\", \"long\", \"walks\", \"on\", \"the\", \"beach\", \"\\n\", \"and\", \"shopping\", \"sprees\", \"in\", \"paris\", \"\\n\", \"i\", \"sometimes\"],\n",
    "[\"it\", \"was\", \"a\", \"dark\", \"day\", \"when\", \"he\", \"died\", \"\\n\", \"my\", \"mom\",  \"had\", \"tears\", \"in\", \"her\", \"eyes\"],\n",
    "[\"yeah\", \"\\n\", \"yeah\", \"\\n\", \"yeah\", \"\\n\", \"this\", \"is\", \"the\", \"way\", \"i\", \"talk\", \"when\", \"i’m\", \"mad\", \"\\n\"],\n",
    "[\"drive\", \"forever\", \"\\n\", \"baby\", \"i\", \"need\", \"your\", \"apples\", \"\\n\", \"free\", \"car\", \"\\n\", \"just\", \"another\", \"a\", \"wild\"],\n",
    "[\"the\", \"way\", \"that\", \"you\", \"love\", \"me\", \"\\n\", \"is\", \"hard\", \"to\", \"explain\", \"\\n\", \"i’m\", \"addicted\", \"to\", \"your\"],\n",
    "[\"love\", \"women\", \"\\n\", \"get\", \"money\", \"\\n\", \"love\", \"women\", \"\\n\", \"get\", \"money\", \"\\n\", \"makes\", \"a\", \"lot\", \"of\"],\n",
    "[\"baby\", \"you\", \"are\", \"crazy\", \"\\n\", \"you\", \"make\", \"no\", \"sense\", \"\\n\", \"talking\", \"to\", \"you\", \"\\n\", \"is\", \"like\"],\n",
    "[\"it’s\", \"been\", \"a\", \"while\", \"since\", \"you\", \"spoke\", \"to\", \"me\", \"\\n\", \"turned\", \"your\", \"head\", \"\\n\", \"cracked\", \"a\"],\n",
    "[\"rumors\", \"spreadin\", \"round\", \"\\n\", \"that\", \"you've\", \"been\", \"seen\", \"with\", \"him\", \"\\n\", \"guess\", \"i\", \"wasn’t\", \"enough\", \"for\"],\n",
    "[\"i\", \"been\", \"all\", \"over\", \"this\", \"god\", \"damn\", \"town\", \"\\n\", \"under\", \"the\", \"bridges\", \"and\", \"up\", \"in\", \"the\"],\n",
    "[\"oh\", \"oh\", \"oh\", \"\\n\", \"yeah\", \"yeah\", \"yeah\", \"\\n\", \"that’s\", \"what\", \"i’m\", \"talkin\", \"about\", \"\\n\", \"look\", \"at\"],\n",
    "[\"well\", \"i\", \"was\", \"walkin\", \"round\", \"town\", \"with\", \"this\", \"girl\", \"i\", \"knew\", \"\\n\", \"when\", \"a\", \"man\", \"came\"],\n",
    "[\"fire\", \"and\", \"flames\", \"\\n\", \"passing\", \"tongues\", \"once\", \"bright\", \"with\", \"life\", \"\\n\", \"this\", \"is\", \"the\", \"world\", \"as\"],\n",
    "[\"on\", \"god\", \"i\", \"love\", \"the\", \"women\", \"\\n\", \"on\", \"god\", \"i\", \"love\", \"the\", \"blow\", \"\\n\", \"on\", \"god\"],\n",
    "[\"i\", \"can\", \"take\", \"you\", \"to\", \"the\", \"west\", \"coast\", \"best\", \"coast\", \"with\", \"a\", \"slice\", \"of\", \"toast\", \"yeah\"],\n",
    "[\"the\", \"stars\", \"were\", \"golden\", \"\\n\", \"the\", \"sky\", \"was\", \"dark\", \"\\n\", \"it\", \"was\", \"just\", \"you\", \"and\", \"me\"],\n",
    "[\"please\", \"baby\", \"please\", \"\\n\", \"please\", \"baby\", \"please\", \"\\n\", \"the\", \"things\", \"you\", \"do\", \"to\", \"me\", \"\\n\", \"you\"],\n",
    "[\"sweet\", \"adam\", \"\\n\", \"your\", \"tender\", \"touch\", \"\\n\", \"all\", \"i\", \"need\", \"when\", \"the\", \"weather\", \"gets\", \"cold\", \"\\n\"],\n",
    "[\"hello\", \"there\", \"\\n\", \"the\", \"pizza\", \"from\", \"my\", \"nightmare\", \"\\n\", \"the\", \"figure\", \"in\", \"front\", \"of\", \"me\", \"\\n\"],\n",
    "[\"i\", \"like\", \"to\", \"spit\", \"\\n\", \"in\", \"the\", \"morning\", \"when\", \"i’m\", \"done\", \"taking\", \"my\", \"shit\", \"\\n\", \"i\"]]\n",
    "\n",
    "seq_length = 16\n",
    "char_to_int = rap_char_to_int\n",
    "int_to_char = rap_int_to_char\n",
    "\n",
    "def generate_sentence(input_sentences): \n",
    "    starter = [] \n",
    "    generation = [] \n",
    "    \n",
    "    for i in range(len(input_sentences)): \n",
    "        print(\"In sentence: \", i)\n",
    "        variance = .5\n",
    "        generated = []\n",
    "        original = input_sentences[i]\n",
    "        window = input_sentences[i]\n",
    "\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, seq_length))\n",
    "            for t, char in enumerate(window):\n",
    "                x[0, t] = char_to_int[char] # Change the sentence to index vector shape (1,50)\n",
    "\n",
    "            x_in = Variable(torch.LongTensor(x).to(device))\n",
    "            pred = pop_model(x_in)\n",
    "            pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
    "            next_index = sample(pred, variance)\n",
    "            next_char = int_to_char[next_index] # index to char\n",
    "\n",
    "            generated = generated + [next_char]\n",
    "            window = window[1:] + [next_char] # Update Window for next char predict\n",
    "        \n",
    "        starter.append(original) \n",
    "        generation.append(generated)\n",
    "\n",
    "    lyrics = pd.DataFrame({'starter': starter, 'output': generation})\n",
    "    print(lyrics.head())\n",
    "    return lyrics \n",
    "output = generate_sentence(starters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METRIC 1: AVERAGE LINE LENGTH \n",
    "import math\n",
    "def mean(numbers):\n",
    "    return float(sum(numbers)) / max(len(numbers), 1)\n",
    "def single_length_length(output): \n",
    "    newline_count = output.count('\\n')\n",
    "    return round((len(output) - newline_count) / (newline_count + 1), 2)\n",
    "def average_line_length(df): \n",
    "    # (length of the list - # of new lines) / (# new lines + 1 )\n",
    "    result = df['output'].apply(single_length_length).tolist()\n",
    "    return mean(result)\n",
    "\n",
    "# METRIC 2: Word variation: # of Unique words divided by total # of words \n",
    "def variation(output): \n",
    "    line = [value for value in output if value != \"\\n\"]\n",
    "    unique_num = len(list(set(line)))\n",
    "    return unique_num/len(line)\n",
    "def word_variation(df): \n",
    "    result = df['output'].apply(variation).tolist()\n",
    "    return mean(result)\n",
    "\n",
    "# METRIC 3: Genre Word Variation \n",
    "def genre_word_variation(df): \n",
    "    output_list = df['output'].tolist()\n",
    "    return variation(output_list[0])\n",
    "\n",
    "# METRIC 4: % of I vs. You \n",
    "def count_iyou(row): \n",
    "    i_count, you_count = 0,0 \n",
    "    x = 0\n",
    "    while x < len(row):\n",
    "        if x == 0 and row[x] == \"you\": \n",
    "            you_count += 1\n",
    "        if x == 0 and row[x] == \"i\":\n",
    "            i_count += 1 \n",
    "        if x < len(row) - 1: \n",
    "            if row[x] == \"\\n\" and row[x + 1] == \"i\": \n",
    "                i_count += 1 \n",
    "            if row[x] == \"\\n\" and row[x + 1] == \"you\": \n",
    "                you_count += 1\n",
    "        x += 1 \n",
    "\n",
    "    return (i_count - you_count)\n",
    "\n",
    "def i_you(df): \n",
    "    result = df['output'].apply(count_iyou).to_list()\n",
    "    return mean(result)\n",
    "# the more positive, the more i's there are. \n",
    "\n",
    "# METRIC 5: Word reptition \n",
    "# if the word is the same as the one that came before it \n",
    "def count_s(row): \n",
    "    count, x = 0, 0\n",
    "    while x < len(row): \n",
    "        if x < len(row) - 1: \n",
    "            if row[x] == row[x+1]: \n",
    "                count += 1 \n",
    "        x += 1 \n",
    "    return count \n",
    "def count_succession(df): \n",
    "    result = df['output'].apply(count_s).to_list()\n",
    "#     print(result)\n",
    "    return mean(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.923\n",
      "0.24064433580466588\n",
      "0.29971181556195964\n",
      "42.35\n",
      "58.6\n"
     ]
    }
   ],
   "source": [
    "# METRIC 1: AVERAGE LINE LENGTH \n",
    "print(average_line_length(output))\n",
    "# METRIC 2: Word variation: # of Unique words divided by total # of words \n",
    "print(word_variation(output))\n",
    "# METRIC 3: Genre Word Variation \n",
    "print(genre_word_variation(output))\n",
    "# METRIC 4: % of I vs. You \n",
    "print(i_you(output))\n",
    "# METRIC 5: Word repetition \n",
    "print(count_succession(output)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5775000000000095\n",
      "0.4066603522369395\n",
      "0.9428571428571428\n",
      "2.2885\n",
      "5.2155\n"
     ]
    }
   ],
   "source": [
    "def sample_data(genre, sample_size):\n",
    "    random.seed(69)\n",
    "    data1 = data\n",
    "    data1 = data1[data1['genre'] == genre].sample(sample_size)\n",
    "    data1['lyrics'] = data1['lyrics'].astype(str)\n",
    "    data1['lyrics']= data1['lyrics'].apply(preprocessText)\n",
    "    return data1\n",
    "\n",
    "def tokenize_data(data):\n",
    "    newlines = re.sub(\"\\n\", \" \\n \", data.lower())\n",
    "    exclamation = re.sub(\"!\", \" ! \", newlines)\n",
    "    question = re.sub(\"!\", \" ! \", exclamation)\n",
    "    DP_text = re.findall(r'\\S+|\\n', question)\n",
    "    return(DP_text)\n",
    "\n",
    "r_data = sample_data('Pop', 2000)\n",
    "r_data['output'] = r_data['lyrics'].apply(tokenize_data)\n",
    "\n",
    "# METRIC 1: AVERAGE LINE LENGTH \n",
    "print(average_line_length(r_data))\n",
    "# METRIC 2: Word variation: # of Unique words divided by total # of words \n",
    "print(word_variation(r_data))\n",
    "# METRIC 3: Genre Word Variation \n",
    "print(genre_word_variation(r_data))\n",
    "# METRIC 4: % of I vs. You \n",
    "print(i_you(r_data))\n",
    "# METRIC 5: Word repetition \n",
    "print(count_succession(r_data)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
