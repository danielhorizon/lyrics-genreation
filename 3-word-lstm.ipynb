{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "# https://github.com/petrosDemetrakopoulos/RNN-Beatles-lyrics-generator\n",
    "# https://github.com/starry91/Lyric-Generator#2-lyric-generator-based-on-word-level-rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>t-lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>ego remix</td>\n",
       "      <td>oh baby how you doing?\\nyou know i'm gonna cut...</td>\n",
       "      <td>['ego', 'remix', '@@@', 'oh', 'baby', 'how', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>then tell me</td>\n",
       "      <td>playin' everything so easy\\nit's like you seem...</td>\n",
       "      <td>['then', 'tell', 'me', '@@@', \"playin'\", 'ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>honesty</td>\n",
       "      <td>if you search\\nfor tenderness\\nit isn't hard t...</td>\n",
       "      <td>['honesty', '@@@', 'if', 'you', 'search\\nfor',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>you are my rock</td>\n",
       "      <td>oh oh oh i oh oh oh i\\nverse 1:\\nif i wrote a ...</td>\n",
       "      <td>['you', 'are', 'my', 'rock', '@@@', 'oh', 'oh'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>black culture</td>\n",
       "      <td>party the people the people the party it's pop...</td>\n",
       "      <td>['black', 'culture', '@@@', 'party', 'the', 'p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist genre            title  \\\n",
       "0  beyonce-knowles   Pop        ego remix   \n",
       "1  beyonce-knowles   Pop     then tell me   \n",
       "2  beyonce-knowles   Pop          honesty   \n",
       "3  beyonce-knowles   Pop  you are my rock   \n",
       "4  beyonce-knowles   Pop    black culture   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  oh baby how you doing?\\nyou know i'm gonna cut...   \n",
       "1  playin' everything so easy\\nit's like you seem...   \n",
       "2  if you search\\nfor tenderness\\nit isn't hard t...   \n",
       "3  oh oh oh i oh oh oh i\\nverse 1:\\nif i wrote a ...   \n",
       "4  party the people the people the party it's pop...   \n",
       "\n",
       "                                             t-lyric  \n",
       "0  ['ego', 'remix', '@@@', 'oh', 'baby', 'how', '...  \n",
       "1  ['then', 'tell', 'me', '@@@', \"playin'\", 'ever...  \n",
       "2  ['honesty', '@@@', 'if', 'you', 'search\\nfor',...  \n",
       "3  ['you', 'are', 'my', 'rock', '@@@', 'oh', 'oh'...  \n",
       "4  ['black', 'culture', '@@@', 'party', 'the', 'p...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"master-process-data.csv\")\n",
    "del data['Unnamed: 0']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>t-lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>ego remix</td>\n",
       "      <td>oh baby how you doing?\\nyou know i'm gonna cut...</td>\n",
       "      <td>ego remix @@@ oh baby how you doing?\\nyou know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>then tell me</td>\n",
       "      <td>playin' everything so easy\\nit's like you seem...</td>\n",
       "      <td>then tell me @@@ playin' everything so easy\\ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>honesty</td>\n",
       "      <td>if you search\\nfor tenderness\\nit isn't hard t...</td>\n",
       "      <td>honesty @@@ if you search\\nfor tenderness\\nit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>you are my rock</td>\n",
       "      <td>oh oh oh i oh oh oh i\\nverse 1:\\nif i wrote a ...</td>\n",
       "      <td>you are my rock @@@ oh oh oh i oh oh oh i\\nver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>black culture</td>\n",
       "      <td>party the people the people the party it's pop...</td>\n",
       "      <td>black culture @@@ party the people the people ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist genre            title  \\\n",
       "0  beyonce-knowles   Pop        ego remix   \n",
       "1  beyonce-knowles   Pop     then tell me   \n",
       "2  beyonce-knowles   Pop          honesty   \n",
       "3  beyonce-knowles   Pop  you are my rock   \n",
       "4  beyonce-knowles   Pop    black culture   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  oh baby how you doing?\\nyou know i'm gonna cut...   \n",
       "1  playin' everything so easy\\nit's like you seem...   \n",
       "2  if you search\\nfor tenderness\\nit isn't hard t...   \n",
       "3  oh oh oh i oh oh oh i\\nverse 1:\\nif i wrote a ...   \n",
       "4  party the people the people the party it's pop...   \n",
       "\n",
       "                                             t-lyric  \n",
       "0  ego remix @@@ oh baby how you doing?\\nyou know...  \n",
       "1  then tell me @@@ playin' everything so easy\\ni...  \n",
       "2  honesty @@@ if you search\\nfor tenderness\\nit ...  \n",
       "3  you are my rock @@@ oh oh oh i oh oh oh i\\nver...  \n",
       "4  black culture @@@ party the people the people ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['t-lyric'] = data['title'] + \" @@@ \" + data['lyrics']\n",
    "data['t-lyric'] = data['t-lyric'].str.lower()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopChars = [',','(',')','.','-','[',']','\"']\n",
    "# preprocessing the corpus by converting all letters to lowercase, \n",
    "# replacing blank lines with blank string and removing special characters\n",
    "def preprocessText(text):\n",
    "#     text = text.replace('\\n', ' ').replace('\\t','')\n",
    "    processedText = text.lower()\n",
    "    for char in stopChars:\n",
    "        processedText = processedText.replace(char,'')\n",
    "    return processedText\n",
    "data['t-lyric'] = data['t-lyric'].astype(str)\n",
    "data['t-lyric'] = data['t-lyric'].apply(preprocessText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization \n",
    "def corpusToList(corpus):\n",
    "    corpusList = [w for w in corpus.split(' ')] \n",
    "    corpusList = [i for i in corpusList if i] #removing empty strings from list\n",
    "    return corpusList\n",
    "data['t-lyric'] = data['t-lyric'].apply(corpusToList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>t-lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>ego remix</td>\n",
       "      <td>oh baby how you doing?\\nyou know i'm gonna cut...</td>\n",
       "      <td>[ego, remix, @@@, oh, baby, how, you, doing?\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>then tell me</td>\n",
       "      <td>playin' everything so easy\\nit's like you seem...</td>\n",
       "      <td>[then, tell, me, @@@, playin', everything, so,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>honesty</td>\n",
       "      <td>if you search\\nfor tenderness\\nit isn't hard t...</td>\n",
       "      <td>[honesty, @@@, if, you, search\\nfor, tendernes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>you are my rock</td>\n",
       "      <td>oh oh oh i oh oh oh i\\nverse 1:\\nif i wrote a ...</td>\n",
       "      <td>[you, are, my, rock, @@@, oh, oh, oh, i, oh, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>black culture</td>\n",
       "      <td>party the people the people the party it's pop...</td>\n",
       "      <td>[black, culture, @@@, party, the, people, the,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist genre            title  \\\n",
       "0  beyonce-knowles   Pop        ego remix   \n",
       "1  beyonce-knowles   Pop     then tell me   \n",
       "2  beyonce-knowles   Pop          honesty   \n",
       "3  beyonce-knowles   Pop  you are my rock   \n",
       "4  beyonce-knowles   Pop    black culture   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  oh baby how you doing?\\nyou know i'm gonna cut...   \n",
       "1  playin' everything so easy\\nit's like you seem...   \n",
       "2  if you search\\nfor tenderness\\nit isn't hard t...   \n",
       "3  oh oh oh i oh oh oh i\\nverse 1:\\nif i wrote a ...   \n",
       "4  party the people the people the party it's pop...   \n",
       "\n",
       "                                             t-lyric  \n",
       "0  [ego, remix, @@@, oh, baby, how, you, doing?\\n...  \n",
       "1  [then, tell, me, @@@, playin', everything, so,...  \n",
       "2  [honesty, @@@, if, you, search\\nfor, tendernes...  \n",
       "3  [you, are, my, rock, @@@, oh, oh, oh, i, oh, o...  \n",
       "4  [black, culture, @@@, party, the, people, the,...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x216e95e50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trim each word for leading or trailing spaces / tabs.\n",
    "map(str.strip, data['t-lyric']) # trim words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>t-lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>ego remix</td>\n",
       "      <td>oh baby how you doing?\\nyou know i'm gonna cut...</td>\n",
       "      <td>[ego, remix, @@@, oh, baby, how, you, doing?\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>then tell me</td>\n",
       "      <td>playin' everything so easy\\nit's like you seem...</td>\n",
       "      <td>[then, tell, me, @@@, playin', everything, so,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>honesty</td>\n",
       "      <td>if you search\\nfor tenderness\\nit isn't hard t...</td>\n",
       "      <td>[honesty, @@@, if, you, search\\nfor, tendernes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>you are my rock</td>\n",
       "      <td>oh oh oh i oh oh oh i\\nverse 1:\\nif i wrote a ...</td>\n",
       "      <td>[you, are, my, rock, @@@, oh, oh, oh, i, oh, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>black culture</td>\n",
       "      <td>party the people the people the party it's pop...</td>\n",
       "      <td>[black, culture, @@@, party, the, people, the,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist genre            title  \\\n",
       "0  beyonce-knowles   Pop        ego remix   \n",
       "1  beyonce-knowles   Pop     then tell me   \n",
       "2  beyonce-knowles   Pop          honesty   \n",
       "3  beyonce-knowles   Pop  you are my rock   \n",
       "4  beyonce-knowles   Pop    black culture   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  oh baby how you doing?\\nyou know i'm gonna cut...   \n",
       "1  playin' everything so easy\\nit's like you seem...   \n",
       "2  if you search\\nfor tenderness\\nit isn't hard t...   \n",
       "3  oh oh oh i oh oh oh i\\nverse 1:\\nif i wrote a ...   \n",
       "4  party the people the people the party it's pop...   \n",
       "\n",
       "                                             t-lyric  \n",
       "0  [ego, remix, @@@, oh, baby, how, you, doing?\\n...  \n",
       "1  [then, tell, me, @@@, playin', everything, so,...  \n",
       "2  [honesty, @@@, if, you, search\\nfor, tendernes...  \n",
       "3  [you, are, my, rock, @@@, oh, oh, oh, i, oh, o...  \n",
       "4  [black, culture, @@@, party, the, people, the,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab length: 67263415\n",
      "Unique words in corpus: 3274867\n"
     ]
    }
   ],
   "source": [
    "corpus_words = [x for sublist in data['t-lyric'] for x in sublist]\n",
    "vocab = sorted(set(corpus_words))\n",
    "print('vocab length:', len(corpus_words))\n",
    "print('Unique words in corpus: {}'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating numeric map; representing words with numberes \n",
    "# map specific number to each specific word of our corpus, and vice versa \n",
    "word2idx = {u: i for i, u in enumerate(vocab)}\n",
    "idx2words = np.array(vocab)\n",
    "word_as_int = np.array([word2idx[c] for c in corpus_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User inputs a song title, and how many words they want the song to be. \n",
    "- Network does, for example, 100 predictions, and in the training phrase we know what word we need to generate. \n",
    "- (genre, song title); have a marker that it's the end of the title "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Level LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0           artist genre            title  \\\n",
      "0           0  beyonce-knowles   Pop        ego remix   \n",
      "1           1  beyonce-knowles   Pop     then tell me   \n",
      "2           2  beyonce-knowles   Pop          honesty   \n",
      "3           3  beyonce-knowles   Pop  you are my rock   \n",
      "4           4  beyonce-knowles   Pop    black culture   \n",
      "\n",
      "                                              lyrics  \\\n",
      "0  oh baby how you doing?\\nyou know i'm gonna cut...   \n",
      "1  playin' everything so easy\\nit's like you seem...   \n",
      "2  if you search\\nfor tenderness\\nit isn't hard t...   \n",
      "3  oh oh oh i oh oh oh i\\nverse 1:\\nif i wrote a ...   \n",
      "4  party the people the people the party it's pop...   \n",
      "\n",
      "                                             t-lyric  \n",
      "0  ['ego', 'remix', '@@@', 'oh', 'baby', 'how', '...  \n",
      "1  ['then', 'tell', 'me', '@@@', \"playin'\", 'ever...  \n",
      "2  ['honesty', '@@@', 'if', 'you', 'search\\nfor',...  \n",
      "3  ['you', 'are', 'my', 'rock', '@@@', 'oh', 'oh'...  \n",
      "4  ['black', 'culture', '@@@', 'party', 'the', 'p...  \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "#nltk.download('punkt')\n",
    "data1 = pd.read_csv(\"master-process-data.csv\")\n",
    "data1['lyrics']= data1['lyrics'].astype(str)\n",
    "data1['lyrics']= data1['lyrics'].apply(preprocessText)\n",
    "print(data1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/taesoodaniellee/nltk_data'\n    - '/Users/taesoodaniellee/opt/anaconda3/nltk_data'\n    - '/Users/taesoodaniellee/opt/anaconda3/share/nltk_data'\n    - '/Users/taesoodaniellee/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4f4187057d4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDP_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lyrics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corpus length:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDP_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#todo(dlee, tokenize words)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \"\"\"\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     return [\n\u001b[1;32m    146\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/taesoodaniellee/nltk_data'\n    - '/Users/taesoodaniellee/opt/anaconda3/nltk_data'\n    - '/Users/taesoodaniellee/opt/anaconda3/share/nltk_data'\n    - '/Users/taesoodaniellee/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "DP_text = word_tokenize(data1['lyrics'].str.cat(sep='\\n').lower())\n",
    "print('corpus length:', len(DP_text))\n",
    "#todo(dlee, tokenize words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting characters appeared in all lyrics\n",
    "words = sorted(list(set(DP_text)))\n",
    "print('total words:', len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of characters, see the index of characters.\n",
    "char_to_int = dict((c, i) for i, c in enumerate(words))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 10 # The sentence window size\n",
    "step = 1 # The steps between the windows\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "# Create Target and sentences window\n",
    "for i in range(0, len(DP_text) - seq_length, step):\n",
    "    # range from current index to sequence length charaters\n",
    "    sentences.append(DP_text[i: i + seq_length])  \n",
    "    next_chars.append(DP_text[i + seq_length]) # the next character\n",
    "    \n",
    "sentences = np.array(sentences)\n",
    "next_chars = np.array(next_chars)\n",
    "\n",
    "#Print Sentence Window and next charaters\n",
    "print('Sentence Window')\n",
    "print (sentences[:5])\n",
    "print('Target characters')\n",
    "print (next_chars[:5])\n",
    "print('Number of sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transferring the character to index \n",
    "def getdata(sentences, next_chars):\n",
    "    X = np.zeros((len(sentences),seq_length))\n",
    "    y = np.zeros((len(sentences)))\n",
    "    length = len(sentences)\n",
    "    index = 0\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t] = char_to_int[char]\n",
    "        y[i] = char_to_int[next_chars[i]]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y = getdata(sentences, next_chars)\n",
    "print(train_x)\n",
    "print('Shape of training_x:', train_x.shape)\n",
    "print('Shape of training_y:', train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Simple_LSTM(nn.Module):\n",
    "    def __init__(self,n_vocab,hidden_dim, embedding_dim,dropout = 0.2):\n",
    "        super(Simple_LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,dropout = dropout,num_layers = 2)\n",
    "        self.embeddings = nn.Embedding(n_vocab, embedding_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, n_vocab)\n",
    "    \n",
    "    def forward(self, seq_in):\n",
    "        # for LSTM, input should be (Sequnce_length,batchsize,hidden_layer), so we need to transpose the input\n",
    "        embedded = self.embeddings(seq_in.t()) \n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        # Only need to keep the last character \n",
    "        ht=lstm_out[-1] \n",
    "        out = self.fc(ht)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(train_x, dtype=torch.long)\n",
    "Y_train_tensor = torch.tensor(train_y, dtype=torch.long)\n",
    "print('Shape of training_x:', X_train_tensor.shape)\n",
    "print('Shape of training_y:', Y_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "train = torch.utils.data.TensorDataset(X_train_tensor,Y_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Simple_LSTM(len(words),256,256)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.002) # Using Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time # Add time counter\n",
    "avg_losses_f = []\n",
    "n_epochs=30\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    avg_loss = 0.\n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        y_pred = model(x_batch)\n",
    "        \n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        avg_loss+= loss.item()/len(train_loader)\n",
    "        \n",
    "    elapsed_time = time.time() - start_time \n",
    "    print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
    "        epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
    "    \n",
    "    avg_losses_f.append(avg_loss)    \n",
    "    \n",
    "print('All \\t loss={:.4f} \\t '.format(np.average(avg_losses_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(avg_losses_f)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start sentence\n",
    "# sentence = 'i read in the news\\nthat the average man\\nplease kis'\n",
    "sentence = [\"she\", \"got\", \"forever\", \"addicted\", \"to\", \"a\", \"body\", \"killer\", \"spillin\", \"ice\"]\n",
    "variance = 1\n",
    "generated = []\n",
    "original = sentence\n",
    "window = sentence\n",
    "\n",
    "for i in range(400):\n",
    "    x = np.zeros((1, seq_length))\n",
    "    for t, char in enumerate(window):\n",
    "        x[0, t] = char_to_int[char] # Change the sentence to index vector shape (1,50)\n",
    "        \n",
    "    x_in = Variable(torch.LongTensor(x))\n",
    "    pred = model(x_in)\n",
    "    pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
    "    next_index = sample(pred, variance)\n",
    "    next_char = int_to_char[next_index] # index to char\n",
    "\n",
    "    generated = generated + [next_char]\n",
    "    window = window[1:] + [next_char] # Update Window for next char predict\n",
    "    \n",
    "print(\" \".join(original + generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
