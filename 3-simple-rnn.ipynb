{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "# https://github.com/petrosDemetrakopoulos/RNN-Beatles-lyrics-generator\n",
    "# https://github.com/starry91/Lyric-Generator#2-lyric-generator-based-on-word-level-rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Migos</td>\n",
       "      <td>rap</td>\n",
       "      <td>Stir Fry</td>\n",
       "      <td>Woo, woo, woo, woo\\nWoo, woo, woo, woo\\n\\nDanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Snoop Dogg</td>\n",
       "      <td>rap</td>\n",
       "      <td>Drop It Like It‚Äôs Hot</td>\n",
       "      <td>Snoop\\nSnoop\\n\\nWhen the pimp's in the crib, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Drake</td>\n",
       "      <td>rap</td>\n",
       "      <td>Headlines</td>\n",
       "      <td>I might be too strung out on compliments\\nOver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Lil Uzi Vert</td>\n",
       "      <td>rap</td>\n",
       "      <td>XO TOUR Llif3</td>\n",
       "      <td>Are you alright?\\nI'm alright, I'm quite alrig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Lil Uzi Vert</td>\n",
       "      <td>rap</td>\n",
       "      <td>The Way Life Goes</td>\n",
       "      <td>That's true (That's true), that's right (That ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist genre                    title  \\\n",
       "0         Migos   rap                 Stir Fry   \n",
       "1    Snoop Dogg   rap  Drop It Like It‚Äôs Hot   \n",
       "2         Drake   rap                Headlines   \n",
       "3  Lil Uzi Vert   rap            XO TOUR Llif3   \n",
       "4  Lil Uzi Vert   rap        The Way Life Goes   \n",
       "\n",
       "                                              lyrics  \n",
       "0  Woo, woo, woo, woo\\nWoo, woo, woo, woo\\n\\nDanc...  \n",
       "1  Snoop\\nSnoop\\n\\nWhen the pimp's in the crib, m...  \n",
       "2  I might be too strung out on compliments\\nOver...  \n",
       "3  Are you alright?\\nI'm alright, I'm quite alrig...  \n",
       "4  That's true (That's true), that's right (That ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"sample-dataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>t-lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Migos</td>\n",
       "      <td>rap</td>\n",
       "      <td>Stir Fry</td>\n",
       "      <td>Woo, woo, woo, woo\\nWoo, woo, woo, woo\\n\\nDanc...</td>\n",
       "      <td>stir fry @@@ woo, woo, woo, woo\\nwoo, woo, woo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Snoop Dogg</td>\n",
       "      <td>rap</td>\n",
       "      <td>Drop It Like It‚Äôs Hot</td>\n",
       "      <td>Snoop\\nSnoop\\n\\nWhen the pimp's in the crib, m...</td>\n",
       "      <td>drop it like it‚äôs hot @@@ snoop\\nsnoop\\n\\nwh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Drake</td>\n",
       "      <td>rap</td>\n",
       "      <td>Headlines</td>\n",
       "      <td>I might be too strung out on compliments\\nOver...</td>\n",
       "      <td>headlines @@@ i might be too strung out on com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Lil Uzi Vert</td>\n",
       "      <td>rap</td>\n",
       "      <td>XO TOUR Llif3</td>\n",
       "      <td>Are you alright?\\nI'm alright, I'm quite alrig...</td>\n",
       "      <td>xo tour llif3 @@@ are you alright?\\ni'm alrigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Lil Uzi Vert</td>\n",
       "      <td>rap</td>\n",
       "      <td>The Way Life Goes</td>\n",
       "      <td>That's true (That's true), that's right (That ...</td>\n",
       "      <td>the way life goes @@@ that's true (that's true...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist genre                    title  \\\n",
       "0         Migos   rap                 Stir Fry   \n",
       "1    Snoop Dogg   rap  Drop It Like It‚Äôs Hot   \n",
       "2         Drake   rap                Headlines   \n",
       "3  Lil Uzi Vert   rap            XO TOUR Llif3   \n",
       "4  Lil Uzi Vert   rap        The Way Life Goes   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  Woo, woo, woo, woo\\nWoo, woo, woo, woo\\n\\nDanc...   \n",
       "1  Snoop\\nSnoop\\n\\nWhen the pimp's in the crib, m...   \n",
       "2  I might be too strung out on compliments\\nOver...   \n",
       "3  Are you alright?\\nI'm alright, I'm quite alrig...   \n",
       "4  That's true (That's true), that's right (That ...   \n",
       "\n",
       "                                             t-lyric  \n",
       "0  stir fry @@@ woo, woo, woo, woo\\nwoo, woo, woo...  \n",
       "1  drop it like it‚äôs hot @@@ snoop\\nsnoop\\n\\nwh...  \n",
       "2  headlines @@@ i might be too strung out on com...  \n",
       "3  xo tour llif3 @@@ are you alright?\\ni'm alrigh...  \n",
       "4  the way life goes @@@ that's true (that's true...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['t-lyric'] = data['title'] + \" @@@ \" + data['lyrics']\n",
    "data['t-lyric'] = data['t-lyric'].str.lower()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopChars = [',','(',')','.','-','[',']','\"']\n",
    "# preprocessing the corpus by converting all letters to lowercase, \n",
    "# replacing blank lines with blank string and removing special characters\n",
    "def preprocessText(text):\n",
    "#     text = text.replace('\\n', ' ').replace('\\t','')\n",
    "    processedText = text.lower()\n",
    "    for char in stopChars:\n",
    "        processedText = processedText.replace(char,'')\n",
    "    return processedText\n",
    "data['t-lyric'] = data['t-lyric'].apply(preprocessText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization \n",
    "def corpusToList(corpus):\n",
    "    corpusList = [w for w in corpus.split(' ')] \n",
    "    corpusList = [i for i in corpusList if i] #removing empty strings from list\n",
    "    return corpusList\n",
    "data['t-lyric'] = data['t-lyric'].apply(corpusToList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>t-lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Migos</td>\n",
       "      <td>rap</td>\n",
       "      <td>Stir Fry</td>\n",
       "      <td>Woo, woo, woo, woo\\nWoo, woo, woo, woo\\n\\nDanc...</td>\n",
       "      <td>[stir, fry, @@@, woo, woo, woo, woo\\nwoo, woo,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Snoop Dogg</td>\n",
       "      <td>rap</td>\n",
       "      <td>Drop It Like It‚Äôs Hot</td>\n",
       "      <td>Snoop\\nSnoop\\n\\nWhen the pimp's in the crib, m...</td>\n",
       "      <td>[drop, it, like, it‚äôs, hot, @@@, snoop\\nsnoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Drake</td>\n",
       "      <td>rap</td>\n",
       "      <td>Headlines</td>\n",
       "      <td>I might be too strung out on compliments\\nOver...</td>\n",
       "      <td>[headlines, @@@, i, might, be, too, strung, ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Lil Uzi Vert</td>\n",
       "      <td>rap</td>\n",
       "      <td>XO TOUR Llif3</td>\n",
       "      <td>Are you alright?\\nI'm alright, I'm quite alrig...</td>\n",
       "      <td>[xo, tour, llif3, @@@, are, you, alright?\\ni'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Lil Uzi Vert</td>\n",
       "      <td>rap</td>\n",
       "      <td>The Way Life Goes</td>\n",
       "      <td>That's true (That's true), that's right (That ...</td>\n",
       "      <td>[the, way, life, goes, @@@, that's, true, that...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist genre                    title  \\\n",
       "0         Migos   rap                 Stir Fry   \n",
       "1    Snoop Dogg   rap  Drop It Like It‚Äôs Hot   \n",
       "2         Drake   rap                Headlines   \n",
       "3  Lil Uzi Vert   rap            XO TOUR Llif3   \n",
       "4  Lil Uzi Vert   rap        The Way Life Goes   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  Woo, woo, woo, woo\\nWoo, woo, woo, woo\\n\\nDanc...   \n",
       "1  Snoop\\nSnoop\\n\\nWhen the pimp's in the crib, m...   \n",
       "2  I might be too strung out on compliments\\nOver...   \n",
       "3  Are you alright?\\nI'm alright, I'm quite alrig...   \n",
       "4  That's true (That's true), that's right (That ...   \n",
       "\n",
       "                                             t-lyric  \n",
       "0  [stir, fry, @@@, woo, woo, woo, woo\\nwoo, woo,...  \n",
       "1  [drop, it, like, it‚äôs, hot, @@@, snoop\\nsnoo...  \n",
       "2  [headlines, @@@, i, might, be, too, strung, ou...  \n",
       "3  [xo, tour, llif3, @@@, are, you, alright?\\ni'm...  \n",
       "4  [the, way, life, goes, @@@, that's, true, that...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x116ce5b50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trim each word for leading or trailing spaces / tabs.\n",
    "map(str.strip, data['t-lyric']) # trim words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>t-lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Migos</td>\n",
       "      <td>rap</td>\n",
       "      <td>Stir Fry</td>\n",
       "      <td>Woo, woo, woo, woo\\nWoo, woo, woo, woo\\n\\nDanc...</td>\n",
       "      <td>[stir, fry, @@@, woo, woo, woo, woo\\nwoo, woo,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Snoop Dogg</td>\n",
       "      <td>rap</td>\n",
       "      <td>Drop It Like It‚Äôs Hot</td>\n",
       "      <td>Snoop\\nSnoop\\n\\nWhen the pimp's in the crib, m...</td>\n",
       "      <td>[drop, it, like, it‚äôs, hot, @@@, snoop\\nsnoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Drake</td>\n",
       "      <td>rap</td>\n",
       "      <td>Headlines</td>\n",
       "      <td>I might be too strung out on compliments\\nOver...</td>\n",
       "      <td>[headlines, @@@, i, might, be, too, strung, ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Lil Uzi Vert</td>\n",
       "      <td>rap</td>\n",
       "      <td>XO TOUR Llif3</td>\n",
       "      <td>Are you alright?\\nI'm alright, I'm quite alrig...</td>\n",
       "      <td>[xo, tour, llif3, @@@, are, you, alright?\\ni'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Lil Uzi Vert</td>\n",
       "      <td>rap</td>\n",
       "      <td>The Way Life Goes</td>\n",
       "      <td>That's true (That's true), that's right (That ...</td>\n",
       "      <td>[the, way, life, goes, @@@, that's, true, that...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist genre                    title  \\\n",
       "0         Migos   rap                 Stir Fry   \n",
       "1    Snoop Dogg   rap  Drop It Like It‚Äôs Hot   \n",
       "2         Drake   rap                Headlines   \n",
       "3  Lil Uzi Vert   rap            XO TOUR Llif3   \n",
       "4  Lil Uzi Vert   rap        The Way Life Goes   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  Woo, woo, woo, woo\\nWoo, woo, woo, woo\\n\\nDanc...   \n",
       "1  Snoop\\nSnoop\\n\\nWhen the pimp's in the crib, m...   \n",
       "2  I might be too strung out on compliments\\nOver...   \n",
       "3  Are you alright?\\nI'm alright, I'm quite alrig...   \n",
       "4  That's true (That's true), that's right (That ...   \n",
       "\n",
       "                                             t-lyric  \n",
       "0  [stir, fry, @@@, woo, woo, woo, woo\\nwoo, woo,...  \n",
       "1  [drop, it, like, it‚äôs, hot, @@@, snoop\\nsnoo...  \n",
       "2  [headlines, @@@, i, might, be, too, strung, ou...  \n",
       "3  [xo, tour, llif3, @@@, are, you, alright?\\ni'm...  \n",
       "4  [the, way, life, goes, @@@, that's, true, that...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab length: 2810\n",
      "Unique words in corpus: 797\n"
     ]
    }
   ],
   "source": [
    "corpus_words = [x for sublist in data['t-lyric'] for x in sublist]\n",
    "vocab = sorted(set(corpus_words))\n",
    "print('vocab length:', len(corpus_words))\n",
    "print('Unique words in corpus: {}'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating numeric map; representing words with numberes \n",
    "# map specific number to each specific word of our corpus, and vice versa \n",
    "word2idx = {u: i for i, u in enumerate(vocab)}\n",
    "idx2words = np.array(vocab)\n",
    "word_as_int = np.array([word2idx[c] for c in corpus_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User inputs a song title, and how many words they want the song to be. \n",
    "- Network does, for example, 100 predictions, and in the training phrase we know what word we need to generate. \n",
    "- (genre, song title); have a marker that it's the end of the title "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Level LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting a character level-RNN for a single genre\n",
    "https://www.kaggle.com/super13579/let-s-auto-write-the-deep-purple-lysics-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         artist genre                    title  \\\n",
      "0         Migos   rap                 Stir Fry   \n",
      "1    Snoop Dogg   rap  Drop It Like It‚Äôs Hot   \n",
      "2         Drake   rap                Headlines   \n",
      "3  Lil Uzi Vert   rap            XO TOUR Llif3   \n",
      "4  Lil Uzi Vert   rap        The Way Life Goes   \n",
      "\n",
      "                                              lyrics  \n",
      "0  woo woo woo woo\\nwoo woo woo woo\\n\\ndance with...  \n",
      "1  snoop\\nsnoop\\n\\nwhen the pimp's in the crib ma...  \n",
      "2  i might be too strung out on compliments\\nover...  \n",
      "3  are you alright?\\ni'm alright i'm quite alrigh...  \n",
      "4  that's true that's true that's right that righ...  \n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"sample-dataset.csv\")\n",
    "data1['lyrics']= data1['lyrics'].apply(preprocessText)\n",
    "print(data1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 15232\n"
     ]
    }
   ],
   "source": [
    "DP_text = data1['lyrics'].str.cat(sep='\\n').lower()\n",
    "print('corpus length:', len(DP_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', \"'\", '4', '7', '8', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '´', '¶', 'ä', 'î', 'ò', '‚', '√']\n",
      "total chars: 41\n"
     ]
    }
   ],
   "source": [
    "# Counting characters appeared in all lyrics\n",
    "chars = sorted(list(set(DP_text)))\n",
    "print(chars)\n",
    "print('total chars:', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, \"'\": 3, '4': 4, '7': 5, '8': 6, '?': 7, 'a': 8, 'b': 9, 'c': 10, 'd': 11, 'e': 12, 'f': 13, 'g': 14, 'h': 15, 'i': 16, 'j': 17, 'k': 18, 'l': 19, 'm': 20, 'n': 21, 'o': 22, 'p': 23, 'q': 24, 'r': 25, 's': 26, 't': 27, 'u': 28, 'v': 29, 'w': 30, 'x': 31, 'y': 32, 'z': 33, '´': 34, '¶': 35, 'ä': 36, 'î': 37, 'ò': 38, '‚': 39, '√': 40}\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of characters, see the index of characters.\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print(char_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Window\n",
      "['woo woo woo woo\\nwoo woo woo woo\\n\\ndance with my dog'\n",
      " 'oo woo woo woo\\nwoo woo woo woo\\n\\ndance with my dogs'\n",
      " 'o woo woo woo\\nwoo woo woo woo\\n\\ndance with my dogs '\n",
      " ' woo woo woo\\nwoo woo woo woo\\n\\ndance with my dogs i'\n",
      " 'woo woo woo\\nwoo woo woo woo\\n\\ndance with my dogs in']\n",
      "Target characters\n",
      "['s' ' ' 'i' 'n' ' ']\n",
      "Number of sequences: 15182\n"
     ]
    }
   ],
   "source": [
    "seq_length = 50 # The sentence window size\n",
    "step = 1 # The steps between the windows\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "# Create Target and sentences window\n",
    "for i in range(0, len(DP_text) - seq_length, step):\n",
    "    # range from current index to sequence length charaters\n",
    "    sentences.append(DP_text[i: i + seq_length])  \n",
    "    next_chars.append(DP_text[i + seq_length]) # the next character\n",
    "    \n",
    "sentences = np.array(sentences)\n",
    "next_chars = np.array(next_chars)\n",
    "\n",
    "#Print Sentence Window and next charaters\n",
    "print('Sentence Window')\n",
    "print (sentences[:5])\n",
    "print('Target characters')\n",
    "print (next_chars[:5])\n",
    "print('Number of sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transferring the character to index \n",
    "def getdata(sentences, next_chars):\n",
    "    X = np.zeros((len(sentences),seq_length))\n",
    "    y = np.zeros((len(sentences)))\n",
    "    length = len(sentences)\n",
    "    index = 0\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t] = char_to_int[char]\n",
    "        y[i] = char_to_int[next_chars[i]]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y = getdata(sentences, next_chars)\n",
    "print(train_x)\n",
    "print('Shape of training_x:', train_x.shape)\n",
    "print('Shape of training_y:', train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building out the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Simple_LSTM(nn.Module):\n",
    "    def __init__(self,n_vocab,hidden_dim, embedding_dim,dropout = 0.2):\n",
    "        super(Simple_LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,dropout = dropout,num_layers = 2)\n",
    "        self.embeddings = nn.Embedding(n_vocab, embedding_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, n_vocab)\n",
    "    \n",
    "    def forward(self, seq_in):\n",
    "        # for LSTM, input should be (Sequnce_length,batchsize,hidden_layer), so we need to transpose the input\n",
    "        embedded = self.embeddings(seq_in.t()) \n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        # Only need to keep the last character \n",
    "        ht=lstm_out[-1] \n",
    "        out = self.fc(ht)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(train_x, dtype=torch.long)\n",
    "Y_train_tensor = torch.tensor(train_y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "train = torch.utils.data.TensorDataset(X_train_tensor,Y_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Simple_LSTM(47,256,256)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.002) # Using Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time # Add time counter\n",
    "avg_losses_f = []\n",
    "n_epochs=10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    avg_loss = 0.\n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        y_pred = model(x_batch)\n",
    "        \n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        avg_loss+= loss.item()/len(train_loader)\n",
    "        \n",
    "    elapsed_time = time.time() - start_time \n",
    "    print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
    "        epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
    "    \n",
    "    avg_losses_f.append(avg_loss)    \n",
    "    \n",
    "print('All \\t loss={:.4f} \\t '.format(np.average(avg_losses_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(avg_losses_f)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a function that can sample an index from a probability array \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start sentence\n",
    "# sentence = 'i read in the news\\nthat the average man\\nplease kis'\n",
    "sentence = 'i put the new forgis on the g\\ni trap until the blo'\n",
    "variance = 0.25\n",
    "generated = ''\n",
    "original = sentence\n",
    "window = sentence\n",
    "\n",
    "for i in range(400):\n",
    "    x = np.zeros((1, seq_length))\n",
    "    for t, char in enumerate(window):\n",
    "        x[0, t] = char_to_int[char] # Change the sentence to index vector shape (1,50)\n",
    "        \n",
    "    x_in = Variable(torch.LongTensor(x))\n",
    "    pred = model(x_in)\n",
    "    pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
    "    next_index = sample(pred, variance)\n",
    "    next_char = int_to_char[next_index] # index to char\n",
    "\n",
    "    generated += next_char\n",
    "    window = window[1:] + next_char # Update Window for next char predict\n",
    "    \n",
    "print(original + generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Level LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         artist genre                    title  \\\n",
      "0         Migos   rap                 Stir Fry   \n",
      "1    Snoop Dogg   rap  Drop It Like It‚Äôs Hot   \n",
      "2         Drake   rap                Headlines   \n",
      "3  Lil Uzi Vert   rap            XO TOUR Llif3   \n",
      "4  Lil Uzi Vert   rap        The Way Life Goes   \n",
      "\n",
      "                                              lyrics  \n",
      "0  woo woo woo woo\\nwoo woo woo woo\\n\\ndance with...  \n",
      "1  snoop\\nsnoop\\n\\nwhen the pimp's in the crib ma...  \n",
      "2  i might be too strung out on compliments\\nover...  \n",
      "3  are you alright?\\ni'm alright i'm quite alrigh...  \n",
      "4  that's true that's true that's right that righ...  \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "#nltk.download('punkt')\n",
    "data1 = pd.read_csv(\"sample-dataset.csv\")\n",
    "data1['lyrics']= data1['lyrics'].apply(preprocessText)\n",
    "print(data1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 3440\n"
     ]
    }
   ],
   "source": [
    "DP_text = word_tokenize(data1['lyrics'].str.cat(sep='\\n').lower())\n",
    "print('corpus length:', len(DP_text))\n",
    "#todo(dlee, tokenize words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 650\n"
     ]
    }
   ],
   "source": [
    "# Counting characters appeared in all lyrics\n",
    "words = sorted(list(set(DP_text)))\n",
    "print('total words:', len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of characters, see the index of characters.\n",
    "char_to_int = dict((c, i) for i, c in enumerate(words))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Window\n",
      "[['woo' 'woo' 'woo' 'woo' 'woo' 'woo' 'woo' 'woo' 'dance' 'with']\n",
      " ['woo' 'woo' 'woo' 'woo' 'woo' 'woo' 'woo' 'dance' 'with' 'my']\n",
      " ['woo' 'woo' 'woo' 'woo' 'woo' 'woo' 'dance' 'with' 'my' 'dogs']\n",
      " ['woo' 'woo' 'woo' 'woo' 'woo' 'dance' 'with' 'my' 'dogs' 'in']\n",
      " ['woo' 'woo' 'woo' 'woo' 'dance' 'with' 'my' 'dogs' 'in' 'the']]\n",
      "Target characters\n",
      "['my' 'dogs' 'in' 'the' 'nighttime']\n",
      "Number of sequences: 3430\n"
     ]
    }
   ],
   "source": [
    "seq_length = 10 # The sentence window size\n",
    "step = 1 # The steps between the windows\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "# Create Target and sentences window\n",
    "for i in range(0, len(DP_text) - seq_length, step):\n",
    "    # range from current index to sequence length charaters\n",
    "    sentences.append(DP_text[i: i + seq_length])  \n",
    "    next_chars.append(DP_text[i + seq_length]) # the next character\n",
    "    \n",
    "sentences = np.array(sentences)\n",
    "next_chars = np.array(next_chars)\n",
    "\n",
    "#Print Sentence Window and next charaters\n",
    "print('Sentence Window')\n",
    "print (sentences[:5])\n",
    "print('Target characters')\n",
    "print (next_chars[:5])\n",
    "print('Number of sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transferring the character to index \n",
    "def getdata(sentences, next_chars):\n",
    "    X = np.zeros((len(sentences),seq_length))\n",
    "    y = np.zeros((len(sentences)))\n",
    "    length = len(sentences)\n",
    "    index = 0\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t] = char_to_int[char]\n",
    "        y[i] = char_to_int[next_chars[i]]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[632. 632. 632. ... 632. 145. 629.]\n",
      " [632. 632. 632. ... 145. 629. 364.]\n",
      " [632. 632. 632. ... 629. 364. 162.]\n",
      " ...\n",
      " [ 86. 284. 320. ... 284. 628. 284.]\n",
      " [284. 320. 547. ... 628. 284. 374.]\n",
      " [320. 547. 236. ... 284. 374. 348.]]\n",
      "Shape of training_x: (3430, 10)\n",
      "Shape of training_y: (3430,)\n"
     ]
    }
   ],
   "source": [
    "train_x,train_y = getdata(sentences, next_chars)\n",
    "print(train_x)\n",
    "print('Shape of training_x:', train_x.shape)\n",
    "print('Shape of training_y:', train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Simple_LSTM(nn.Module):\n",
    "    def __init__(self,n_vocab,hidden_dim, embedding_dim,dropout = 0.2):\n",
    "        super(Simple_LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,dropout = dropout,num_layers = 2)\n",
    "        self.embeddings = nn.Embedding(n_vocab, embedding_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, n_vocab)\n",
    "    \n",
    "    def forward(self, seq_in):\n",
    "        # for LSTM, input should be (Sequnce_length,batchsize,hidden_layer), so we need to transpose the input\n",
    "        embedded = self.embeddings(seq_in.t()) \n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        # Only need to keep the last character \n",
    "        ht=lstm_out[-1] \n",
    "        out = self.fc(ht)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training_x: torch.Size([3430, 10])\n",
      "Shape of training_y: torch.Size([3430])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.tensor(train_x, dtype=torch.long)\n",
    "Y_train_tensor = torch.tensor(train_y, dtype=torch.long)\n",
    "print('Shape of training_x:', X_train_tensor.shape)\n",
    "print('Shape of training_y:', Y_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "train = torch.utils.data.TensorDataset(X_train_tensor,Y_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Simple_LSTM(len(words),256,256)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.002) # Using Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch 1/20 \t loss=5.8391 \t time=3.12s\n",
      "Epoch:  1\n",
      "Epoch 2/20 \t loss=5.3785 \t time=2.98s\n",
      "Epoch:  2\n",
      "Epoch 3/20 \t loss=4.9413 \t time=2.92s\n",
      "Epoch:  3\n",
      "Epoch 4/20 \t loss=4.4266 \t time=3.15s\n",
      "Epoch:  4\n",
      "Epoch 5/20 \t loss=3.8698 \t time=3.20s\n",
      "Epoch:  5\n",
      "Epoch 6/20 \t loss=3.3261 \t time=3.07s\n",
      "Epoch:  6\n",
      "Epoch 7/20 \t loss=2.8072 \t time=3.13s\n",
      "Epoch:  7\n",
      "Epoch 8/20 \t loss=2.3601 \t time=3.17s\n",
      "Epoch:  8\n",
      "Epoch 9/20 \t loss=1.9756 \t time=3.02s\n",
      "Epoch:  9\n",
      "Epoch 10/20 \t loss=1.5993 \t time=3.17s\n",
      "Epoch:  10\n",
      "Epoch 11/20 \t loss=1.2876 \t time=3.14s\n",
      "Epoch:  11\n",
      "Epoch 12/20 \t loss=0.9869 \t time=3.14s\n",
      "Epoch:  12\n",
      "Epoch 13/20 \t loss=0.7217 \t time=3.20s\n",
      "Epoch:  13\n",
      "Epoch 14/20 \t loss=0.5157 \t time=3.15s\n",
      "Epoch:  14\n",
      "Epoch 15/20 \t loss=0.3938 \t time=3.20s\n",
      "Epoch:  15\n",
      "Epoch 16/20 \t loss=0.2901 \t time=3.13s\n",
      "Epoch:  16\n",
      "Epoch 17/20 \t loss=0.2170 \t time=3.17s\n",
      "Epoch:  17\n",
      "Epoch 18/20 \t loss=0.1737 \t time=3.22s\n",
      "Epoch:  18\n",
      "Epoch 19/20 \t loss=0.1460 \t time=3.23s\n",
      "Epoch:  19\n",
      "Epoch 20/20 \t loss=0.1319 \t time=3.21s\n",
      "All \t loss=2.0694 \t \n"
     ]
    }
   ],
   "source": [
    "import time # Add time counter\n",
    "avg_losses_f = []\n",
    "n_epochs=20\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    avg_loss = 0.\n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        y_pred = model(x_batch)\n",
    "        \n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        avg_loss+= loss.item()/len(train_loader)\n",
    "        \n",
    "    elapsed_time = time.time() - start_time \n",
    "    print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
    "        epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
    "    \n",
    "    avg_losses_f.append(avg_loss)    \n",
    "    \n",
    "print('All \\t loss={:.4f} \\t '.format(np.average(avg_losses_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(avg_losses_f)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she got forever addicted to a body killer spillin ice with the chickens like suicide wrist red take it i take a second ding cars real you big should four take your rick diamonds on the million hey to give you fuck faded them own look and i got a niggas premiere boss to the left pockets fallin and i roll the best weed ‚äòcause i got it goin ' on i 'm a gangsta but y'all y'all knew that leather big boss yeah i had to do that i keep a blue flag hangin ' all my money but in the way that she treat me gon ' leave you wo n't leave me i call it that casanova she say i 'm insane yeah i might blow my brain out hey xanny help the pain yeah please xanny make it go away i 'm committed not addicted but it keep control of me all the pain now i ca n't feel it i swear it 's listening she to the plan other all way my bands to with the money all my friends are dead push me to the edge all my friends are dead push me to the edge that 's all red inside all white like somethin ' you ride a sled down i just want that head my brittany got mad i 'm barely her man now everybody got the same swag now watch the way that i tear it spillin ' down see i all it look them way to the top 'til they be fallin ' over yeah yeah yeah countin ' them bands all way to the top 'til 'til they be fallin ' over yeah yeah is not your swag i had to your a new bitch to swag you at you got a gun you should take off my second laurent opera bird off my body take my time take you stop ! i 'm on the real you trying to fuck and i swear that you 'll get over it i know you 're sad and tired you 've got nothing left to give yeah you 'll find another life to live 'll i know no no i do n't got a debt hah you crawl 'fore you walk on my mans i got ta dead her her i 'm pourin ' onion onion then make all all make was go niggas soap opera rappers like that 's want\n"
     ]
    }
   ],
   "source": [
    "# Define the start sentence\n",
    "# sentence = 'i read in the news\\nthat the average man\\nplease kis'\n",
    "sentence = [\"she\", \"got\", \"forever\", \"addicted\", \"to\", \"a\", \"body\", \"killer\", \"spillin\", \"ice\"]\n",
    "variance = 1\n",
    "generated = []\n",
    "original = sentence\n",
    "window = sentence\n",
    "\n",
    "for i in range(400):\n",
    "    x = np.zeros((1, seq_length))\n",
    "    for t, char in enumerate(window):\n",
    "        x[0, t] = char_to_int[char] # Change the sentence to index vector shape (1,50)\n",
    "        \n",
    "    x_in = Variable(torch.LongTensor(x))\n",
    "    pred = model(x_in)\n",
    "    pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
    "    next_index = sample(pred, variance)\n",
    "    next_char = int_to_char[next_index] # index to char\n",
    "\n",
    "    generated = generated + [next_char]\n",
    "    window = window[1:] + [next_char] # Update Window for next char predict\n",
    "    \n",
    "print(\" \".join(original + generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
