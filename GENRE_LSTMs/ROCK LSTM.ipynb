{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import random \n",
    "# https://github.com/petrosDemetrakopoulos/RNN-Beatles-lyrics-generator\n",
    "# https://github.com/starry91/Lyric-Generator#2-lyric-generator-based-on-word-level-rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssh -i \"ling380.pem\" ec2-user@ec2-3-21-233-161.us-east-2.compute.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "Country           20115\n",
      "Electronic         7009\n",
      "Folk               5777\n",
      "Hip-Hop           23045\n",
      "Indie              2971\n",
      "Jazz              12247\n",
      "Metal             29418\n",
      "Not Available     17582\n",
      "Other              3985\n",
      "Pop               43211\n",
      "R&B                7704\n",
      "Rap               10105\n",
      "Rock             110690\n",
      "Soul               4069\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Reading in language CSV \n",
    "data = pd.read_csv(\"language-processed-data.csv\")\n",
    "data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
    "data[\"genre\"].replace({\"country\": \"Country\", \"soul\": \"Soul\", \"jazz\":\"Jazz\", \n",
    "                            \"folk\":\"Folk\", \"pop\":\"Pop\", \"metal\":\"Metal\", \"rb\":\"R&B\", \n",
    "                            \"rock\":\"Rock\", \"rap\":\"Rap\"}, inplace=True)\n",
    "print(data.groupby(['genre']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297928, 6)\n",
      "            artist genre            title  \\\n",
      "0  beyonce-knowles   Pop        ego remix   \n",
      "1  beyonce-knowles   Pop     then tell me   \n",
      "2  beyonce-knowles   Pop          honesty   \n",
      "3  beyonce-knowles   Pop  you are my rock   \n",
      "4  beyonce-knowles   Pop    black culture   \n",
      "\n",
      "                                              lyrics  word_num language  \n",
      "0  Oh baby, how you doing?\\nYou know I'm gonna cu...       NaN       en  \n",
      "1  playin' everything so easy,\\nit's like you see...       NaN       en  \n",
      "2  If you search\\nFor tenderness\\nIt isn't hard t...       NaN       en  \n",
      "3  Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...       NaN       en  \n",
      "4  Party the people, the people the party it's po...       NaN       en  \n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User inputs a song title, and how many words they want the song to be. \n",
    "- Network does, for example, 100 predictions, and in the training phrase we know what word we need to generate. \n",
    "- (genre, song title); have a marker that it's the end of the title "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Level LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopChars = [',','(',')','.','-','[',']','\"']\n",
    "# preprocessing the corpus by converting all letters to lowercase, \n",
    "# replacing blank lines with blank string and removing special characters\n",
    "def preprocessText(text):\n",
    "#     text = text.replace('\\n', ' ').replace('\\t','')\n",
    "    processedText = text.lower()\n",
    "    for char in stopChars:\n",
    "        processedText = processedText.replace(char,'')\n",
    "    return processedText\n",
    "\n",
    "# tokenization \n",
    "def corpusToList(corpus):\n",
    "    corpusList = [w for w in corpus.split(' ')] \n",
    "    corpusList = [i for i in corpusList if i] #removing empty strings from list\n",
    "    return corpusList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(genre, sample_size):\n",
    "    random.seed(69)\n",
    "    data1 = data\n",
    "    data1 = data1[data1['genre'] == genre].sample(sample_size)\n",
    "    data1['lyrics'] = data1['lyrics'].astype(str)\n",
    "    data1['lyrics']= data1['lyrics'].apply(preprocessText)\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(data):\n",
    "    newlines = re.sub(\"\\n\", \" \\n \", data['lyrics'].str.cat(sep='\\n').lower())\n",
    "    exclamation = re.sub(\"!\", \" ! \", newlines)\n",
    "    question = re.sub(\"!\", \" ! \", exclamation)\n",
    "    DP_text = re.findall(r'\\S+|\\n', question)\n",
    "    print('corpus length:', len(DP_text))\n",
    "    return(DP_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of characters, see the index of characters.\n",
    "def dictionary_maker(words):\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(words))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(words))\n",
    "    return(char_to_int, int_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentences_and_next_chars(seq_length, DP_text, step):\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "\n",
    "    # Create Target and sentences window\n",
    "    for i in range(0, len(DP_text) - seq_length, step):\n",
    "        # range from current index to sequence length charaters\n",
    "        sentences.append(DP_text[i: i + seq_length])  \n",
    "        next_chars.append(DP_text[i + seq_length]) # the next character\n",
    "    \n",
    "    sentences = np.array(sentences)\n",
    "    next_chars = np.array(next_chars)\n",
    "    return(sentences, next_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 6)\n",
      "['Rock']\n"
     ]
    }
   ],
   "source": [
    "rap_data = sample_data('Rock', 6000)\n",
    "print(rap_data.shape)\n",
    "print(rap_data.genre.unique())\n",
    "#pop_data = sample_data('pop', 2000)\n",
    "#country_data = sample_data('country', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 1369100\n"
     ]
    }
   ],
   "source": [
    "DP_rap = tokenize_data(rap_data)\n",
    "#DP_pop = tokenize_data(pop_data)\n",
    "#DP_country = tokenize_data(country_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting characters appeared in all lyrics\n",
    "rap_words = sorted(list(set(DP_rap)))\n",
    "#pop_words = sorted(list(set(DP_pop)))\n",
    "#country_words = sorted(list(set(DP_country)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rap_char_to_int, rap_int_to_char = dictionary_maker(rap_words)\n",
    "#pop_char_to_int, pop_int_to_char = dictionary_maker(pop_words)\n",
    "#country_char_to_int, country_int_to_char = dictionary_maker(country_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rap_sentences, rap_next_chars = make_sentences_and_next_chars(16, DP_rap, 1)\n",
    "#pop_sentences, pop_next_chars = make_sentences_and_next_chars(16, DP_pop, 1)\n",
    "#country_sentences, country_next_chars = make_sentences_and_next_chars(16, DP_country, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transferring the character to index \n",
    "def getdata(sentences, next_chars, seq_length, char_to_int):\n",
    "    X = np.zeros((len(sentences),seq_length))\n",
    "    y = np.zeros((len(sentences)))\n",
    "    length = len(sentences)\n",
    "    index = 0\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t] = char_to_int[char]\n",
    "        y[i] = char_to_int[next_chars[i]]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple_LSTM(nn.Module):\n",
    "    def __init__(self,n_vocab,hidden_dim, embedding_dim,dropout = 0.2):\n",
    "        super(Simple_LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,dropout = dropout,num_layers = 2)\n",
    "        self.embeddings = nn.Embedding(n_vocab, embedding_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, n_vocab)\n",
    "    \n",
    "    def forward(self, seq_in):\n",
    "        # for LSTM, input should be (Sequnce_length,batchsize,hidden_layer), so we need to transpose the input\n",
    "        embedded = self.embeddings(seq_in.t()) \n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        # Only need to keep the last character \n",
    "        ht=lstm_out[-1] \n",
    "        out = self.fc(ht)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(sentences, next_chars, epoch_count, words, seq_length, char_to_int):\n",
    "    train_x, train_y = getdata(sentences, next_chars, seq_length, char_to_int)\n",
    "    \n",
    "    X_train_tensor = torch.tensor(train_x, dtype=torch.long).to(device)\n",
    "    Y_train_tensor = torch.tensor(train_y, dtype=torch.long).to(device)\n",
    "    \n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    train = torch.utils.data.TensorDataset(X_train_tensor,Y_train_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size = 128)\n",
    "    \n",
    "    model = Simple_LSTM(len(words),256,256).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.002)\n",
    "    \n",
    "    import time # Add time counter\n",
    "    avg_losses_f = []\n",
    "    n_epochs = epoch_count\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch: \", epoch)\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        avg_loss = 0.\n",
    "        for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        \n",
    "            y_pred = model(x_batch)\n",
    "        \n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "            avg_loss+= loss.item()/len(train_loader)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time \n",
    "        print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
    "            epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
    "    \n",
    "        avg_losses_f.append(avg_loss)    \n",
    "    \n",
    "    print('All \\t loss={:.4f} \\t '.format(np.average(avg_losses_f)))\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.plot(avg_losses_f)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss value')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch 1/20 \t loss=5.4158 \t time=961.45s\n",
      "Epoch:  1\n",
      "Epoch 2/20 \t loss=4.8779 \t time=963.82s\n",
      "Epoch:  2\n",
      "Epoch 3/20 \t loss=4.6611 \t time=964.63s\n",
      "Epoch:  3\n",
      "Epoch 4/20 \t loss=4.4873 \t time=964.69s\n",
      "Epoch:  4\n",
      "Epoch 5/20 \t loss=4.3554 \t time=963.84s\n",
      "Epoch:  5\n",
      "Epoch 6/20 \t loss=4.2534 \t time=964.34s\n",
      "Epoch:  6\n",
      "Epoch 7/20 \t loss=4.1654 \t time=963.92s\n",
      "Epoch:  7\n",
      "Epoch 8/20 \t loss=4.0934 \t time=963.88s\n",
      "Epoch:  8\n",
      "Epoch 9/20 \t loss=4.0312 \t time=963.72s\n",
      "Epoch:  9\n",
      "Epoch 10/20 \t loss=3.9826 \t time=963.65s\n",
      "Epoch:  10\n",
      "Epoch 11/20 \t loss=3.9408 \t time=964.17s\n",
      "Epoch:  11\n",
      "Epoch 12/20 \t loss=3.9029 \t time=963.84s\n",
      "Epoch:  12\n",
      "Epoch 13/20 \t loss=3.8714 \t time=963.46s\n",
      "Epoch:  13\n",
      "Epoch 14/20 \t loss=3.8435 \t time=963.67s\n",
      "Epoch:  14\n",
      "Epoch 15/20 \t loss=3.8166 \t time=963.53s\n",
      "Epoch:  15\n",
      "Epoch 16/20 \t loss=3.7968 \t time=963.00s\n",
      "Epoch:  16\n",
      "Epoch 17/20 \t loss=3.7764 \t time=962.47s\n",
      "Epoch:  17\n",
      "Epoch 18/20 \t loss=3.7580 \t time=694.05s\n",
      "Epoch:  18\n",
      "Epoch 19/20 \t loss=3.7399 \t time=547.05s\n",
      "Epoch:  19\n",
      "Epoch 20/20 \t loss=3.7235 \t time=347.71s\n",
      "All \t loss=4.1247 \t \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock done\n"
     ]
    }
   ],
   "source": [
    "rock_model = train_model(rap_sentences, rap_next_chars, 20, rap_words, 16, rap_char_to_int)\n",
    "torch.save(rock_model.state_dict(), 'rock_checkpoint.pth')\n",
    "print(\"rock done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pop_model = train_model(pop_sentences, pop_next_chars, 5, pop_words, 16, pop_char_to_int)\n",
    "# print(\"pop done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country_model = train_model(country_sentences, country_next_chars, 5, country_words, 16, country_char_to_int)\n",
    "# print(\"country done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on god i love the blow \n",
      " on god i love the pussy \n",
      " but more than slave \n",
      " rots and moan \n",
      " and i'm on my shoulders \n",
      " rushin' around my head \n",
      " my home's will restore \n",
      " and i've gotten away \n",
      " and i know what i mean \n",
      " and i want to find you \n",
      " i know you know \n",
      " i'm not gonna start this thing \n",
      " and lend me a smile \n",
      " and i don't know what it means \n",
      " how can i have to be a father \n",
      " i'm a rebel rebel \n",
      " am i a preacher's son \n",
      " who knows i'm a liar \n",
      " i got the sugar \n",
      " i love you \n",
      " but i want to be \n",
      " cause i don't know what i want \n",
      " i wish i could be here \n",
      " i'm not sure i'm losing control \n",
      " i know i miss you for \n",
      " you've got to hide \n",
      " i wish i could fly \n",
      " to be the only one \n",
      " to see me again \n",
      " i wish that i could be in love \n",
      " and i know i know that you are \n",
      " i couldn't see you \n",
      " i was my love \n",
      " you'll be your worrying \n",
      " i could just be found \n",
      " i want you to be for you \n",
      " i don't know you \n",
      " i don't wanna be back \n",
      " i don't wanna wait \n",
      " i'm not listening \n",
      " i don't know what to do \n",
      " i got a date i’ll \n",
      " i got my answer \n",
      " i got the lonesome thing \n",
      " she doesn't want me \n",
      " i'm not so fine \n",
      " she walks away \n",
      " she danced my way \n",
      " she danced to me \n",
      " she danced her eyes \n",
      " she danced my heart \n",
      " i found her \n",
      " she danced and i danced \n",
      " i danced to the night \n",
      " i danced my face and i danced to my heart \n",
      " she danced my old song \n",
      " i was half my address \n",
      " i would have my suspicions \n",
      " i saw a second horse \n",
      " i heard a rumor ran away \n",
      " and i was found in my ear \n",
      " she danced my day \n",
      " i danced with my eyes \n",
      " and i danced her name \n",
      " well i danced to the ocean \n",
      " i didn't know you \n",
      " i was so happy but the world is \n",
      " and i thought i could have seen it \n",
      " i could\n"
     ]
    }
   ],
   "source": [
    "# Define the start sentence\n",
    "# sentence = 'i read in the news\\nthat the average man\\nplease kis'\n",
    "seq_length = 16\n",
    "char_to_int = rap_char_to_int\n",
    "int_to_char = rap_int_to_char\n",
    "sentence = [\"on\", \"god\", \"i\", \"love\", \"the\", \"blow\", \"\\n\", \"on\", \"god\", \"i\",\n",
    "           \"love\", \"the\", \"pussy\", \"\\n\", \"but\", \"more\"]\n",
    "variance = .5\n",
    "generated = []\n",
    "original = sentence\n",
    "window = sentence\n",
    "\n",
    "for i in range(400):\n",
    "    x = np.zeros((1, seq_length))\n",
    "    for t, char in enumerate(window):\n",
    "        x[0, t] = char_to_int[char] # Change the sentence to index vector shape (1,50)\n",
    "        \n",
    "    x_in = Variable(torch.LongTensor(x).to(device))\n",
    "    pred = rock_model(x_in)\n",
    "    pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
    "    next_index = sample(pred, variance)\n",
    "    next_char = int_to_char[next_index] # index to char\n",
    "\n",
    "    generated = generated + [next_char]\n",
    "    window = window[1:] + [next_char] # Update Window for next char predict\n",
    "    \n",
    "print(\" \".join(original + generated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sentence:  0\n",
      "In sentence:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sentence:  2\n",
      "In sentence:  3\n",
      "In sentence:  4\n",
      "In sentence:  5\n",
      "In sentence:  6\n",
      "In sentence:  7\n",
      "In sentence:  8\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'wasn’t'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a6e2ac5e4ca5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlyrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlyrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-a6e2ac5e4ca5>\u001b[0m in \u001b[0;36mgenerate_sentence\u001b[0;34m(input_sentences)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Change the sentence to index vector shape (1,50)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mx_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'wasn’t'"
     ]
    }
   ],
   "source": [
    "starters = [[\"i\", \"like\", \"long\", \"walk\", \"on\", \"the\", \"beach\", \"\\n\", \"and\", \"shopping\", \"runs\", \"in\", \"paris\", \"\\n\", \"i\", \"sometimes\"],\n",
    "[\"it\", \"was\", \"a\", \"dark\", \"day\", \"when\", \"he\", \"died\", \"\\n\", \"my\", \"mom\",  \"had\", \"tears\", \"in\", \"her\", \"eyes\"],\n",
    "[\"yeah\", \"\\n\", \"yeah\", \"\\n\", \"yeah\", \"\\n\", \"this\", \"is\", \"the\", \"way\", \"i\", \"talk\", \"when\", \"i’m\", \"mad\", \"\\n\"],\n",
    "[\"drive\", \"forever\", \"\\n\", \"baby\", \"i\", \"need\", \"your\", \"heart\", \"\\n\", \"free\", \"car\", \"\\n\", \"just\", \"another\", \"a\", \"wild\"],\n",
    "[\"the\", \"way\", \"that\", \"you\", \"love\", \"me\", \"\\n\", \"is\", \"hard\", \"to\", \"explain\", \"\\n\", \"i’m\", \"addicted\", \"to\", \"your\"],\n",
    "[\"love\", \"women\", \"\\n\", \"get\", \"money\", \"\\n\", \"love\", \"women\", \"\\n\", \"get\", \"money\", \"\\n\", \"makes\", \"a\", \"lot\", \"of\"],\n",
    "[\"baby\", \"you\", \"are\", \"crazy\", \"\\n\", \"you\", \"make\", \"no\", \"sense\", \"\\n\", \"talking\", \"to\", \"you\", \"\\n\", \"is\", \"like\"],\n",
    "[\"it’s\", \"been\", \"a\", \"while\", \"since\", \"you\", \"spoke\", \"to\", \"me\", \"\\n\", \"turned\", \"your\", \"head\", \"\\n\", \"cracked\", \"a\"],\n",
    "[\"lies\", \"spreading\", \"round\", \"\\n\", \"that\", \"you've\", \"been\", \"seen\", \"with\", \"him\", \"\\n\", \"guess\", \"i\", \"wasn’t\", \"enough\", \"for\"],\n",
    "[\"i\", \"been\", \"all\", \"over\", \"this\", \"god\", \"damn\", \"town\", \"\\n\", \"under\", \"the\", \"bridges\", \"and\", \"up\", \"in\", \"the\"],\n",
    "[\"oh\", \"oh\", \"oh\", \"\\n\", \"yeah\", \"yeah\", \"yeah\", \"\\n\", \"that’s\", \"what\", \"i’m\", \"talkin\", \"about\", \"\\n\", \"look\", \"at\"],\n",
    "[\"well\", \"i\", \"was\", \"walking\", \"round\", \"town\", \"with\", \"this\", \"girl\", \"i\", \"knew\", \"\\n\", \"when\", \"a\", \"man\", \"came\"],\n",
    "[\"fire\", \"and\", \"flames\", \"\\n\", \"passing\", \"tongues\", \"once\", \"bright\", \"with\", \"life\", \"\\n\", \"this\", \"is\", \"the\", \"world\", \"as\"],\n",
    "[\"on\", \"god\", \"i\", \"love\", \"the\", \"women\", \"\\n\", \"on\", \"god\", \"i\", \"love\", \"the\", \"blow\", \"\\n\", \"on\", \"god\"],\n",
    "[\"i\", \"can\", \"take\", \"you\", \"to\", \"the\", \"west\", \"coast\", \"best\", \"coast\", \"with\", \"a\", \"piece\", \"of\", \"toast\", \"yeah\"],\n",
    "[\"the\", \"stars\", \"were\", \"golden\", \"\\n\", \"the\", \"sky\", \"was\", \"dark\", \"\\n\", \"it\", \"was\", \"just\", \"you\", \"and\", \"me\"],\n",
    "[\"please\", \"baby\", \"please\", \"\\n\", \"please\", \"baby\", \"please\", \"\\n\", \"the\", \"things\", \"you\", \"do\", \"to\", \"me\", \"\\n\", \"you\"],\n",
    "[\"sweet\", \"adam\", \"\\n\", \"your\", \"tender\", \"touch\", \"\\n\", \"all\", \"i\", \"need\", \"when\", \"the\", \"weather\", \"gets\", \"cold\", \"\\n\"],\n",
    "[\"hello\", \"there\", \"\\n\", \"the\", \"toy\", \"from\", \"my\", \"nightmare\", \"\\n\", \"the\", \"figure\", \"in\", \"front\", \"of\", \"me\", \"\\n\"],\n",
    "[\"i\", \"like\", \"to\", \"spit\", \"\\n\", \"in\", \"the\", \"morning\", \"when\", \"i’m\", \"done\", \"taking\", \"my\", \"shit\", \"\\n\", \"i\"]]\n",
    "\n",
    "seq_length = 16\n",
    "char_to_int = rap_char_to_int\n",
    "int_to_char = rap_int_to_char\n",
    "\n",
    "def generate_sentence(input_sentences): \n",
    "    starter = [] \n",
    "    generation = [] \n",
    "    \n",
    "    for i in range(len(input_sentences)): \n",
    "        print(\"In sentence: \", i)\n",
    "        variance = .5\n",
    "        generated = []\n",
    "        original = input_sentences[i]\n",
    "        window = input_sentences[i]\n",
    "\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, seq_length))\n",
    "            for t, char in enumerate(window):\n",
    "                x[0, t] = char_to_int[char] # Change the sentence to index vector shape (1,50)\n",
    "\n",
    "            x_in = Variable(torch.LongTensor(x).to(device))\n",
    "            pred = rock_model(x_in)\n",
    "            pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
    "            next_index = sample(pred, variance)\n",
    "            next_char = int_to_char[next_index] # index to char\n",
    "\n",
    "            generated = generated + [next_char]\n",
    "            window = window[1:] + [next_char] # Update Window for next char predict\n",
    "        \n",
    "        starter.append(original) \n",
    "        generation.append(generated)\n",
    "\n",
    "    lyrics = pd.DataFrame({'starter': starter, 'output': generation})\n",
    "    print(lyrics.head())\n",
    "    return lyrics \n",
    "output = generate_sentence(starters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METRIC 1: AVERAGE LINE LENGTH \n",
    "import math\n",
    "def mean(numbers):\n",
    "    return float(sum(numbers)) / max(len(numbers), 1)\n",
    "def single_length_length(output): \n",
    "    newline_count = output.count('\\n')\n",
    "    return round((len(output) - newline_count) / (newline_count + 1), 2)\n",
    "def average_line_length(df): \n",
    "    # (length of the list - # of new lines) / (# new lines + 1 )\n",
    "    result = df['output'].apply(single_length_length).tolist()\n",
    "    return mean(result)\n",
    "\n",
    "# METRIC 2: Word variation: # of Unique words divided by total # of words \n",
    "def variation(output): \n",
    "    line = [value for value in output if value != \"\\n\"]\n",
    "    unique_num = len(list(set(line)))\n",
    "    return unique_num/len(line)\n",
    "def word_variation(df): \n",
    "    result = df['output'].apply(variation).tolist()\n",
    "    return mean(result)\n",
    "\n",
    "# METRIC 3: Genre Word Variation \n",
    "def genre_word_variation(df): \n",
    "    output_list = df['output'].tolist()\n",
    "    return variation(output_list[0])\n",
    "\n",
    "# METRIC 4: % of I vs. You \n",
    "def count_iyou(row): \n",
    "    i_count, you_count = 0,0 \n",
    "    x = 0\n",
    "    while x < len(row):\n",
    "        if x == 0 and row[x] == \"you\": \n",
    "            you_count += 1\n",
    "        if x == 0 and row[x] == \"i\":\n",
    "            i_count += 1 \n",
    "        if x < len(row) - 1: \n",
    "            if row[x] == \"\\n\" and row[x + 1] == \"i\": \n",
    "                i_count += 1 \n",
    "            if row[x] == \"\\n\" and row[x + 1] == \"you\": \n",
    "                you_count += 1\n",
    "        x += 1 \n",
    "\n",
    "    return (i_count - you_count)\n",
    "\n",
    "def i_you(df): \n",
    "    result = df['output'].apply(count_iyou).to_list()\n",
    "    return mean(result)\n",
    "# the more positive, the more i's there are. \n",
    "\n",
    "# METRIC 5: Word reptition \n",
    "# if the word is the same as the one that came before it \n",
    "def count_s(row): \n",
    "    count, x = 0, 0\n",
    "    while x < len(row): \n",
    "        if x < len(row) - 1: \n",
    "            if row[x] == row[x+1]: \n",
    "                count += 1 \n",
    "        x += 1 \n",
    "    return count \n",
    "def count_succession(df): \n",
    "    result = df['output'].apply(count_s).to_list()\n",
    "    return mean(result)\n",
    "\n",
    "# METRIC 1: AVERAGE LINE LENGTH \n",
    "print(average_line_length(output))\n",
    "# METRIC 2: Word variation: # of Unique words divided by total # of words \n",
    "print(word_variation(output))\n",
    "# METRIC 3: Genre Word Variation \n",
    "print(genre_word_variation(output))\n",
    "# METRIC 4: % of I vs. You \n",
    "print(i_you(output))\n",
    "# METRIC 5: Word repetition \n",
    "print(count_succession(output)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(genre, sample_size):\n",
    "    random.seed(69)\n",
    "    data1 = data\n",
    "    data1 = data1[data1['genre'] == genre].sample(sample_size)\n",
    "    data1['lyrics'] = data1['lyrics'].astype(str)\n",
    "    data1['lyrics']= data1['lyrics'].apply(preprocessText)\n",
    "    return data1\n",
    "\n",
    "def tokenize_data(data):\n",
    "    newlines = re.sub(\"\\n\", \" \\n \", data.lower())\n",
    "    exclamation = re.sub(\"!\", \" ! \", newlines)\n",
    "    question = re.sub(\"!\", \" ! \", exclamation)\n",
    "    DP_text = re.findall(r'\\S+|\\n', question)\n",
    "    return(DP_text)\n",
    "\n",
    "r_data = sample_data('Rock', 2000)\n",
    "r_data['output'] = r_data['lyrics'].apply(tokenize_data)\n",
    "\n",
    "# METRIC 1: AVERAGE LINE LENGTH \n",
    "print(average_line_length(r_data))\n",
    "# METRIC 2: Word variation: # of Unique words divided by total # of words \n",
    "print(word_variation(r_data))\n",
    "# METRIC 3: Genre Word Variation \n",
    "print(genre_word_variation(r_data))\n",
    "# METRIC 4: % of I vs. You \n",
    "print(i_you(r_data))\n",
    "# METRIC 5: Word repetition \n",
    "print(count_succession(r_data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
