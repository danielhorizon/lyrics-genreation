{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import random \n",
    "\n",
    "# https://github.com/petrosDemetrakopoulos/RNN-Beatles-lyrics-generator\n",
    "# https://github.com/starry91/Lyric-Generator#2-lyric-generator-based-on-word-level-rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssh -i \"ling380.pem\" ec2-user@ec2-3-21-233-161.us-east-2.compute.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "Country           20115\n",
      "Electronic         7009\n",
      "Folk               5777\n",
      "Hip-Hop           23045\n",
      "Indie              2971\n",
      "Jazz              12247\n",
      "Metal             29418\n",
      "Not Available     17582\n",
      "Other              3985\n",
      "Pop               43211\n",
      "R&B                7704\n",
      "Rap               10105\n",
      "Rock             110690\n",
      "Soul               4069\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Reading in language CSV \n",
    "data = pd.read_csv(\"language-processed-data.csv\")\n",
    "data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
    "data[\"genre\"].replace({\"country\": \"Country\", \"soul\": \"Soul\", \"jazz\":\"Jazz\", \n",
    "                            \"folk\":\"Folk\", \"pop\":\"Pop\", \"metal\":\"Metal\", \"rb\":\"R&B\", \n",
    "                            \"rock\":\"Rock\", \"rap\":\"Rap\"}, inplace=True)\n",
    "print(data.groupby(['genre']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297928, 6)\n",
      "            artist genre            title  \\\n",
      "0  beyonce-knowles   Pop        ego remix   \n",
      "1  beyonce-knowles   Pop     then tell me   \n",
      "2  beyonce-knowles   Pop          honesty   \n",
      "3  beyonce-knowles   Pop  you are my rock   \n",
      "4  beyonce-knowles   Pop    black culture   \n",
      "\n",
      "                                              lyrics  word_num language  \n",
      "0  Oh baby, how you doing?\\nYou know I'm gonna cu...       NaN       en  \n",
      "1  playin' everything so easy,\\nit's like you see...       NaN       en  \n",
      "2  If you search\\nFor tenderness\\nIt isn't hard t...       NaN       en  \n",
      "3  Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...       NaN       en  \n",
      "4  Party the people, the people the party it's po...       NaN       en  \n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User inputs a song title, and how many words they want the song to be. \n",
    "- Network does, for example, 100 predictions, and in the training phrase we know what word we need to generate. \n",
    "- (genre, song title); have a marker that it's the end of the title "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Level LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopChars = [',','(',')','.','-','[',']','\"']\n",
    "# preprocessing the corpus by converting all letters to lowercase, \n",
    "# replacing blank lines with blank string and removing special characters\n",
    "def preprocessText(text):\n",
    "#     text = text.replace('\\n', ' ').replace('\\t','')\n",
    "    processedText = text.lower()\n",
    "    for char in stopChars:\n",
    "        processedText = processedText.replace(char,'')\n",
    "    return processedText\n",
    "\n",
    "# tokenization \n",
    "def corpusToList(corpus):\n",
    "    corpusList = [w for w in corpus.split(' ')] \n",
    "    corpusList = [i for i in corpusList if i] #removing empty strings from list\n",
    "    return corpusList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(genre, sample_size):\n",
    "    random.seed(69)\n",
    "    data1 = data\n",
    "    data1 = data1[data1['genre'] == genre].sample(sample_size)\n",
    "    data1['lyrics'] = data1['lyrics'].astype(str)\n",
    "    data1['lyrics']= data1['lyrics'].apply(preprocessText)\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(data):\n",
    "    newlines = re.sub(\"\\n\", \" \\n \", data['lyrics'].str.cat(sep='\\n').lower())\n",
    "    exclamation = re.sub(\"!\", \" ! \", newlines)\n",
    "    question = re.sub(\"!\", \" ! \", exclamation)\n",
    "    DP_text = re.findall(r'\\S+|\\n', question)\n",
    "    print('corpus length:', len(DP_text))\n",
    "    return(DP_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of characters, see the index of characters.\n",
    "def dictionary_maker(words):\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(words))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(words))\n",
    "    return(char_to_int, int_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentences_and_next_chars(seq_length, DP_text, step):\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "\n",
    "    # Create Target and sentences window\n",
    "    for i in range(0, len(DP_text) - seq_length, step):\n",
    "        # range from current index to sequence length charaters\n",
    "        sentences.append(DP_text[i: i + seq_length])  \n",
    "        next_chars.append(DP_text[i + seq_length]) # the next character\n",
    "    \n",
    "    sentences = np.array(sentences)\n",
    "    next_chars = np.array(next_chars)\n",
    "    return(sentences, next_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 6)\n",
      "['Metal']\n"
     ]
    }
   ],
   "source": [
    "rap_data = sample_data('Metal', 6000)\n",
    "print(rap_data.shape)\n",
    "print(rap_data.genre.unique())\n",
    "#pop_data = sample_data('pop', 2000)\n",
    "#country_data = sample_data('country', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 1350235\n"
     ]
    }
   ],
   "source": [
    "DP_rap = tokenize_data(rap_data)\n",
    "#DP_pop = tokenize_data(pop_data)\n",
    "#DP_country = tokenize_data(country_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting characters appeared in all lyrics\n",
    "rap_words = sorted(list(set(DP_rap)))\n",
    "#pop_words = sorted(list(set(DP_pop)))\n",
    "#country_words = sorted(list(set(DP_country)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rap_char_to_int, rap_int_to_char = dictionary_maker(rap_words)\n",
    "#pop_char_to_int, pop_int_to_char = dictionary_maker(pop_words)\n",
    "#country_char_to_int, country_int_to_char = dictionary_maker(country_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rap_sentences, rap_next_chars = make_sentences_and_next_chars(16, DP_rap, 1)\n",
    "#pop_sentences, pop_next_chars = make_sentences_and_next_chars(16, DP_pop, 1)\n",
    "#country_sentences, country_next_chars = make_sentences_and_next_chars(16, DP_country, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transferring the character to index \n",
    "def getdata(sentences, next_chars, seq_length, char_to_int):\n",
    "    X = np.zeros((len(sentences),seq_length))\n",
    "    y = np.zeros((len(sentences)))\n",
    "    length = len(sentences)\n",
    "    index = 0\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t] = char_to_int[char]\n",
    "        y[i] = char_to_int[next_chars[i]]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple_LSTM(nn.Module):\n",
    "    def __init__(self,n_vocab,hidden_dim, embedding_dim,dropout = 0.2):\n",
    "        super(Simple_LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,dropout = dropout,num_layers = 2)\n",
    "        self.embeddings = nn.Embedding(n_vocab, embedding_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, n_vocab)\n",
    "    \n",
    "    def forward(self, seq_in):\n",
    "        # for LSTM, input should be (Sequnce_length,batchsize,hidden_layer), so we need to transpose the input\n",
    "        embedded = self.embeddings(seq_in.t()) \n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        # Only need to keep the last character \n",
    "        ht=lstm_out[-1] \n",
    "        out = self.fc(ht)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(sentences, next_chars, epoch_count, words, seq_length, char_to_int):\n",
    "    train_x, train_y = getdata(sentences, next_chars, seq_length, char_to_int)\n",
    "    \n",
    "    X_train_tensor = torch.tensor(train_x, dtype=torch.long).to(device)\n",
    "    Y_train_tensor = torch.tensor(train_y, dtype=torch.long).to(device)\n",
    "    \n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    train = torch.utils.data.TensorDataset(X_train_tensor,Y_train_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size = 128)\n",
    "    \n",
    "    model = Simple_LSTM(len(words),256,256).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.002)\n",
    "    \n",
    "    import time # Add time counter\n",
    "    avg_losses_f = []\n",
    "    n_epochs = epoch_count\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch: \", epoch)\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        avg_loss = 0.\n",
    "        for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        \n",
    "            y_pred = model(x_batch)\n",
    "        \n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "            avg_loss+= loss.item()/len(train_loader)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time \n",
    "        print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
    "            epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
    "    \n",
    "        avg_losses_f.append(avg_loss)    \n",
    "    \n",
    "    print('All \\t loss={:.4f} \\t '.format(np.average(avg_losses_f)))\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.plot(avg_losses_f)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss value')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch 1/20 \t loss=5.7774 \t time=738.32s\n",
      "Epoch:  1\n",
      "Epoch 2/20 \t loss=5.1786 \t time=751.51s\n",
      "Epoch:  2\n",
      "Epoch 3/20 \t loss=4.9225 \t time=750.91s\n",
      "Epoch:  3\n",
      "Epoch 4/20 \t loss=4.7304 \t time=751.09s\n",
      "Epoch:  4\n",
      "Epoch 5/20 \t loss=4.5862 \t time=750.87s\n",
      "Epoch:  5\n",
      "Epoch 6/20 \t loss=4.4776 \t time=750.49s\n",
      "Epoch:  6\n",
      "Epoch 7/20 \t loss=4.3860 \t time=750.46s\n",
      "Epoch:  7\n",
      "Epoch 8/20 \t loss=4.3077 \t time=750.40s\n",
      "Epoch:  8\n",
      "Epoch 9/20 \t loss=4.2409 \t time=750.00s\n",
      "Epoch:  9\n",
      "Epoch 10/20 \t loss=4.1852 \t time=750.14s\n",
      "Epoch:  10\n",
      "Epoch 11/20 \t loss=4.1374 \t time=749.67s\n",
      "Epoch:  11\n",
      "Epoch 12/20 \t loss=4.0944 \t time=750.08s\n",
      "Epoch:  12\n",
      "Epoch 13/20 \t loss=4.0598 \t time=749.80s\n",
      "Epoch:  13\n",
      "Epoch 14/20 \t loss=4.0259 \t time=749.84s\n",
      "Epoch:  14\n",
      "Epoch 15/20 \t loss=3.9936 \t time=749.33s\n",
      "Epoch:  15\n",
      "Epoch 16/20 \t loss=3.9648 \t time=749.33s\n",
      "Epoch:  16\n",
      "Epoch 17/20 \t loss=3.9423 \t time=748.55s\n",
      "Epoch:  17\n",
      "Epoch 18/20 \t loss=3.9188 \t time=748.63s\n",
      "Epoch:  18\n",
      "Epoch 19/20 \t loss=3.8975 \t time=749.33s\n",
      "Epoch:  19\n",
      "Epoch 20/20 \t loss=3.8778 \t time=748.93s\n",
      "All \t loss=4.3352 \t \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metal done\n"
     ]
    }
   ],
   "source": [
    "metal_model = train_model(rap_sentences, rap_next_chars, 20, rap_words, 16, rap_char_to_int)\n",
    "torch.save(metal_model.state_dict(), 'big_metal_checkpoint.pth')\n",
    "print(\"metal done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pop_model = train_model(pop_sentences, pop_next_chars, 5, pop_words, 16, pop_char_to_int)\n",
    "# print(\"pop done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country_model = train_model(country_sentences, country_next_chars, 5, country_words, 16, country_char_to_int)\n",
    "# print(\"country done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on god i love the blow \n",
      " on god i love the pussy \n",
      " but more already \n",
      " i pull down the way i've got a pink bottle \n",
      " i'd rather go alone \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't sweat me \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't stick around \n",
      " don't address don't try to talk about me \n",
      " i just wanted to be the same \n",
      " it's too late \n",
      " just to make you believe in me \n",
      " \n",
      " i can't wait till i can't be \n",
      " the battle of my dismay \n",
      " \n",
      " ooh \n",
      " crisis of deceit \n",
      " arise \n",
      " tomorrow's angels softly \n",
      " schizophrenic \n",
      " lead: les \n",
      " chorus: \n",
      " tomorrow's handed backwards \n",
      " the end of the darkside \n",
      " flight of the \n",
      " house of the war \n",
      " abide \n",
      " lovely \n",
      " the glistening of the darkside \n",
      " while the world is pink \n",
      " the smell of deceit \n",
      " we'll fit to hide \n",
      " the only thing harder's the heavens \n",
      " for freedom's art and the only son \n",
      " abide with the answers \n",
      " the secret of the darkside \n",
      " to the ancient gods of the damned \n",
      " the undead the occult \n",
      " the ruler of the enchanted dungeon \n",
      " the almighty of the occult ones behind the sky \n",
      " the ones of our roses \n",
      " the universe will be the final angel \n",
      " and the only thing is certain \n",
      " and the wrath of the house \n",
      " flight and destruction \n",
      " sons of dust \n",
      " rule the maiden \n",
      " pandora's ruin the majestic domain \n",
      " pandora's strokes the farts \n",
      " the opera \n",
      " tame the war \n",
      " judas \n",
      " judas \n",
      " devil \n",
      " smoke on the iris opera opera opera \n",
      " no pregnant dismay \n",
      " the damned is the meaning of the sudden son \n",
      " the power of the rear \n",
      " to the next man \n",
      " the future \n",
      " no fear \n",
      " tomorrow's storms\n"
     ]
    }
   ],
   "source": [
    "# Define the start sentence\n",
    "# sentence = 'i read in the news\\nthat the average man\\nplease kis'\n",
    "seq_length = 16\n",
    "char_to_int = rap_char_to_int\n",
    "int_to_char = rap_int_to_char\n",
    "sentence = [\"on\", \"god\", \"i\", \"love\", \"the\", \"blow\", \"\\n\", \"on\", \"god\", \"i\",\n",
    "           \"love\", \"the\", \"pussy\", \"\\n\", \"but\", \"more\"]\n",
    "variance = .5\n",
    "generated = []\n",
    "original = sentence\n",
    "window = sentence\n",
    "\n",
    "for i in range(400):\n",
    "    x = np.zeros((1, seq_length))\n",
    "    for t, char in enumerate(window):\n",
    "        x[0, t] = char_to_int[char] # Change the sentence to index vector shape (1,50)\n",
    "        \n",
    "    x_in = Variable(torch.LongTensor(x).to(device))\n",
    "    pred = metal_model(x_in)\n",
    "    pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
    "    next_index = sample(pred, variance)\n",
    "    next_char = int_to_char[next_index] # index to char\n",
    "\n",
    "    generated = generated + [next_char]\n",
    "    window = window[1:] + [next_char] # Update Window for next char predict\n",
    "    \n",
    "print(\" \".join(original + generated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sentence:  0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sprees'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d94b7a8170ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlyrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlyrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-d94b7a8170ad>\u001b[0m in \u001b[0;36mgenerate_sentence\u001b[0;34m(input_sentences)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Change the sentence to index vector shape (1,50)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mx_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sprees'"
     ]
    }
   ],
   "source": [
    "starters = [[\"i\", \"like\", \"long\", \"walk\", \"on\", \"the\", \"beach\", \"\\n\", \"and\", \"shopping\", \"sprees\", \"in\", \"paris\", \"\\n\", \"i\", \"sometimes\"],\n",
    "[\"it\", \"was\", \"a\", \"dark\", \"day\", \"when\", \"he\", \"died\", \"\\n\", \"my\", \"mom\",  \"had\", \"tears\", \"in\", \"her\", \"eyes\"],\n",
    "[\"yeah\", \"\\n\", \"yeah\", \"\\n\", \"yeah\", \"\\n\", \"this\", \"is\", \"the\", \"way\", \"i\", \"talk\", \"when\", \"i’m\", \"mad\", \"\\n\"],\n",
    "[\"drive\", \"forever\", \"\\n\", \"baby\", \"i\", \"need\", \"your\", \"apples\", \"\\n\", \"free\", \"car\", \"\\n\", \"just\", \"another\", \"a\", \"wild\"],\n",
    "[\"the\", \"way\", \"that\", \"you\", \"love\", \"me\", \"\\n\", \"is\", \"hard\", \"to\", \"explain\", \"\\n\", \"i’m\", \"addicted\", \"to\", \"your\"],\n",
    "[\"love\", \"women\", \"\\n\", \"get\", \"money\", \"\\n\", \"love\", \"women\", \"\\n\", \"get\", \"money\", \"\\n\", \"makes\", \"a\", \"lot\", \"of\"],\n",
    "[\"baby\", \"you\", \"are\", \"crazy\", \"\\n\", \"you\", \"make\", \"no\", \"sense\", \"\\n\", \"talking\", \"to\", \"you\", \"\\n\", \"is\", \"like\"],\n",
    "[\"it’s\", \"been\", \"a\", \"while\", \"since\", \"you\", \"spoke\", \"to\", \"me\", \"\\n\", \"turned\", \"your\", \"head\", \"\\n\", \"cracked\", \"a\"],\n",
    "[\"lies\", \"spreading\", \"round\", \"\\n\", \"that\", \"you've\", \"been\", \"seen\", \"with\", \"him\", \"\\n\", \"guess\", \"i\", \"wasn’t\", \"enough\", \"for\"],\n",
    "[\"i\", \"been\", \"all\", \"over\", \"this\", \"god\", \"damn\", \"town\", \"\\n\", \"under\", \"the\", \"bridges\", \"and\", \"up\", \"in\", \"the\"],\n",
    "[\"oh\", \"oh\", \"oh\", \"\\n\", \"yeah\", \"yeah\", \"yeah\", \"\\n\", \"that’s\", \"what\", \"i’m\", \"talkin\", \"about\", \"\\n\", \"look\", \"at\"],\n",
    "[\"well\", \"i\", \"was\", \"walkin\", \"round\", \"town\", \"with\", \"this\", \"girl\", \"i\", \"knew\", \"\\n\", \"when\", \"a\", \"man\", \"came\"],\n",
    "[\"fire\", \"and\", \"flames\", \"\\n\", \"passing\", \"tongues\", \"once\", \"bright\", \"with\", \"life\", \"\\n\", \"this\", \"is\", \"the\", \"world\", \"as\"],\n",
    "[\"on\", \"god\", \"i\", \"love\", \"the\", \"women\", \"\\n\", \"on\", \"god\", \"i\", \"love\", \"the\", \"blow\", \"\\n\", \"on\", \"god\"],\n",
    "[\"i\", \"can\", \"take\", \"you\", \"to\", \"the\", \"west\", \"coast\", \"best\", \"coast\", \"with\", \"a\", \"slice\", \"of\", \"toast\", \"yeah\"],\n",
    "[\"the\", \"stars\", \"were\", \"golden\", \"\\n\", \"the\", \"sky\", \"was\", \"dark\", \"\\n\", \"it\", \"was\", \"just\", \"you\", \"and\", \"me\"],\n",
    "[\"please\", \"baby\", \"please\", \"\\n\", \"please\", \"baby\", \"please\", \"\\n\", \"the\", \"things\", \"you\", \"do\", \"to\", \"me\", \"\\n\", \"you\"],\n",
    "[\"sweet\", \"adam\", \"\\n\", \"your\", \"tender\", \"touch\", \"\\n\", \"all\", \"i\", \"need\", \"when\", \"the\", \"weather\", \"gets\", \"cold\", \"\\n\"],\n",
    "[\"hello\", \"there\", \"\\n\", \"the\", \"pizza\", \"from\", \"my\", \"nightmare\", \"\\n\", \"the\", \"figure\", \"in\", \"front\", \"of\", \"me\", \"\\n\"],\n",
    "[\"i\", \"like\", \"to\", \"spit\", \"\\n\", \"in\", \"the\", \"morning\", \"when\", \"i’m\", \"done\", \"taking\", \"my\", \"shit\", \"\\n\", \"i\"]]\n",
    "\n",
    "seq_length = 16\n",
    "char_to_int = rap_char_to_int\n",
    "int_to_char = rap_int_to_char\n",
    "\n",
    "def generate_sentence(input_sentences): \n",
    "    starter = [] \n",
    "    generation = [] \n",
    "    \n",
    "    for i in range(len(input_sentences)): \n",
    "        print(\"In sentence: \", i)\n",
    "        variance = .5\n",
    "        generated = []\n",
    "        original = input_sentences[i]\n",
    "        window = input_sentences[i]\n",
    "\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, seq_length))\n",
    "            for t, char in enumerate(window):\n",
    "                x[0, t] = char_to_int[char] # Change the sentence to index vector shape (1,50)\n",
    "\n",
    "            x_in = Variable(torch.LongTensor(x).to(device))\n",
    "            pred = metal_model(x_in)\n",
    "            pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
    "            next_index = sample(pred, variance)\n",
    "            next_char = int_to_char[next_index] # index to char\n",
    "\n",
    "            generated = generated + [next_char]\n",
    "            window = window[1:] + [next_char] # Update Window for next char predict\n",
    "        \n",
    "        starter.append(original) \n",
    "        generation.append(generated)\n",
    "\n",
    "    lyrics = pd.DataFrame({'starter': starter, 'output': generation})\n",
    "    print(lyrics.head())\n",
    "    return lyrics \n",
    "output = generate_sentence(starters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METRIC 1: AVERAGE LINE LENGTH \n",
    "import math\n",
    "def mean(numbers):\n",
    "    return float(sum(numbers)) / max(len(numbers), 1)\n",
    "def single_length_length(output): \n",
    "    newline_count = output.count('\\n')\n",
    "    return round((len(output) - newline_count) / (newline_count + 1), 2)\n",
    "def average_line_length(df): \n",
    "    # (length of the list - # of new lines) / (# new lines + 1 )\n",
    "    result = df['output'].apply(single_length_length).tolist()\n",
    "    return mean(result)\n",
    "\n",
    "# METRIC 2: Word variation: # of Unique words divided by total # of words \n",
    "def variation(output): \n",
    "    line = [value for value in output if value != \"\\n\"]\n",
    "    unique_num = len(list(set(line)))\n",
    "    return unique_num/len(line)\n",
    "def word_variation(df): \n",
    "    result = df['output'].apply(variation).tolist()\n",
    "    return mean(result)\n",
    "\n",
    "# METRIC 3: Genre Word Variation \n",
    "def genre_word_variation(df): \n",
    "    output_list = df['output'].tolist()\n",
    "    return variation(output_list[0])\n",
    "\n",
    "# METRIC 4: % of I vs. You \n",
    "def count_iyou(row): \n",
    "    i_count, you_count = 0,0 \n",
    "    x = 0\n",
    "    while x < len(row):\n",
    "        if x == 0 and row[x] == \"you\": \n",
    "            you_count += 1\n",
    "        if x == 0 and row[x] == \"i\":\n",
    "            i_count += 1 \n",
    "        if x < len(row) - 1: \n",
    "            if row[x] == \"\\n\" and row[x + 1] == \"i\": \n",
    "                i_count += 1 \n",
    "            if row[x] == \"\\n\" and row[x + 1] == \"you\": \n",
    "                you_count += 1\n",
    "        x += 1 \n",
    "\n",
    "    return (i_count - you_count)\n",
    "\n",
    "def i_you(df): \n",
    "    result = df['output'].apply(count_iyou).to_list()\n",
    "    return mean(result)\n",
    "# the more positive, the more i's there are. \n",
    "\n",
    "# METRIC 5: Word reptition \n",
    "# if the word is the same as the one that came before it \n",
    "def count_s(row): \n",
    "    count, x = 0, 0\n",
    "    while x < len(row): \n",
    "        if x < len(row) - 1: \n",
    "            if row[x] == row[x+1]: \n",
    "                count += 1 \n",
    "        x += 1 \n",
    "    return count \n",
    "def count_succession(df): \n",
    "    result = df['output'].apply(count_s).to_list()\n",
    "    return mean(result)\n",
    "\n",
    "# METRIC 1: AVERAGE LINE LENGTH \n",
    "print(average_line_length(output))\n",
    "# METRIC 2: Word variation: # of Unique words divided by total # of words \n",
    "print(word_variation(output))\n",
    "# METRIC 3: Genre Word Variation \n",
    "print(genre_word_variation(output))\n",
    "# METRIC 4: % of I vs. You \n",
    "print(i_you(output))\n",
    "# METRIC 5: Word repetition \n",
    "print(count_succession(output)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(genre, sample_size):\n",
    "    random.seed(69)\n",
    "    data1 = data\n",
    "    data1 = data1[data1['genre'] == genre].sample(sample_size)\n",
    "    data1['lyrics'] = data1['lyrics'].astype(str)\n",
    "    data1['lyrics']= data1['lyrics'].apply(preprocessText)\n",
    "    return data1\n",
    "\n",
    "def tokenize_data(data):\n",
    "    newlines = re.sub(\"\\n\", \" \\n \", data.lower())\n",
    "    exclamation = re.sub(\"!\", \" ! \", newlines)\n",
    "    question = re.sub(\"!\", \" ! \", exclamation)\n",
    "    DP_text = re.findall(r'\\S+|\\n', question)\n",
    "    return(DP_text)\n",
    "\n",
    "r_data = sample_data('Metal', 2000)\n",
    "r_data['output'] = r_data['lyrics'].apply(tokenize_data)\n",
    "\n",
    "# METRIC 1: AVERAGE LINE LENGTH \n",
    "print(average_line_length(r_data))\n",
    "# METRIC 2: Word variation: # of Unique words divided by total # of words \n",
    "print(word_variation(r_data))\n",
    "# METRIC 3: Genre Word Variation \n",
    "print(genre_word_variation(r_data))\n",
    "# METRIC 4: % of I vs. You \n",
    "print(i_you(r_data))\n",
    "# METRIC 5: Word repetition \n",
    "print(count_succession(r_data)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
