{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import random \n",
    "# https://github.com/petrosDemetrakopoulos/RNN-Beatles-lyrics-generator\n",
    "# https://github.com/starry91/Lyric-Generator#2-lyric-generator-based-on-word-level-rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssh -i \"ling380.pem\" ec2-user@ec2-3-21-233-161.us-east-2.compute.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "Country           20115\n",
      "Electronic         7009\n",
      "Folk               5777\n",
      "Hip-Hop           23045\n",
      "Indie              2971\n",
      "Jazz              12247\n",
      "Metal             29418\n",
      "Not Available     17582\n",
      "Other              3985\n",
      "Pop               43211\n",
      "R&B                7704\n",
      "Rap               10105\n",
      "Rock             110690\n",
      "Soul               4069\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Reading in language CSV \n",
    "data = pd.read_csv(\"language-processed-data.csv\")\n",
    "data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
    "data[\"genre\"].replace({\"country\": \"Country\", \"soul\": \"Soul\", \"jazz\":\"Jazz\", \n",
    "                            \"folk\":\"Folk\", \"pop\":\"Pop\", \"metal\":\"Metal\", \"rb\":\"R&B\", \n",
    "                            \"rock\":\"Rock\", \"rap\":\"Rap\"}, inplace=True)\n",
    "print(data.groupby(['genre']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297928, 6)\n",
      "            artist genre            title  \\\n",
      "0  beyonce-knowles   Pop        ego remix   \n",
      "1  beyonce-knowles   Pop     then tell me   \n",
      "2  beyonce-knowles   Pop          honesty   \n",
      "3  beyonce-knowles   Pop  you are my rock   \n",
      "4  beyonce-knowles   Pop    black culture   \n",
      "\n",
      "                                              lyrics  word_num language  \n",
      "0  Oh baby, how you doing?\\nYou know I'm gonna cu...       NaN       en  \n",
      "1  playin' everything so easy,\\nit's like you see...       NaN       en  \n",
      "2  If you search\\nFor tenderness\\nIt isn't hard t...       NaN       en  \n",
      "3  Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...       NaN       en  \n",
      "4  Party the people, the people the party it's po...       NaN       en  \n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User inputs a song title, and how many words they want the song to be. \n",
    "- Network does, for example, 100 predictions, and in the training phrase we know what word we need to generate. \n",
    "- (genre, song title); have a marker that it's the end of the title "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Level LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopChars = [',','(',')','.','-','[',']','\"']\n",
    "# preprocessing the corpus by converting all letters to lowercase, \n",
    "# replacing blank lines with blank string and removing special characters\n",
    "def preprocessText(text):\n",
    "#     text = text.replace('\\n', ' ').replace('\\t','')\n",
    "    processedText = text.lower()\n",
    "    for char in stopChars:\n",
    "        processedText = processedText.replace(char,'')\n",
    "    return processedText\n",
    "\n",
    "# tokenization \n",
    "def corpusToList(corpus):\n",
    "    corpusList = [w for w in corpus.split(' ')] \n",
    "    corpusList = [i for i in corpusList if i] #removing empty strings from list\n",
    "    return corpusList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(genre, sample_size):\n",
    "    random.seed(69)\n",
    "    data1 = data\n",
    "    data1 = data1[data1['genre'] == genre].sample(sample_size)\n",
    "    data1['lyrics'] = data1['lyrics'].astype(str)\n",
    "    data1['lyrics']= data1['lyrics'].apply(preprocessText)\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(data):\n",
    "    newlines = re.sub(\"\\n\", \" \\n \", data['lyrics'].str.cat(sep='\\n').lower())\n",
    "    exclamation = re.sub(\"!\", \" ! \", newlines)\n",
    "    question = re.sub(\"!\", \" ! \", exclamation)\n",
    "    DP_text = re.findall(r'\\S+|\\n', question)\n",
    "    print('corpus length:', len(DP_text))\n",
    "    return(DP_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of characters, see the index of characters.\n",
    "def dictionary_maker(words):\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(words))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(words))\n",
    "    return(char_to_int, int_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentences_and_next_chars(seq_length, DP_text, step):\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "\n",
    "    # Create Target and sentences window\n",
    "    for i in range(0, len(DP_text) - seq_length, step):\n",
    "        # range from current index to sequence length charaters\n",
    "        sentences.append(DP_text[i: i + seq_length])  \n",
    "        next_chars.append(DP_text[i + seq_length]) # the next character\n",
    "    \n",
    "    sentences = np.array(sentences)\n",
    "    next_chars = np.array(next_chars)\n",
    "    return(sentences, next_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 6)\n",
      "['Rap']\n"
     ]
    }
   ],
   "source": [
    "rap_data = sample_data('Rap', 6000)\n",
    "print(rap_data.shape)\n",
    "print(rap_data.genre.unique())\n",
    "#pop_data = sample_data('pop', 2000)\n",
    "#country_data = sample_data('country', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 1247643\n"
     ]
    }
   ],
   "source": [
    "DP_rap = tokenize_data(rap_data)\n",
    "#DP_pop = tokenize_data(pop_data)\n",
    "#DP_country = tokenize_data(country_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting characters appeared in all lyrics\n",
    "rap_words = sorted(list(set(DP_rap)))\n",
    "#pop_words = sorted(list(set(DP_pop)))\n",
    "#country_words = sorted(list(set(DP_country)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rap_char_to_int, rap_int_to_char = dictionary_maker(rap_words)\n",
    "#pop_char_to_int, pop_int_to_char = dictionary_maker(pop_words)\n",
    "#country_char_to_int, country_int_to_char = dictionary_maker(country_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rap_sentences, rap_next_chars = make_sentences_and_next_chars(16, DP_rap, 1)\n",
    "#pop_sentences, pop_next_chars = make_sentences_and_next_chars(16, DP_pop, 1)\n",
    "#country_sentences, country_next_chars = make_sentences_and_next_chars(16, DP_country, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transferring the character to index \n",
    "def getdata(sentences, next_chars, seq_length, char_to_int):\n",
    "    X = np.zeros((len(sentences),seq_length))\n",
    "    y = np.zeros((len(sentences)))\n",
    "    length = len(sentences)\n",
    "    index = 0\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t] = char_to_int[char]\n",
    "        y[i] = char_to_int[next_chars[i]]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple_LSTM(nn.Module):\n",
    "    def __init__(self,n_vocab,hidden_dim, embedding_dim,dropout = 0.2):\n",
    "        super(Simple_LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,dropout = dropout,num_layers = 2)\n",
    "        self.embeddings = nn.Embedding(n_vocab, embedding_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, n_vocab)\n",
    "    \n",
    "    def forward(self, seq_in):\n",
    "        # for LSTM, input should be (Sequnce_length,batchsize,hidden_layer), so we need to transpose the input\n",
    "        embedded = self.embeddings(seq_in.t()) \n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        # Only need to keep the last character \n",
    "        ht=lstm_out[-1] \n",
    "        out = self.fc(ht)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(sentences, next_chars, epoch_count, words, seq_length, char_to_int):\n",
    "    train_x, train_y = getdata(sentences, next_chars, seq_length, char_to_int)\n",
    "    \n",
    "    X_train_tensor = torch.tensor(train_x, dtype=torch.long).to(device)\n",
    "    Y_train_tensor = torch.tensor(train_y, dtype=torch.long).to(device)\n",
    "    \n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    train = torch.utils.data.TensorDataset(X_train_tensor,Y_train_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size = 128)\n",
    "    \n",
    "    model = Simple_LSTM(len(words),256,256).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.002)\n",
    "    \n",
    "    import time # Add time counter\n",
    "    avg_losses_f = []\n",
    "    n_epochs = epoch_count\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch: \", epoch)\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        avg_loss = 0.\n",
    "        for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        \n",
    "            y_pred = model(x_batch)\n",
    "        \n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "            avg_loss+= loss.item()/len(train_loader)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time \n",
    "        print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
    "            epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
    "    \n",
    "        avg_losses_f.append(avg_loss)    \n",
    "    \n",
    "    print('All \\t loss={:.4f} \\t '.format(np.average(avg_losses_f)))\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.plot(avg_losses_f)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss value')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch 1/20 \t loss=5.8501 \t time=1151.07s\n",
      "Epoch:  1\n",
      "Epoch 2/20 \t loss=5.2660 \t time=959.73s\n",
      "Epoch:  2\n",
      "Epoch 3/20 \t loss=4.9967 \t time=909.78s\n",
      "Epoch:  3\n",
      "Epoch 4/20 \t loss=4.7839 \t time=490.92s\n",
      "Epoch:  4\n",
      "Epoch 5/20 \t loss=4.6181 \t time=353.17s\n",
      "Epoch:  5\n",
      "Epoch 6/20 \t loss=4.4886 \t time=353.46s\n",
      "Epoch:  6\n",
      "Epoch 7/20 \t loss=4.3898 \t time=353.51s\n",
      "Epoch:  7\n",
      "Epoch 8/20 \t loss=4.3045 \t time=353.38s\n",
      "Epoch:  8\n",
      "Epoch 9/20 \t loss=4.2351 \t time=353.17s\n",
      "Epoch:  9\n",
      "Epoch 10/20 \t loss=4.1779 \t time=353.17s\n",
      "Epoch:  10\n",
      "Epoch 11/20 \t loss=4.1292 \t time=353.20s\n",
      "Epoch:  11\n",
      "Epoch 12/20 \t loss=4.0862 \t time=378.37s\n",
      "Epoch:  12\n",
      "Epoch 13/20 \t loss=4.0497 \t time=383.34s\n",
      "Epoch:  13\n",
      "Epoch 14/20 \t loss=4.0152 \t time=375.41s\n",
      "Epoch:  14\n",
      "Epoch 15/20 \t loss=3.9837 \t time=352.91s\n",
      "Epoch:  15\n",
      "Epoch 16/20 \t loss=3.9565 \t time=353.15s\n",
      "Epoch:  16\n",
      "Epoch 17/20 \t loss=3.9310 \t time=352.82s\n",
      "Epoch:  17\n",
      "Epoch 18/20 \t loss=3.9071 \t time=353.00s\n",
      "Epoch:  18\n",
      "Epoch 19/20 \t loss=3.8860 \t time=352.97s\n",
      "Epoch:  19\n",
      "Epoch 20/20 \t loss=3.8679 \t time=353.20s\n",
      "All \t loss=4.3462 \t \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxV9Z3/8dcnG4FASEIu+w5BERXBlKIsrnUXtdNFR1urdhirjradttN5dEZb2/7aTjfHahe7uLR1aZ261LqiVsQ9yCoohEVWSUIgECD75/fHPcHbcAM3kHvPTfJ+Ph7nce/9nu/J+XBI8sl3Od9j7o6IiEhbGWEHICIi6UkJQkRE4lKCEBGRuJQgREQkLiUIERGJKyvsADpTcXGxjx49OuwwRES6jIULF1a5eyTevm6VIEaPHk1ZWVnYYYiIdBlm9n57+9TFJCIicSlBiIhIXEoQIiISlxKEiIjEpQQhIiJxKUGIiEhcShAiIhJXj08QdY3N/OqlNSxYXRV2KCIiaaXHJ4iczAzumr+WhxduDDsUEZG00uMTREaGMaukmAXlVbS06OFJIiKtenyCAJhVEqGqtoEVW3eFHYqISNpQggBmlRQD8LLGIURE9lOCAAbm53L04H68vLoy7FBERNKGEkRg9oQIZet3sLehKexQRETSghJEYHZJhIbmFt5YWx12KCIiaSGpz4Mws/XAbqAZaHL30jb7vwpcHhPLRCDi7tWHOrazlY4uJDc7g5dWVXLa0QOTeSoRkS4hFQ8MOs3d447+uvsPgR8CmNmFwJfcvTqRYztbbnYmHx0zQOMQIiKBdOpiugx4IMwAZpUUs6ZyD5t37gszDBGRtJDsBOHAs2a20MzmtlfJzPoA5wD/dxjHzjWzMjMrq6w8sr/+Z0+IPpb15VVqRYiIJDtBzHD3qcC5wPVmNrudehcCr7TpXkroWHe/y91L3b00Eon73O2ElQzsy+D8XN0PISJCkhOEu28JXiuAR4Bp7VS9lDbdSx04ttOYfbjsRrOW3RCRHi5pCcLM8sysX+t74CxgeZx6/YFTgMc6emwyzJ4QoWZfI0s37UzF6URE0lYyZzENAh4xs9bz3O/uT5vZtQDu/sug3iXAs+6+51DHJjHW/WaML8YsuuzGlJGFqTiliEhaSlqCcPe1wOQ45b9s8/ke4J5Ejk2ForwcjhvWn/mrKrnxjJIwQhARSQvpNM01bcwuibBo40521TWGHYqISGiUIOKYVVJMc4vzavn2sEMREQmNEkQcU0cVkpeTqbuqRaRHU4KIIzszg5PGFet+CBHp0ZQg2jF7QjEbqveyvmrPoSuLiHRDShDtmF0SLLuhbiYR6aGUINoxakAfRhT15qVV6mYSkZ5JCaIdZsbskgivramisbkl7HBERFJOCeIgZpVE2NPQzKINWnZDRHoeJYiDOHn8ADIzjPla/ltEeiAliIPIz81myogCDVSLSI+kBHEIs0oiLN1cQ/WehrBDERFJKSWIQ5g9oRh3eKVcs5lEpGdRgjiE44cXkJ+bpW4mEelxlCAOITPDmFlSzPxVVbjrKXMi0nMoQSRgdkmED3bVUV5RG3YoIiIpk9QEYWbrzWyZmS02s7I4+081s5pg/2Izuzlm3zlm9p6ZlZvZ15MZ56HMmhBdduMlTXcVkR4kmY8cbXWaux9shPdld78gtsDMMoE7gY8Bm4C3zOxxd1+RxDjbNaygN+Mieby8uorPzxobRggiIimXrl1M04Byd1/r7g3Ag8BFYQY0qyTCG+u2U9fYHGYYIiIpk+wE4cCzZrbQzOa2U+ckM1tiZk+Z2aSgbBiwMabOpqDsAGY218zKzKyssjJ5XUCzJxRT19hC2fodSTuHiEg6SXaCmOHuU4FzgevNbHab/W8Do9x9MvAz4NGg3OJ8rbhTiNz9LncvdffSSCTSWXEfYPrYAWRnmqa7ikiPkdQE4e5bgtcK4BGiXUex+3e5e23w/kkg28yKibYYRsRUHQ5sSWash9InJ4vSUUUaqBaRHiNpCcLM8sysX+t74CxgeZs6g83MgvfTgni2A28BJWY2xsxygEuBx5MVa6JmT4jw7ge7qdhVF3YoIiJJl8wWxCBggZktAd4E/ubuT5vZtWZ2bVDnE8DyoM7twKUe1QTcADwDrAT+5O7vJDHWhMwqKQZggZbdEJEeIGnTXN19LTA5TvkvY97fAdzRzvFPAk8mK77DccyQfIr75jB/VSUfnzo87HBERJIqXae5pqWMDGPm+GIWlFfR0qJlN0Ske1OC6KBZJRGqahtYsXVX2KGIiCSVEkQHtY5DvLxa4xAi0r0pQXTQwPxcjh7cT48hFZFuTwniMJwyIULZ+9XsbWgKOxQRkaRRgjgMs0oiNDY7b6ytDjsUEZGkUYI4DKWjC8nNztBd1SLSrSlBHIbc7Ew+OmaA1mUSkW5NCeIwzSopZk3lHjbv3Bd2KCIiSaEEcZhOCZ4y97K6mUSkm1KCOEzjB/ZlcH6u7ocQkW5LCeIwmRmzSqLLbjRr2Q0R6YaUII7A7AkRavY1snTTzrBDERHpdEoQR2Dm+GLMYP4qdTOJSPejBHEECvNyOH5Yf013FZFuSQniCM0qibBo40521TWGHYqISKdKaoIws/VmtszMFptZWZz9l5vZ0mB71cwmJ3psuphVUkxzi/Nq+fawQxER6VRJe6JcjNPcvb1O+nXAKe6+w8zOBe4CPprgsWlh6qhC+uVm8fDCjZxz7OCwwxER6TShdjG5+6vuviP4+DrQ5Z7jmZ2ZwfWnjWfeygpefK8i7HBERDpNshOEA8+a2UIzm3uIutcAT3X0WDOba2ZlZlZWWRnOYPHVM8YwNpLHtx5/h/qm5lBiEBHpbMlOEDPcfSpwLnC9mc2OV8nMTiOaIP6jo8e6+13uXurupZFIpJPDT0xOVgbfmjOJ9dv38uv5a0OJQUSksyU1Qbj7luC1AngEmNa2jpkdD/wGuMjdt3fk2HQyqyTCuccO5o4Xy7WAn4h0C0lLEGaWZ2b9Wt8DZwHL29QZCfwF+Iy7r+rIsenovy44BoDvPLEi5EhERI5cMlsQg4AFZrYEeBP4m7s/bWbXmtm1QZ2bgQHAz9tMZ417bBJj7RTDCnpzw2njeWr5B7p5TkS6PHPvPgvNlZaWellZuLdM1Dc1c/ZP55ORYTx902xysnQvooikLzNb6O6l8fbpt1cn65WVyS1zJrG2cg+/e2Vd2OGIiBw2JYgkOO2ogZw5cRC3P7+arTUasBaRrkkJIkluufAYmluc7/5tZdihiIgcFiWIJBlR1IcvnDqOJ5Zu5dU1ab1aiIhIXEoQSXTtKeMYUdSbWx57h8bmlrDDERHpECWIJMrNzuTmCyaxuqKWe19dH3Y4IiIdogSRZGdOHMhpR0W4bd5qKnbVhR2OiEjClCCSzMy45cJJNDS18L2n3g07HBGRhClBpMDo4jz+9ZSxPLJoM2+uqw47HBGRhBwyQZjZBDN73syWB5+PN7P/Sn5o3ct1p45nWEFvbn5sOU0asBaRLiCRFsSvgf8EGgHcfSlwaTKD6o5652Ty3xdM5N0PdvP7198POxwRkUNKJEH0cfc325Q1JSOY7u7sSYOZVVLMT55dReXu+rDDERE5qEQSRJWZjSP6hDfM7BPA1qRG1U2ZGd+cM4m6pmZ+8LQGrEUkvSWSIK4HfgUcbWabgS8CX0hqVN3YuEhfrpk5locXbmLh+zsOfYCISEgOmSDcfa27nwlEgKPdfaa7r096ZN3Yv50+niH9c7n5seU0t3Sf5dZFpHvJOlQFM7u5zWcA3P3WJMXU7eX1yuIb50/khvsXcf+bG/jM9FFhhyQicoBEupj2xGzNwLnA6ES+uJmtN7NlbZ4WF7vfzOx2Mys3s6VmNjVm35VmtjrYrkzoX9OFnH/cEE4eN4AfPfMe1Xsawg5HROQAiXQx/Thm+y5wKjCsA+c4zd1PaOeJRecCJcE2F/gFgJkVAbcAHwWmAbeYWWEHzpn2zIxvzZnEnvom/kcD1iKShg7nTuo+wNhOOv9FwH0e9TpQYGZDgLOB59y92t13AM8B53TSOdNGyaB+XDVjNA+VbWTxxp1hhyMi8g8SuZN6WdD9s9TM3gHeA/43wa/vwLNmttDM5sbZPwzYGPN5U1DWXnm8+OaaWZmZlVVWViYYVvq46cwJDOzXiy//aTG19bq9RETSRyItiAuAC4PtLGCou9+R4Nef4e5TiXYlXW9ms9vstzjH+EHKDyx0v8vdS929NBKJJBhW+ujbK4vbPj2F9VV7+MYjy3DXrCYRSQ/tJggzKwrGAnbHbPuA/KD8kNx9S/BaATxCdDwh1iZgRMzn4cCWg5R3SyeNG8CXPzaBxxZv4YE3Nx76ABGRFDhYC2IhUBa8tt0OmJHUlpnlmVm/1vdEWx/L21R7HPhsMJtpOlDj7luBZ4CzzKwwGJw+Kyjrtq47dTyzJ0T45l/f4Z0tNWGHIyLSfoJw9zHuPjZ4bbslMkg9CFhgZkuAN4G/ufvTZnatmV0b1HkSWAuUE10U8Lrg3NXAt4G3gu3WoKzbysgwfvqpyRT1yeH6P77N7rrGsEMSkR7OEunzDv6KLwFyW8vcfX4S4zospaWlXlZ2yMZNWntrfTWX3vU650wazB3/PGX/jYkiIslgZgvbuQ0hoVlMnwfmE+3i+Vbw+s3ODFA+9JHRRXzlrKP427KtWhZcREKVyCymm4CPAO+7+2nAFKDrzSftQv519lhOP3og33liJcs2aTxCRMKRSIKoc/c6ADPr5e7vAkclN6yeLSPD+PEnJ1PcN4fr7l9IzT6NR4hI6iWSIDaZWQHwKPCcmT1GN55ymi4K83K44/KpbN1Zx9ceXqL7I0Qk5RJZi+kSd9/p7t8E/hv4LXBxsgMTmDqykK+fezTPvLON372yPuxwRKSHSWSQ+n/N7GQAd3/J3R93dy0/miLXzBzDx44ZxPeeXMmiDXrAkIikTiJdTG8D/xUsyf1DM4s7HUqSw8z40ScmM7h/Ljfcv4ide5WbRSQ1EuliutfdzyO6TMYq4Admtjrpkcl+/ftkc+c/T6Vidx1f+bPGI0QkNTqy3Pd44GiiDwvSAwxSbPKIAr5x3kTmrazg1y+vDTscEekBEhmDaG0x3Ep0LaUT3f3CpEcmB7jy5NGcd9xgfvD0e5St79Yrj4hIGkikBbEOOMndz3H3u91dT7YJiZnx/X86nuGFvbnh/kV6VKmIJFUiYxC/dPeqVAQjh5afGx2PqN7TwJceWkxLi8YjRCQ5DueRoxKyY4f1578vPIaXVlXyi5fWhB2OiHRTShBd1BUfHckFxw/hx8++xxtrt4cdjoh0Q4kMUo8zs17B+1PN7MZg6Q0JUet4xOgBefzbA4uoqq0POyQR6WYSaUH8H9BsZuOJLrMxBrg/qVFJQvr2yuLOy6dSs6+Rf7mvjNr6prBDEpFuJJEE0eLuTcAlwG3u/iVgSKInMLNMM1tkZk/E2fdTM1scbKvMbGfMvuaYfY8ner6eZuKQfG6/bApLN9Vw9d1vsbdBSUJEOkciCaLRzC4DrgRaf8lnd+AcNwEr4+1w9y+5+wnufgLwM+AvMbv3te5z9zkdOF+Pc/akwdz26RMoe7+af7mvjLrG5rBDEpFuIJEEcRVwEvBdd19nZmOAPyTyxc1sOHA+8JsEql8GPJDI15UDXTh5KD/65GReXbOda/+wkPomJQkROTKJ3Aexwt1vdPcHgmdT93P37yf49W8Dvga0HKySmY0iOrbxQkxxrpmVmdnrZtbu8uJmNjeoV1ZZ2bMfdPfxqcP53iXH8ff3Krnh/kU0Nh/0souIHFQis5j+bmb5ZlYELAHuNrOfJHDcBUCFuy9MII5LgYfdPfbP3pHBg7T/GbjNzMbFO9Dd73L3UncvjUQiCZyqe7t02khuvWgSz63YxhcfXEyTkoSIHKZEupj6u/su4OPA3e5+InBmAsfNAOaY2XrgQeB0M2uva+pS2nQvufuW4HUt8Heiz8KWBHz2pNH81/kT+duyrXz14aU0625rETkMiSSILDMbAnyKDwepD8nd/9Pdh7v7aKIJ4AV3v6JtPTM7CigEXospK4y596KYaLJZkei5BT4/ayxfPfsoHlm0mW88skxLcohIh2UlUOdW4BngFXd/y8zGAof9PAgzuxUoc/fWqauXAQ/6Pz7kYCLwKzNrIZrEvu/uShAddP1p46lvbOb2F8rJycrgW3MmYWZhhyUiXYR1p4fPlJaWellZWdhhpBV35/tPvcuv5q/l8zPH8I3zJypJiMh+ZrYwGO89wCFbEMFU1Z8R7eZxYAFwk7tv6tQoJSnMjK+fezT1TS38ZsE6crMz+crZR4Udloh0AYl0Md1NdGmNTwafrwjKPpasoKRzmRm3XHgM9U0t3PFiOb2yMvi3M0rCDktE0lwiCSLi7nfHfL7HzL6YrIAkOcyM7158LA1NLfz4uVXkZGXwr6fEnTksIgIkliCqzOwKPpyGehmg9aW7oIwM438+cTwNzS1876l3ycnK4KoZY8IOS0TSVCIJ4mrgDuCnRMcgXiW6/IZ0QZkZxk8+NZmGpma+9dcV5GRlcPlHR4UdloikoUSW2tjg7nPcPeLuA939YqI3zUkXlZ2Zwc8um8rpRw/kG48s5+GFmm8gIgc63CfKfblTo5CUy8nK4OeXT2Xm+GK+9vAS/ly2MeyQRCTNHG6C0ET6biA3O5Nff7aUk8YN4KsPL+U7T6zQ2k0ist/hJojuc3ddD9c7J5N7rprG504ezW8WrONzd7/Fjj0NYYclImmg3QRhZrvNbFecbTcwNIUxSpJlZ2bwzTmT+J9PHM+b66qZc+cCVm7dFXZYIhKydhOEu/dz9/w4Wz93T2T2k3QxnyodwUP/Op2GphY+/vNXeXLZ1rBDEpEQHW4Xk3RTU0YW8tcbZjJxSD+u++Pb/PCZd7VcuEgPpQQhBxiYn8sDc6dz6UdGcOeLa/j8vW9Rs68x7LBEJMWUICSuXlmZfO/jx/Hti4/l5dVVXHLnK5RX7A47LBFJISUIaZeZ8Znpo7j/X6azq66Ri+98ledWbAs7LBFJESUIOaRpY4p4/IaZjCnO41/uK+N/563WE+pEeoCkJwgzyzSzRWZ2wONKzexzZlZpZouD7fMx+640s9XBdmWy45SDG1rQmz9fexKXTBnGT+et4gt/XEhtfVPYYYlIEqWiBXETsPIg+x9y9xOC7TcAZlYE3AJ8FJgG3GJmhckPVQ4mNzuTn3xqMv99wTHMW1nBJXe+wvqqPWGHJSJJktQEETyN7nzgNx089GzgOXevdvcdwHPAOZ0dn3ScmXHNzDHcd/U0KmvrmXPHAl5aVRl2WCKSBMluQdwGfA042AI//2RmS83sYTMbEZQNA2JXj9sUlB3AzOaaWZmZlVVW6hdVqswYX8xfb5jJ0ILeXHX3m/zk2feoa2wOOywR6URJSxBmdgFQ4e4LD1Ltr8Bodz8emAfc23p4nLpxR0Xd/S53L3X30kgkckQxS8eMKOrDX647mYtOGMbtL5Rz7v++zILVVWGHJSKdJJktiBnAHDNbDzwInG5mf4it4O7b3b0++Phr4MTg/SZgREzV4cCWJMYqh6lPThY//fQJ3Hf1NNydK377Bjc+sIiK3XVhhyYiRyhpCcLd/9Pdh7v7aOBS4AV3vyK2jpkNifk4hw8Hs58BzjKzwmBw+qygTNLU7AkRnv7ibG46o4Snl3/AGT96ifteW69lOkS6sJTfB2Fmt5rZnODjjWb2jpktAW4EPgfg7tXAt4G3gu3WoEzSWG52Jl/62ASe/uIsJo8o4ObH3uGSn7/Csk01YYcmIofB3LvPX3ilpaVeVlYWdhgCuDt/XbqVbz+xgu219Xxm+ij+/eyjyM/NDjs0EYlhZgvdvTTePt1JLUlhZsyZPJTn//0UPjN9FPe9/j5n/PglHl+yhe70R4lId6YEIUmVn5vNty46lseun8Hg/FxufGARn/ntm6zTDXYiaU8JQlLi+OEFPHr9DG69aBJLNu7k7Nvmc9u8Vbp3QiSNKUFIymRmGJ89aTTP//spnDNpMLfNW805t83n5dW6wVEkHSlBSMoNzM/l9sum8IdrPhpdUvy3b3Lt7xdSXlEbdmgiEkMJQkIzs6SYp26axb9/bAIvr67krJ++xH88vJQtO/eFHZqIoGmukia219Zz54tr+MPr74PBlSeN4rpTx1OYlxN2aCLd2sGmuSpBSFrZtGMvt81bzV/e3kReThZzZ4/l6pljyOuVFXZoIt2SEoR0Oau27eZHz7zHsyu2Udw3h387vYTLpo0kJ0u9oiKdSTfKSZczYVA/7vpsKX+57mTGRfpyy+PvcMZP/s4jizZpfSeRFFGCkLQ2dWQhD86dzr1XTyM/N5svPbSE829/medXbtMd2SJJpgQhac/MOGVChL/eMJOfXTaFusZmrrm3jE/+8jXeWq81HEWSRQlCuoyMDOPCyUN57sun8N1LjmVD9V4++cvXuPqet7RirEgSaJBauqx9Dc3c8+p6fvH3cnbVNVE6qpCrZozh7EmDyMrU3z4iidAsJunWdtU18ueyTdz76no2VO9lSP9cPnPSKC77yEjdRyFyCEoQ0iM0tzgvvFvBPa+u45Xy7eRmZ3DJlGF87uQxHDW4X9jhiaSlUBOEmWUCZcBmd7+gzb4vA58HmoBK4Gp3fz/Y1wwsC6pucPc5HIIShLR674Pd3PPqOv7y9mbqm1o4edwArpoxhtOPHkhmhoUdnkjaCDtBfBkoBfLjJIjTgDfcfa+ZfQE41d0/Heyrdfe+HTmXEoS0tWNPAw++tZHfv7aeLTV1jCzqw2dPGsWnPjJCT7cTIcQb5cxsOHA+8Jt4+939RXffG3x8HRiezHik5ynMy+ELp45j/tdO4+eXT2VQfi++87eVTP9/z3PzY8tZU6kVZEXak+wFbm4DvgYk0gF8DfBUzOdcMysj2v30fXd/NN5BZjYXmAswcuTII4tWuq2szAzOO24I5x03hOWba7j7lfU8+OZG7nvtfU6ZEOGK6aM4ZUJES3mIxEhaF5OZXQCc5+7XmdmpwFfadjHF1L0CuAE4xd3rg7Kh7r7FzMYCLwBnuPuag51TXUzSEZW763ngzQ38/vX3qdxdT0GfbM4/bggXTxnGiSMLydBYhfQAoYxBmNn3gM8QbQHkAvnAX9z9ijb1zgR+RjQ5VLTzte4BnnD3hw92TiUIORyNzS28vLqSRxdt4dkVH1DX2MKwgt5cdMJQLp4yjAmDNANKuq/Qp7m214IwsynAw8A57r46prwQ2Ovu9WZWDLwGXOTuKw52HiUIOVJ76pt4dsUHPLpoCwvKq2hucY4Zks/FU4YyZ/IwBvfPDTtEkU6VVgnCzG4Fytz9cTObBxwHbA2qbnD3OWZ2MvAroIXoQPpt7v7bQ51HCUI6U+Xuep5YuoVHF29hycadmMH0MQO4eMpQzjl2CP17axaUdH2hJ4hUUYKQZFlXtYfHFm/mscVbWFe1h5ysDE4/aiAXTxnKaUcPpFdWZtghihwWJQiRTuLuLN1Uw6OLN/PXJVuoqm2gX24WZx0zmI8dM5BZJRE9/U66FCUIkSRoam7hlTXbeWzRZuat3MauuiZyMjM4efwAzpg4iDMnDmRI/95hhylyUEoQIknW2NxC2fodzFu5jXkrt/H+9uj9n5OG5nPmxEF87JhBTBqaj5mmzkp6UYIQSSF3Z01lLc+tqGDeym28vWEH7jA4P5czJg7kzImDOGncAHKzNW4h4VOCEAlRVW09L75bwfMrK5i/upK9Dc30yclkVkkxZ0wcxOlHD6S4b6+ww5QeSglCJE3UNTbz2trtPL9yG/NWVPDBrjrM4PjhBcwaX8yM8cVMHVWgWVGSMkoQImnI3Xlnyy7mrdzG/FWVLNlUQ3OL0zs7k2ljipg5vpiZJcUcPbifxi4kaZQgRLqAXXWNvL5mO6+UV/FyeRVrK/cAUNw3hxlB62Lm+GKGFmhmlHSegyUITdgWSRP5udmcNWkwZ00aDMCWnft4pbyKBeVVvFJexWOLtwAwNpIXbV2ML2b6uAF6roUkjVoQIl2Au/Pett0sWB1NGG+srWZfYzOZGcbk4f2ZPnYApaMLmTqykII+eg63JE5dTCLdTH1TM4s27Ix2R62uYtnm6PgFwPiBfTlxZCEnji7kxFGFjC3O0xiGtEsJQqSb29vQxNJNNSx8f8f+rWZfIwCFfbKZ2powRhZy/PACeudolpREaQxCpJvrk5PF9LEDmD52AAAtLc7aqtr9yaLs/R08/270cStZGcakYf2jrYxRhZSOLmRQvpYxlwOpBSHSQ1TvaWDRhg8TxpKNO6lvagFgaP9cThhZwAkjCjhhRCHHDeuvVkYPoRaEiFCUl8MZEwdxxsRBADQ0tbBy6y7K3t/Bog07WLxxJ08u+wCAzAzjqEH99ieNKSMKGBfpq8ew9jBqQYjIfpW761mycSeLg23Jxp3srm8CoF+vLI4f0Z8TRhQweXgBJ4wsYGA/dU11daEOUptZJlAGbI7zyNFewH3AicB24NPuvj7Y95/ANUAzcKO7P3OocylBiHSu6FjGniBhRFsZ727dTVMwY2pYQe9owhjRn2OH9mfSsP560l4XE3YX003ASiA/zr5rgB3uPt7MLgV+AHzazI4BLgUmAUOBeWY2wd2bUxCviAQyMozxA/syfmBfPnHicCC6ntTyzTUs3riTRRt3snjDTv62bOv+Y0YW9eHYYfkcOyyaNI4d1p+iPN2b0RUlNUGY2XDgfOC7wJfjVLkI+Gbw/mHgDotO2L4IeNDd64F1ZlYOTANeS2a8InJoudmZlI4uonR00f6y6j0NLN9cw/ItNbyzeRfLNtfsH8+A6CD4scP6B1s0eah7Kv0luwVxG/A1oF87+4cBGwHcvcnMaoABQfnrMfU2BWUHMLO5wFyAkSNHdk7UItIhRXk5zJ4QYfaEyP6ymr2NvLO1Jpo4Nu9i+ZYanlu5jdZe7YH9egWtjHyOGZrPhEH9GDUgj0wNhKeNpCUIM7sAqHD3hWZ2anvV4pT5QcoPLHS/C7gLomMQhxGqiCRB/z7ZnDyumJPHFe8vq61vYsWWXUHSiLY4/v5eBcGQBjlZGYyL9D8rFQEAAApISURBVOWoQX0pGdSPowb1Y8Kgfgwv7K0ZVCFIZgtiBjDHzM4DcoF8M/uDu18RU2cTMALYZGZZQH+gOqa81XBgSxJjFZEU6Nsri2ljipg25sPuqb0NTazeVsuqbbtZXVHLex/s5s111Ty6+MMf+d7ZmZQM6kvJwH5MGNSXCYOjiWNo/1wtI5JEKZnmGrQgvhJnFtP1wHHufm0wSP1xd/+UmU0C7ic67jAUeB4oOdQgtWYxiXQfu+oaWb2tltXbdvPett37k0jF7vr9dfr2ygoSR3QgfVwk+jq8sI+6qhIU9iymtsHcCpS5++PAb4HfB4PQ1URnLuHu75jZn4AVQBNwvWYwifQs+bnZnDgquhxIrJ17G1gVJIvW7YV3K/hT2ab9dXKyMhhbnMe4SF/GDezLuEge4wf2ZWxxX90h3gG6UU5EuoWdextYU1nLmoo9lFfWsqailvLKWjZW790/xgHRezdiWxvjInmMG9iXAXk5PbK7Kq1aECIiyVDQJ4cTRxVx4qiifyiva2xm/fY90cRRUcuaylrKK2p5Y9126hpb9tfLz81iTKQvY4vzGBOzjY3k0SenZ/6q7Jn/ahHpMXKzMzl6cD5HD/7He3VbWpzNO/dRXlnLuso9rKuKbm+s3c4jizb/Q93B+bnRhBHJ259Axkb6MrywN9mZGan856SUEoSI9EgZGcaIoj6MKOrDaUf94759DdFWR2vSWFu5h3VVtTy1bCs79jbur5eVYYws6sPo4jxGFPbe//VGBq99e3XtX7FdO3oRkSTonZPJxCH5TBxy4ApBO/Y0sLaqNXnUBq97eWtd9f6FDVsV5eXsTxwjY5NHYR+GFOSmfetDCUJEpAMK83I4MS/ngNlV7k7NvkY2VO9lQ/VeNlbvY0P1Xjbt2MuyzTU8vfyD/YscQnRJ9SH9cxlZ1Ifhhb0Z0r83Qwty/+E1L+QWiBKEiEgnMDMK+uRQ0CeH44cXHLC/qbmFD3bVRZNGkDw2VO9l4469vPheJZUx93e0ys/NYmhBbwb3DxJH/1yGFHz4OqR/LrnZyZu2qwQhIpICWZkZDC/sw/DCPjDuwP0NTS1s21XHlp372FpTx5aafWzdWcfWmujnpZtqqN7TcMBxRXk5jIvk8edrT+78mDv9K4qISIflZGXsH+RuT11jM1tr6ti6cx9bYl7bWaruiClBiIh0EbnZmfvvz0iF9B5CFxGR0ChBiIhIXEoQIiISlxKEiIjEpQQhIiJxKUGIiEhcShAiIhKXEoSIiMTVrZ4oZ2aVwPuHeXgxUNWJ4XQ2xXdkFN+RUXxHJp3jG+XukXg7ulWCOBJmVtbeY/fSgeI7MorvyCi+I5Pu8bVHXUwiIhKXEoSIiMSlBPGhu8IO4BAU35FRfEdG8R2ZdI8vLo1BiIhIXGpBiIhIXEoQIiISV49LEGZ2jpm9Z2blZvb1OPt7mdlDwf43zGx0CmMbYWYvmtlKM3vHzG6KU+dUM6sxs8XBdnOq4gvOv97MlgXnLouz38zs9uD6LTWzqSmM7aiY67LYzHaZ2Rfb1Enp9TOz35lZhZktjykrMrPnzGx18FrYzrFXBnVWm9mVKYzvh2b2bvD/94iZHfiAZQ79vZDE+L5pZptj/g/Pa+fYg/6sJzG+h2JiW29mi9s5NunX74i5e4/ZgExgDTAWyAGWAMe0qXMd8Mvg/aXAQymMbwgwNXjfD1gVJ75TgSdCvIbrgeKD7D8PeAowYDrwRoj/1x8QvQkotOsHzAamAstjyv4H+Hrw/uvAD+IcVwSsDV4Lg/eFKYrvLCAreP+DePEl8r2QxPi+CXwlgf//g/6sJyu+Nvt/DNwc1vU70q2ntSCmAeXuvtbdG4AHgYva1LkIuDd4/zBwhplZKoJz963u/nbwfjewEhiWinN3oouA+zzqdaDAzIaEEMcZwBp3P9w76zuFu88HqtsUx36P3QtcHOfQs4Hn3L3a3XcAzwHnpCI+d3/W3ZuCj68Dwzv7vIlq5/olIpGf9SN2sPiC3xufAh7o7POmSk9LEMOAjTGfN3HgL+D9dYIfkhpgQEqiixF0bU0B3oiz+yQzW2JmT5nZpJQGFn06+rNmttDM5sbZn8g1ToVLaf8HM8zrBzDI3bdC9I8CYGCcOulyHa8m2iKM51DfC8l0Q9AF9rt2uujS4frNAra5++p29od5/RLS0xJEvJZA23m+idRJKjPrC/wf8EV339Vm99tEu00mAz8DHk1lbMAMd58KnAtcb2az2+xPh+uXA8wB/hxnd9jXL1HpcB2/ATQBf2ynyqG+F5LlF8A44ARgK9FunLZCv37AZRy89RDW9UtYT0sQm4ARMZ+HA1vaq2NmWUB/Dq+Je1jMLJtocviju/+l7X533+XutcH7J4FsMytOVXzuviV4rQAeIdqUj5XINU62c4G33X1b2x1hX7/AttZut+C1Ik6dUK9jMCh+AXC5Bx3mbSXwvZAU7r7N3ZvdvQX4dTvnDfv6ZQEfBx5qr05Y168jelqCeAsoMbMxwV+ZlwKPt6nzONA6Y+QTwAvt/YB0tqDP8rfASnf/STt1BreOiZjZNKL/h9tTFF+emfVrfU90MHN5m2qPA58NZjNNB2pau1NSqN2/3MK8fjFiv8euBB6LU+cZ4CwzKwy6UM4KypLOzM4B/gOY4+5726mTyPdCsuKLHdO6pJ3zJvKznkxnAu+6+6Z4O8O8fh0S9ih5qjeis2xWEZ3h8I2g7FaiPwwAuUS7JsqBN4GxKYxtJtFm8FJgcbCdB1wLXBvUuQF4h+isjNeBk1MY39jgvEuCGFqvX2x8BtwZXN9lQGmK/3/7EP2F3z+mLLTrRzRRbQUaif5Vew3RMa3ngdXBa1FQtxT4TcyxVwffh+XAVSmMr5xo/33r92DrrL6hwJMH+15IUXy/D763lhL9pT+kbXzB5wN+1lMRX1B+T+v3XEzdlF+/I9201IaIiMTV07qYREQkQUoQIiISlxKEiIjEpQQhIiJxKUGIiEhcShAiHWBmzW1WjO20VULNbHTsqqAiYcsKOwCRLmafu58QdhAiqaAWhEgnCNb2/4GZvRls44PyUWb2fLCw3PNmNjIoHxQ8a2FJsJ0cfKlMM/u1RZ8H8qyZ9Q7tHyU9nhKESMf0btPF9OmYfbvcfRpwB3BbUHYH0eXPjye66N3tQfntwEseXTRwKtG7aQFKgDvdfRKwE/inJP97RNqlO6lFOsDMat29b5zy9cDp7r42WHDxA3cfYGZVRJeCaAzKt7p7sZlVAsPdvT7ma4wm+gyIkuDzfwDZ7v6d5P/LRA6kFoRI5/F23rdXJ576mPfNaJxQQqQEIdJ5Ph3z+lrw/lWiK4kCXA4sCN4/D3wBwMwyzSw/VUGKJEp/nYh0TO82D6F/2t1bp7r2MrM3iP7hdVlQdiPwOzP7KlAJXBWU3wTcZWbXEG0pfIHoqqAiaUNjECKdIBiDKHX3qrBjEeks6mISEZG41IIQEZG41IIQEZG4lCBERCQuJQgREYlLCUJEROJSghARkbj+P4iIGknwI1SlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rap done\n"
     ]
    }
   ],
   "source": [
    "rap_model = train_model(rap_sentences, rap_next_chars, 20, rap_words, 16, rap_char_to_int)\n",
    "torch.save(rap_model.state_dict(), 'rap_checkpoint.pth')\n",
    "print(\"rap done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pop_model = train_model(pop_sentences, pop_next_chars, 5, pop_words, 16, pop_char_to_int)\n",
    "# print(\"pop done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country_model = train_model(country_sentences, country_next_chars, 5, country_words, 16, country_char_to_int)\n",
    "# print(\"country done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on god i love the blow \n",
      " on god i love the pussy \n",
      " but more all night on the line \n",
      " i was born for dinner and kindness she said she need me \n",
      " i just might be a fan but her butt \n",
      " i never lie i don't need no company no no \n",
      " i can't get no shorts no more no more no more no more no more no more \n",
      " i got a show for the dough in the rental \n",
      " and i'm hurting in the studio i can't fuck with no friends \n",
      " i can't fuck with no relationship no license \n",
      " i can't stop no more no more rhyming no more no more \n",
      " i ain't worried 'bout literally \n",
      " ugh champ \n",
      " \n",
      " show me how you do it when i was tourin' \n",
      " \n",
      " i pulled out the mall with that k pole \n",
      " i swear to god damn hatin' and violent glowin' to the bank \n",
      " and you'll get caught in the trap and it's a good time \n",
      " and if you was dreamin' is erykah nothing's \n",
      " i got task in the buildin' i'm a menace \n",
      " i was raised with that bitch she said “you me \n",
      " i don't know how to do this shit for you \n",
      " i love you momma \n",
      " i do that i love you momma throught ! \n",
      " \n",
      " i just got a whole lotta problems yeah yeah yeah \n",
      " \n",
      " i got a whole lotta lil' nigga \n",
      " pull up on a kid pull up on my side \n",
      " pull up on me pull up on pull up pull up pull up pull up pull up ferrari pull up pull up ferrari \n",
      " pull up pull up on 'em pull up pull up pull up pull up pull up pull up pull up ferrari \n",
      " pull up on a lil' somethin' bae slatt \n",
      " i pull up and air it out pull up \n",
      " pull up on the wave we don't get no more ! \n",
      " \n",
      " \n",
      " canibus? yes you can \n",
      " canibus? ! \n",
      " canibus? yes ! \n",
      " \n",
      " canibus? yes you can ! ! \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " dom whoa \n",
      " sensual seduction whoa \n",
      " sensual seduction \n",
      " sensual seduction \n",
      " sensual seduction \n",
      " sensual seduction \n",
      " sensual seduction \n",
      " sensual seduction \n",
      " sensual seduction \n",
      " sensual seduction whoa \n",
      " sensual seduction \n",
      " sensual seduction \n",
      " sensual seduction \n",
      " sensual seduction whoa whoa whoa whoa\n"
     ]
    }
   ],
   "source": [
    "# Define the start sentence\n",
    "# sentence = 'i read in the news\\nthat the average man\\nplease kis'\n",
    "seq_length = 16\n",
    "char_to_int = rap_char_to_int\n",
    "int_to_char = rap_int_to_char\n",
    "sentence = [\"on\", \"god\", \"i\", \"love\", \"the\", \"blow\", \"\\n\", \"on\", \"god\", \"i\",\n",
    "           \"love\", \"the\", \"pussy\", \"\\n\", \"but\", \"more\"]\n",
    "variance = .5\n",
    "generated = []\n",
    "original = sentence\n",
    "window = sentence\n",
    "\n",
    "for i in range(400):\n",
    "    x = np.zeros((1, seq_length))\n",
    "    for t, char in enumerate(window):\n",
    "        x[0, t] = char_to_int[char] # Change the sentence to index vector shape (1,50)\n",
    "        \n",
    "    x_in = Variable(torch.LongTensor(x).to(device))\n",
    "    pred = rap_model(x_in)\n",
    "    pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
    "    next_index = sample(pred, variance)\n",
    "    next_char = int_to_char[next_index] # index to char\n",
    "\n",
    "    generated = generated + [next_char]\n",
    "    window = window[1:] + [next_char] # Update Window for next char predict\n",
    "    \n",
    "print(\" \".join(original + generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sentence:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sentence:  1\n",
      "In sentence:  2\n",
      "In sentence:  3\n",
      "In sentence:  4\n",
      "In sentence:  5\n",
      "In sentence:  6\n",
      "In sentence:  7\n",
      "In sentence:  8\n",
      "In sentence:  9\n",
      "In sentence:  10\n",
      "In sentence:  11\n",
      "In sentence:  12\n",
      "In sentence:  13\n",
      "In sentence:  14\n",
      "In sentence:  15\n",
      "In sentence:  16\n",
      "In sentence:  17\n",
      "In sentence:  18\n",
      "In sentence:  19\n",
      "                                             starter  \\\n",
      "0  [i, like, long, walk, on, the, beach, \\n, and,...   \n",
      "1  [it, was, a, dark, day, when, he, died, \\n, my...   \n",
      "2  [yeah, \\n, yeah, \\n, yeah, \\n, this, is, the, ...   \n",
      "3  [drive, forever, \\n, baby, i, need, your, hear...   \n",
      "4  [the, way, that, you, love, me, \\n, is, hard, ...   \n",
      "\n",
      "                                              output  \n",
      "0  [the, weather, \\n, negative, hopin, undergroun...  \n",
      "1  [and, i'm, violent, \\n, i, got, a, bitch, in, ...  \n",
      "2  [i, got, a, pole, on, the, firearm, i'm, a, st...  \n",
      "3  [merry, prison, \\n, unlock, the, mic, and, wak...  \n",
      "4  [violent, \\n, and, every, day, every, week, ev...  \n"
     ]
    }
   ],
   "source": [
    "starters = [[\"i\", \"like\", \"long\", \"walk\", \"on\", \"the\", \"beach\", \"\\n\", \"and\", \"shopping\", \"runs\", \"in\", \"paris\", \"\\n\", \"i\", \"sometimes\"],\n",
    "[\"it\", \"was\", \"a\", \"dark\", \"day\", \"when\", \"he\", \"died\", \"\\n\", \"my\", \"mom\",  \"had\", \"tears\", \"in\", \"her\", \"eyes\"],\n",
    "[\"yeah\", \"\\n\", \"yeah\", \"\\n\", \"yeah\", \"\\n\", \"this\", \"is\", \"the\", \"way\", \"i\", \"talk\", \"when\", \"i’m\", \"mad\", \"\\n\"],\n",
    "[\"drive\", \"forever\", \"\\n\", \"baby\", \"i\", \"need\", \"your\", \"heart\", \"\\n\", \"free\", \"car\", \"\\n\", \"just\", \"another\", \"a\", \"wild\"],\n",
    "[\"the\", \"way\", \"that\", \"you\", \"love\", \"me\", \"\\n\", \"is\", \"hard\", \"to\", \"explain\", \"\\n\", \"i’m\", \"addicted\", \"to\", \"your\"],\n",
    "[\"love\", \"women\", \"\\n\", \"get\", \"money\", \"\\n\", \"love\", \"women\", \"\\n\", \"get\", \"money\", \"\\n\", \"makes\", \"a\", \"lot\", \"of\"],\n",
    "[\"baby\", \"you\", \"are\", \"crazy\", \"\\n\", \"you\", \"make\", \"no\", \"sense\", \"\\n\", \"talking\", \"to\", \"you\", \"\\n\", \"is\", \"like\"],\n",
    "[\"it’s\", \"been\", \"a\", \"while\", \"since\", \"you\", \"spoke\", \"to\", \"me\", \"\\n\", \"turned\", \"your\", \"head\", \"\\n\", \"cracked\", \"a\"],\n",
    "[\"lies\", \"spreading\", \"round\", \"\\n\", \"that\", \"you've\", \"been\", \"seen\", \"with\", \"him\", \"\\n\", \"guess\", \"i\", \"wasn’t\", \"enough\", \"for\"],\n",
    "[\"i\", \"been\", \"all\", \"over\", \"this\", \"god\", \"damn\", \"town\", \"\\n\", \"under\", \"the\", \"bridges\", \"and\", \"up\", \"in\", \"the\"],\n",
    "[\"oh\", \"oh\", \"oh\", \"\\n\", \"yeah\", \"yeah\", \"yeah\", \"\\n\", \"that’s\", \"what\", \"i’m\", \"talkin\", \"about\", \"\\n\", \"look\", \"at\"],\n",
    "[\"well\", \"i\", \"was\", \"walking\", \"round\", \"town\", \"with\", \"this\", \"girl\", \"i\", \"knew\", \"\\n\", \"when\", \"a\", \"man\", \"came\"],\n",
    "[\"fire\", \"and\", \"flames\", \"\\n\", \"passing\", \"tongues\", \"once\", \"bright\", \"with\", \"life\", \"\\n\", \"this\", \"is\", \"the\", \"world\", \"as\"],\n",
    "[\"on\", \"god\", \"i\", \"love\", \"the\", \"women\", \"\\n\", \"on\", \"god\", \"i\", \"love\", \"the\", \"blow\", \"\\n\", \"on\", \"god\"],\n",
    "[\"i\", \"can\", \"take\", \"you\", \"to\", \"the\", \"west\", \"coast\", \"best\", \"coast\", \"with\", \"a\", \"slice\", \"of\", \"toast\", \"yeah\"],\n",
    "[\"the\", \"stars\", \"were\", \"golden\", \"\\n\", \"the\", \"sky\", \"was\", \"dark\", \"\\n\", \"it\", \"was\", \"just\", \"you\", \"and\", \"me\"],\n",
    "[\"please\", \"baby\", \"please\", \"\\n\", \"please\", \"baby\", \"please\", \"\\n\", \"the\", \"things\", \"you\", \"do\", \"to\", \"me\", \"\\n\", \"you\"],\n",
    "[\"sweet\", \"adam\", \"\\n\", \"your\", \"tender\", \"touch\", \"\\n\", \"all\", \"i\", \"need\", \"when\", \"the\", \"weather\", \"gets\", \"cold\", \"\\n\"],\n",
    "[\"hello\", \"there\", \"\\n\", \"the\", \"toy\", \"from\", \"my\", \"nightmare\", \"\\n\", \"the\", \"figure\", \"in\", \"front\", \"of\", \"me\", \"\\n\"],\n",
    "[\"i\", \"like\", \"to\", \"spit\", \"\\n\", \"in\", \"the\", \"morning\", \"when\", \"i’m\", \"done\", \"taking\", \"my\", \"shit\", \"\\n\", \"i\"]]\n",
    "\n",
    "seq_length = 16\n",
    "char_to_int = rap_char_to_int\n",
    "int_to_char = rap_int_to_char\n",
    "\n",
    "def generate_sentence(input_sentences): \n",
    "    starter = [] \n",
    "    generation = [] \n",
    "    \n",
    "    for i in range(len(input_sentences)): \n",
    "        print(\"In sentence: \", i)\n",
    "        variance = .5\n",
    "        generated = []\n",
    "        original = input_sentences[i]\n",
    "        window = input_sentences[i]\n",
    "\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, seq_length))\n",
    "            for t, char in enumerate(window):\n",
    "                x[0, t] = char_to_int[char] # Change the sentence to index vector shape (1,50)\n",
    "\n",
    "            x_in = Variable(torch.LongTensor(x).to(device))\n",
    "            pred = rap_model(x_in)\n",
    "            pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
    "            next_index = sample(pred, variance)\n",
    "            next_char = int_to_char[next_index] # index to char\n",
    "\n",
    "            generated = generated + [next_char]\n",
    "            window = window[1:] + [next_char] # Update Window for next char predict\n",
    "        \n",
    "        starter.append(original) \n",
    "        generation.append(generated)\n",
    "\n",
    "    lyrics = pd.DataFrame({'starter': starter, 'output': generation})\n",
    "    print(lyrics.head())\n",
    "    return lyrics \n",
    "output = generate_sentence(starters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.906499999999999\n",
      "0.4041076806973868\n",
      "0.3395061728395062\n",
      "20.5\n",
      "16.85\n"
     ]
    }
   ],
   "source": [
    "# METRIC 1: AVERAGE LINE LENGTH \n",
    "import math\n",
    "def mean(numbers):\n",
    "    return float(sum(numbers)) / max(len(numbers), 1)\n",
    "def single_length_length(output): \n",
    "    newline_count = output.count('\\n')\n",
    "    return round((len(output) - newline_count) / (newline_count + 1), 2)\n",
    "def average_line_length(df): \n",
    "    # (length of the list - # of new lines) / (# new lines + 1 )\n",
    "    result = df['output'].apply(single_length_length).tolist()\n",
    "    return mean(result)\n",
    "\n",
    "# METRIC 2: Word variation: # of Unique words divided by total # of words \n",
    "def variation(output): \n",
    "    line = [value for value in output if value != \"\\n\"]\n",
    "    unique_num = len(list(set(line)))\n",
    "    return unique_num/len(line)\n",
    "def word_variation(df): \n",
    "    result = df['output'].apply(variation).tolist()\n",
    "    return mean(result)\n",
    "\n",
    "# METRIC 3: Genre Word Variation \n",
    "def genre_word_variation(df): \n",
    "    output_list = df['output'].tolist()\n",
    "    return variation(output_list[0])\n",
    "\n",
    "# METRIC 4: % of I vs. You \n",
    "def count_iyou(row): \n",
    "    i_count, you_count = 0,0 \n",
    "    x = 0\n",
    "    while x < len(row):\n",
    "        if x == 0 and row[x] == \"you\": \n",
    "            you_count += 1\n",
    "        if x == 0 and row[x] == \"i\":\n",
    "            i_count += 1 \n",
    "        if x < len(row) - 1: \n",
    "            if row[x] == \"\\n\" and row[x + 1] == \"i\": \n",
    "                i_count += 1 \n",
    "            if row[x] == \"\\n\" and row[x + 1] == \"you\": \n",
    "                you_count += 1\n",
    "        x += 1 \n",
    "\n",
    "    return (i_count - you_count)\n",
    "\n",
    "def i_you(df): \n",
    "    result = df['output'].apply(count_iyou).to_list()\n",
    "    return mean(result)\n",
    "# the more positive, the more i's there are. \n",
    "\n",
    "# METRIC 5: Word reptition \n",
    "# if the word is the same as the one that came before it \n",
    "def count_s(row): \n",
    "    count, x = 0, 0\n",
    "    while x < len(row): \n",
    "        if x < len(row) - 1: \n",
    "            if row[x] == row[x+1]: \n",
    "                count += 1 \n",
    "        x += 1 \n",
    "    return count \n",
    "def count_succession(df): \n",
    "    result = df['output'].apply(count_s).to_list()\n",
    "    return mean(result)\n",
    "\n",
    "# METRIC 1: AVERAGE LINE LENGTH \n",
    "print(average_line_length(output))\n",
    "# METRIC 2: Word variation: # of Unique words divided by total # of words \n",
    "print(word_variation(output))\n",
    "# METRIC 3: Genre Word Variation \n",
    "print(genre_word_variation(output))\n",
    "# METRIC 4: % of I vs. You \n",
    "print(i_you(output))\n",
    "# METRIC 5: Word repetition \n",
    "print(count_succession(output)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       artist genre                   title  \\\n",
      "253987    NaN   Rap              Never Been   \n",
      "247554    NaN   Rap                  Own It   \n",
      "255422    NaN   Rap  Too Deep For The Intro   \n",
      "250399    NaN   Rap         CUDDLE MY WRIST   \n",
      "249502    NaN   Rap                Decimals   \n",
      "\n",
      "                                                   lyrics  word_num language  \\\n",
      "253987  i've been workin' like i've never been\\ni stru...     684.0       en   \n",
      "247554  own it\\nit's yours\\nit's yours\\n\\nyours you're...     530.0       en   \n",
      "255422  partially functional half of me is comfortable...     642.0       en   \n",
      "250399  zaytoven\\ncuddle my wrist cucucuddle my wrist\\...     457.0       en   \n",
      "249502  cjbeatz\\nyeah yeah yeah yeah\\nyeah yeah yeah y...     578.0       en   \n",
      "\n",
      "                                                   output  \n",
      "253987  [i've, been, workin', like, i've, never, been,...  \n",
      "247554  [own, it, \\n, it's, yours, \\n, it's, yours, \\n...  \n",
      "255422  [partially, functional, half, of, me, is, comf...  \n",
      "250399  [zaytoven, \\n, cuddle, my, wrist, cucucuddle, ...  \n",
      "249502  [cjbeatz, \\n, yeah, yeah, yeah, yeah, \\n, yeah...  \n"
     ]
    }
   ],
   "source": [
    "def sample_data(genre, sample_size):\n",
    "    random.seed(69)\n",
    "    data1 = data\n",
    "    data1 = data1[data1['genre'] == genre].sample(sample_size)\n",
    "    data1['lyrics'] = data1['lyrics'].astype(str)\n",
    "    data1['lyrics']= data1['lyrics'].apply(preprocessText)\n",
    "    return data1\n",
    "\n",
    "def tokenize_data(data):\n",
    "    newlines = re.sub(\"\\n\", \" \\n \", data.lower())\n",
    "    exclamation = re.sub(\"!\", \" ! \", newlines)\n",
    "    question = re.sub(\"!\", \" ! \", exclamation)\n",
    "    DP_text = re.findall(r'\\S+|\\n', question)\n",
    "    return(DP_text)\n",
    "\n",
    "r_data = sample_data('Rap', 2000)\n",
    "r_data['output'] = r_data['lyrics'].apply(tokenize_data)\n",
    "\n",
    "# METRIC 1: AVERAGE LINE LENGTH \n",
    "print(average_line_length(r_data))\n",
    "# METRIC 2: Word variation: # of Unique words divided by total # of words \n",
    "print(word_variation(r_data))\n",
    "# METRIC 3: Genre Word Variation \n",
    "print(genre_word_variation(r_data))\n",
    "# METRIC 4: % of I vs. You \n",
    "print(i_you(r_data))\n",
    "# METRIC 5: Word repetition \n",
    "print(count_succession(r_data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.172479999999991\n",
      "0.42391935862860003\n",
      "0.35912408759124087\n",
      "4.7135\n",
      "10.964\n"
     ]
    }
   ],
   "source": [
    "# METRIC 1: AVERAGE LINE LENGTH \n",
    "print(average_line_length(r_data))\n",
    "# METRIC 2: Word variation: # of Unique words divided by total # of words \n",
    "print(word_variation(r_data))\n",
    "# METRIC 3: Genre Word Variation \n",
    "print(genre_word_variation(r_data))\n",
    "# METRIC 4: % of I vs. You \n",
    "print(i_you(r_data))\n",
    "# METRIC 5: Word repetition \n",
    "print(count_succession(r_data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
