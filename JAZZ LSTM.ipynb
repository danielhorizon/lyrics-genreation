{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "# https://github.com/petrosDemetrakopoulos/RNN-Beatles-lyrics-generator\n",
    "# https://github.com/starry91/Lyric-Generator#2-lyric-generator-based-on-word-level-rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssh -i \"ling380.pem\" ec2-user@ec2-3-21-233-161.us-east-2.compute.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "Country           20115\n",
      "Electronic         7009\n",
      "Folk               5777\n",
      "Hip-Hop           23045\n",
      "Indie              2971\n",
      "Jazz              12247\n",
      "Metal             29418\n",
      "Not Available     17582\n",
      "Other              3985\n",
      "Pop               43211\n",
      "R&B                7704\n",
      "Rap               10105\n",
      "Rock             110690\n",
      "Soul               4069\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Reading in language CSV \n",
    "data = pd.read_csv(\"language-processed-data.csv\")\n",
    "data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
    "data[\"genre\"].replace({\"country\": \"Country\", \"soul\": \"Soul\", \"jazz\":\"Jazz\", \n",
    "                            \"folk\":\"Folk\", \"pop\":\"Pop\", \"metal\":\"Metal\", \"rb\":\"R&B\", \n",
    "                            \"rock\":\"Rock\", \"rap\":\"Rap\"}, inplace=True)\n",
    "print(data.groupby(['genre']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297928, 6)\n",
      "            artist genre            title  \\\n",
      "0  beyonce-knowles   Pop        ego remix   \n",
      "1  beyonce-knowles   Pop     then tell me   \n",
      "2  beyonce-knowles   Pop          honesty   \n",
      "3  beyonce-knowles   Pop  you are my rock   \n",
      "4  beyonce-knowles   Pop    black culture   \n",
      "\n",
      "                                              lyrics  word_num language  \n",
      "0  Oh baby, how you doing?\\nYou know I'm gonna cu...       NaN       en  \n",
      "1  playin' everything so easy,\\nit's like you see...       NaN       en  \n",
      "2  If you search\\nFor tenderness\\nIt isn't hard t...       NaN       en  \n",
      "3  Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...       NaN       en  \n",
      "4  Party the people, the people the party it's po...       NaN       en  \n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User inputs a song title, and how many words they want the song to be. \n",
    "- Network does, for example, 100 predictions, and in the training phrase we know what word we need to generate. \n",
    "- (genre, song title); have a marker that it's the end of the title "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Level LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopChars = [',','(',')','.','-','[',']','\"']\n",
    "# preprocessing the corpus by converting all letters to lowercase, \n",
    "# replacing blank lines with blank string and removing special characters\n",
    "def preprocessText(text):\n",
    "#     text = text.replace('\\n', ' ').replace('\\t','')\n",
    "    processedText = text.lower()\n",
    "    for char in stopChars:\n",
    "        processedText = processedText.replace(char,'')\n",
    "    return processedText\n",
    "\n",
    "# tokenization \n",
    "def corpusToList(corpus):\n",
    "    corpusList = [w for w in corpus.split(' ')] \n",
    "    corpusList = [i for i in corpusList if i] #removing empty strings from list\n",
    "    return corpusList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(genre, sample_size):\n",
    "    random.seed(69)\n",
    "    data1 = data\n",
    "    data1 = data1[data1['genre'] == genre].sample(sample_size)\n",
    "    data1['lyrics'] = data1['lyrics'].astype(str)\n",
    "    data1['lyrics']= data1['lyrics'].apply(preprocessText)\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(data):\n",
    "    newlines = re.sub(\"\\n\", \" \\n \", data['lyrics'].str.cat(sep='\\n').lower())\n",
    "    exclamation = re.sub(\"!\", \" ! \", newlines)\n",
    "    question = re.sub(\"!\", \" ! \", exclamation)\n",
    "    DP_text = re.findall(r'\\S+|\\n', question)\n",
    "    print('corpus length:', len(DP_text))\n",
    "    return(DP_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of characters, see the index of characters.\n",
    "def dictionary_maker(words):\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(words))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(words))\n",
    "    return(char_to_int, int_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentences_and_next_chars(seq_length, DP_text, step):\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "\n",
    "    # Create Target and sentences window\n",
    "    for i in range(0, len(DP_text) - seq_length, step):\n",
    "        # range from current index to sequence length charaters\n",
    "        sentences.append(DP_text[i: i + seq_length])  \n",
    "        next_chars.append(DP_text[i + seq_length]) # the next character\n",
    "    \n",
    "    sentences = np.array(sentences)\n",
    "    next_chars = np.array(next_chars)\n",
    "    return(sentences, next_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 6)\n",
      "['Jazz']\n"
     ]
    }
   ],
   "source": [
    "rap_data = sample_data('Jazz', 6000)\n",
    "print(rap_data.shape)\n",
    "print(rap_data.genre.unique())\n",
    "#pop_data = sample_data('pop', 2000)\n",
    "#country_data = sample_data('country', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 1202944\n"
     ]
    }
   ],
   "source": [
    "DP_rap = tokenize_data(rap_data)\n",
    "#DP_pop = tokenize_data(pop_data)\n",
    "#DP_country = tokenize_data(country_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting characters appeared in all lyrics\n",
    "rap_words = sorted(list(set(DP_rap)))\n",
    "#pop_words = sorted(list(set(DP_pop)))\n",
    "#country_words = sorted(list(set(DP_country)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rap_char_to_int, rap_int_to_char = dictionary_maker(rap_words)\n",
    "#pop_char_to_int, pop_int_to_char = dictionary_maker(pop_words)\n",
    "#country_char_to_int, country_int_to_char = dictionary_maker(country_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rap_sentences, rap_next_chars = make_sentences_and_next_chars(16, DP_rap, 1)\n",
    "#pop_sentences, pop_next_chars = make_sentences_and_next_chars(16, DP_pop, 1)\n",
    "#country_sentences, country_next_chars = make_sentences_and_next_chars(16, DP_country, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transferring the character to index \n",
    "def getdata(sentences, next_chars, seq_length, char_to_int):\n",
    "    X = np.zeros((len(sentences),seq_length))\n",
    "    y = np.zeros((len(sentences)))\n",
    "    length = len(sentences)\n",
    "    index = 0\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t] = char_to_int[char]\n",
    "        y[i] = char_to_int[next_chars[i]]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple_LSTM(nn.Module):\n",
    "    def __init__(self,n_vocab,hidden_dim, embedding_dim,dropout = 0.2):\n",
    "        super(Simple_LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,dropout = dropout,num_layers = 2)\n",
    "        self.embeddings = nn.Embedding(n_vocab, embedding_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, n_vocab)\n",
    "    \n",
    "    def forward(self, seq_in):\n",
    "        # for LSTM, input should be (Sequnce_length,batchsize,hidden_layer), so we need to transpose the input\n",
    "        embedded = self.embeddings(seq_in.t()) \n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        # Only need to keep the last character \n",
    "        ht=lstm_out[-1] \n",
    "        out = self.fc(ht)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(sentences, next_chars, epoch_count, words, seq_length, char_to_int):\n",
    "    train_x, train_y = getdata(sentences, next_chars, seq_length, char_to_int)\n",
    "    \n",
    "    X_train_tensor = torch.tensor(train_x, dtype=torch.long).to(device)\n",
    "    Y_train_tensor = torch.tensor(train_y, dtype=torch.long).to(device)\n",
    "    \n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    train = torch.utils.data.TensorDataset(X_train_tensor,Y_train_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size = 128)\n",
    "    \n",
    "    model = Simple_LSTM(len(words),256,256).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.002)\n",
    "    \n",
    "    import time # Add time counter\n",
    "    avg_losses_f = []\n",
    "    n_epochs = epoch_count\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch: \", epoch)\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        avg_loss = 0.\n",
    "        for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        \n",
    "            y_pred = model(x_batch)\n",
    "        \n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "            avg_loss+= loss.item()/len(train_loader)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time \n",
    "        print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
    "            epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
    "    \n",
    "        avg_losses_f.append(avg_loss)    \n",
    "    \n",
    "    print('All \\t loss={:.4f} \\t '.format(np.average(avg_losses_f)))\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.plot(avg_losses_f)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss value')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch 1/20 \t loss=5.3408 \t time=781.55s\n",
      "Epoch:  1\n",
      "Epoch 2/20 \t loss=4.6683 \t time=827.12s\n",
      "Epoch:  2\n",
      "Epoch 3/20 \t loss=4.3452 \t time=827.23s\n",
      "Epoch:  3\n",
      "Epoch 4/20 \t loss=4.1203 \t time=831.36s\n",
      "Epoch:  4\n",
      "Epoch 5/20 \t loss=3.9498 \t time=830.82s\n",
      "Epoch:  5\n",
      "Epoch 6/20 \t loss=3.8238 \t time=830.43s\n",
      "Epoch:  6\n",
      "Epoch 7/20 \t loss=3.7271 \t time=831.51s\n",
      "Epoch:  7\n",
      "Epoch 8/20 \t loss=3.6483 \t time=830.78s\n",
      "Epoch:  8\n",
      "Epoch 9/20 \t loss=3.5856 \t time=830.38s\n",
      "Epoch:  9\n",
      "Epoch 10/20 \t loss=3.5354 \t time=829.96s\n",
      "Epoch:  10\n",
      "Epoch 11/20 \t loss=3.4926 \t time=830.18s\n",
      "Epoch:  11\n",
      "Epoch 12/20 \t loss=3.4513 \t time=829.73s\n",
      "Epoch:  12\n",
      "Epoch 13/20 \t loss=3.4201 \t time=829.49s\n",
      "Epoch:  13\n",
      "Epoch 14/20 \t loss=3.3906 \t time=828.43s\n",
      "Epoch:  14\n",
      "Epoch 15/20 \t loss=3.3631 \t time=829.00s\n",
      "Epoch:  15\n",
      "Epoch 16/20 \t loss=3.3408 \t time=829.27s\n",
      "Epoch:  16\n",
      "Epoch 17/20 \t loss=3.3190 \t time=828.84s\n",
      "Epoch:  17\n",
      "Epoch 18/20 \t loss=3.2987 \t time=829.82s\n",
      "Epoch:  18\n",
      "Epoch 19/20 \t loss=3.2786 \t time=829.98s\n",
      "Epoch:  19\n",
      "Epoch 20/20 \t loss=3.2631 \t time=829.67s\n",
      "All \t loss=3.7181 \t \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jazz done\n"
     ]
    }
   ],
   "source": [
    "jazz_model = train_model(rap_sentences, rap_next_chars, 20, rap_words, 16, rap_char_to_int)\n",
    "torch.save(jazz_model.state_dict(), 'jazz_checkpoint.pth')\n",
    "print(\"jazz done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pop_model = train_model(pop_sentences, pop_next_chars, 5, pop_words, 16, pop_char_to_int)\n",
    "# print(\"pop done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country_model = train_model(country_sentences, country_next_chars, 5, country_words, 16, country_char_to_int)\n",
    "# print(\"country done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on god i love the blow \n",
      " on god i love the pussy \n",
      " but more than a percolator \n",
      " and he didn't know how \n",
      " that was the first thing that i found \n",
      " i can hear that train to hold \n",
      " that pulls it right down \n",
      " oh \n",
      " i can hear the whistle blow by \n",
      " and i can see \n",
      " told me \n",
      " i can't believe \n",
      " that i'll be seeing you \n",
      " to make the world complete \n",
      " you might be a lady \n",
      " i'm gonna brush you \n",
      " `cause i don't know \n",
      " you ain't got no money \n",
      " you got me \n",
      " i ain't comin' back \n",
      " ain't no one \n",
      " no woman ain't no good \n",
      " ain't no good \n",
      " so ill be the man down inside \n",
      " but the power says monday \n",
      " i can't escape that man \n",
      " he says murder \n",
      " he says murder he says murder \n",
      " he says murder he says \n",
      " he says murder he says jackson \n",
      " she pulls my guitar and miriam \n",
      " he says murder he says \n",
      " he says murder he says \n",
      " it was he says neither \n",
      " he says murder \n",
      " he says murder \n",
      " she says murder \n",
      " and he says murder he says \n",
      " and he says murder \n",
      " he says murder \n",
      " he says murder \n",
      " he says murder \n",
      " and he says murder \n",
      " he says murder \n",
      " he says murder \n",
      " and he says murder \n",
      " he says murder he says \n",
      " i know that he was having \n",
      " so he took his smiles her eyes \n",
      " but i can't believe it \n",
      " how many times many ways \n",
      " we'll be growing high \n",
      " a moment that we're dreaming \n",
      " we'll be 10 k hiding roses \n",
      " frank \n",
      " we always knew \n",
      " why we love each other \n",
      " and we found out of the rockies \n",
      " while the band is in \n",
      " and the angels end \n",
      " our favorite sight \n",
      " we see the snow \n",
      " and unto sheep \n",
      " and we will never never meet again \n",
      " oh maiden \n",
      " this is a man's fairytale \n",
      " i know that i can see \n",
      " how he needs me \n",
      " just like a lover's call \n",
      " and i just can't get back \n",
      " i can't stay \n",
      " spending the mornin' \n",
      " a cigarette \n",
      " bears a number of illusion \n",
      " a man's a winner \n",
      " he's a lady \n",
      " he's a\n"
     ]
    }
   ],
   "source": [
    "# Define the start sentence\n",
    "# sentence = 'i read in the news\\nthat the average man\\nplease kis'\n",
    "seq_length = 16\n",
    "char_to_int = rap_char_to_int\n",
    "int_to_char = rap_int_to_char\n",
    "sentence = [\"on\", \"god\", \"i\", \"love\", \"the\", \"blow\", \"\\n\", \"on\", \"god\", \"i\",\n",
    "           \"love\", \"the\", \"pussy\", \"\\n\", \"but\", \"more\"]\n",
    "variance = .5\n",
    "generated = []\n",
    "original = sentence\n",
    "window = sentence\n",
    "\n",
    "for i in range(400):\n",
    "    x = np.zeros((1, seq_length))\n",
    "    for t, char in enumerate(window):\n",
    "        x[0, t] = char_to_int[char] # Change the sentence to index vector shape (1,50)\n",
    "        \n",
    "    x_in = Variable(torch.LongTensor(x).to(device))\n",
    "    pred = jazz_model(x_in)\n",
    "    pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
    "    next_index = sample(pred, variance)\n",
    "    next_char = int_to_char[next_index] # index to char\n",
    "\n",
    "    generated = generated + [next_char]\n",
    "    window = window[1:] + [next_char] # Update Window for next char predict\n",
    "    \n",
    "print(\" \".join(original + generated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sentence:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sentence:  1\n",
      "In sentence:  2\n",
      "In sentence:  3\n",
      "In sentence:  4\n",
      "In sentence:  5\n",
      "In sentence:  6\n",
      "In sentence:  7\n",
      "In sentence:  8\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'wasn’t'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-13fa41801329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlyrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlyrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-13fa41801329>\u001b[0m in \u001b[0;36mgenerate_sentence\u001b[0;34m(input_sentences)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Change the sentence to index vector shape (1,50)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mx_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'wasn’t'"
     ]
    }
   ],
   "source": [
    "starters = [[\"i\", \"like\", \"long\", \"walk\", \"on\", \"the\", \"beach\", \"\\n\", \"and\", \"shopping\", \"runs\", \"in\", \"paris\", \"\\n\", \"i\", \"sometimes\"],\n",
    "[\"it\", \"was\", \"a\", \"dark\", \"day\", \"when\", \"he\", \"died\", \"\\n\", \"my\", \"mom\",  \"had\", \"tears\", \"in\", \"her\", \"eyes\"],\n",
    "[\"yeah\", \"\\n\", \"yeah\", \"\\n\", \"yeah\", \"\\n\", \"this\", \"is\", \"the\", \"way\", \"i\", \"talk\", \"when\", \"i’m\", \"mad\", \"\\n\"],\n",
    "[\"drive\", \"forever\", \"\\n\", \"baby\", \"i\", \"need\", \"your\", \"heart\", \"\\n\", \"free\", \"car\", \"\\n\", \"just\", \"another\", \"a\", \"wild\"],\n",
    "[\"the\", \"way\", \"that\", \"you\", \"love\", \"me\", \"\\n\", \"is\", \"hard\", \"to\", \"explain\", \"\\n\", \"i’m\", \"addicted\", \"to\", \"your\"],\n",
    "[\"love\", \"women\", \"\\n\", \"get\", \"money\", \"\\n\", \"love\", \"women\", \"\\n\", \"get\", \"money\", \"\\n\", \"makes\", \"a\", \"lot\", \"of\"],\n",
    "[\"baby\", \"you\", \"are\", \"crazy\", \"\\n\", \"you\", \"make\", \"no\", \"sense\", \"\\n\", \"talking\", \"to\", \"you\", \"\\n\", \"is\", \"like\"],\n",
    "[\"it’s\", \"been\", \"a\", \"while\", \"since\", \"you\", \"spoke\", \"to\", \"me\", \"\\n\", \"turned\", \"your\", \"head\", \"\\n\", \"cracked\", \"a\"],\n",
    "[\"lies\", \"spreading\", \"round\", \"\\n\", \"that\", \"you've\", \"been\", \"seen\", \"with\", \"him\", \"\\n\", \"guess\", \"i\", \"wasn’t\", \"enough\", \"for\"],\n",
    "[\"i\", \"been\", \"all\", \"over\", \"this\", \"god\", \"damn\", \"town\", \"\\n\", \"under\", \"the\", \"bridges\", \"and\", \"up\", \"in\", \"the\"],\n",
    "[\"oh\", \"oh\", \"oh\", \"\\n\", \"yeah\", \"yeah\", \"yeah\", \"\\n\", \"that’s\", \"what\", \"i’m\", \"talkin\", \"about\", \"\\n\", \"look\", \"at\"],\n",
    "[\"well\", \"i\", \"was\", \"walking\", \"round\", \"town\", \"with\", \"this\", \"girl\", \"i\", \"knew\", \"\\n\", \"when\", \"a\", \"man\", \"came\"],\n",
    "[\"fire\", \"and\", \"flames\", \"\\n\", \"passing\", \"tongues\", \"once\", \"bright\", \"with\", \"life\", \"\\n\", \"this\", \"is\", \"the\", \"world\", \"as\"],\n",
    "[\"on\", \"god\", \"i\", \"love\", \"the\", \"women\", \"\\n\", \"on\", \"god\", \"i\", \"love\", \"the\", \"blow\", \"\\n\", \"on\", \"god\"],\n",
    "[\"i\", \"can\", \"take\", \"you\", \"to\", \"the\", \"west\", \"coast\", \"best\", \"coast\", \"with\", \"a\", \"slice\", \"of\", \"toast\", \"yeah\"],\n",
    "[\"the\", \"stars\", \"were\", \"golden\", \"\\n\", \"the\", \"sky\", \"was\", \"dark\", \"\\n\", \"it\", \"was\", \"just\", \"you\", \"and\", \"me\"],\n",
    "[\"please\", \"baby\", \"please\", \"\\n\", \"please\", \"baby\", \"please\", \"\\n\", \"the\", \"things\", \"you\", \"do\", \"to\", \"me\", \"\\n\", \"you\"],\n",
    "[\"sweet\", \"adam\", \"\\n\", \"your\", \"tender\", \"touch\", \"\\n\", \"all\", \"i\", \"need\", \"when\", \"the\", \"weather\", \"gets\", \"cold\", \"\\n\"],\n",
    "[\"hello\", \"there\", \"\\n\", \"the\", \"toy\", \"from\", \"my\", \"nightmare\", \"\\n\", \"the\", \"figure\", \"in\", \"front\", \"of\", \"me\", \"\\n\"],\n",
    "[\"i\", \"like\", \"to\", \"spit\", \"\\n\", \"in\", \"the\", \"morning\", \"when\", \"i’m\", \"done\", \"taking\", \"my\", \"shit\", \"\\n\", \"i\"]]\n",
    "\n",
    "seq_length = 16\n",
    "char_to_int = rap_char_to_int\n",
    "int_to_char = rap_int_to_char\n",
    "\n",
    "def generate_sentence(input_sentences): \n",
    "    starter = [] \n",
    "    generation = [] \n",
    "    \n",
    "    for i in range(len(input_sentences)): \n",
    "        print(\"In sentence: \", i)\n",
    "        variance = .5\n",
    "        generated = []\n",
    "        original = input_sentences[i]\n",
    "        window = input_sentences[i]\n",
    "\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, seq_length))\n",
    "            for t, char in enumerate(window):\n",
    "                x[0, t] = char_to_int[char] # Change the sentence to index vector shape (1,50)\n",
    "\n",
    "            x_in = Variable(torch.LongTensor(x).to(device))\n",
    "            pred = jazz_model(x_in)\n",
    "            pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
    "            next_index = sample(pred, variance)\n",
    "            next_char = int_to_char[next_index] # index to char\n",
    "\n",
    "            generated = generated + [next_char]\n",
    "            window = window[1:] + [next_char] # Update Window for next char predict\n",
    "        \n",
    "        starter.append(original) \n",
    "        generation.append(generated)\n",
    "\n",
    "    lyrics = pd.DataFrame({'starter': starter, 'output': generation})\n",
    "    print(lyrics.head())\n",
    "    return lyrics \n",
    "output = generate_sentence(starters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METRIC 1: AVERAGE LINE LENGTH \n",
    "import math\n",
    "def mean(numbers):\n",
    "    return float(sum(numbers)) / max(len(numbers), 1)\n",
    "def single_length_length(output): \n",
    "    newline_count = output.count('\\n')\n",
    "    return round((len(output) - newline_count) / (newline_count + 1), 2)\n",
    "def average_line_length(df): \n",
    "    # (length of the list - # of new lines) / (# new lines + 1 )\n",
    "    result = df['output'].apply(single_length_length).tolist()\n",
    "    return mean(result)\n",
    "\n",
    "# METRIC 2: Word variation: # of Unique words divided by total # of words \n",
    "def variation(output): \n",
    "    line = [value for value in output if value != \"\\n\"]\n",
    "    unique_num = len(list(set(line)))\n",
    "    return unique_num/len(line)\n",
    "def word_variation(df): \n",
    "    result = df['output'].apply(variation).tolist()\n",
    "    return mean(result)\n",
    "\n",
    "# METRIC 3: Genre Word Variation \n",
    "def genre_word_variation(df): \n",
    "    output_list = df['output'].tolist()\n",
    "    return variation(output_list[0])\n",
    "\n",
    "# METRIC 4: % of I vs. You \n",
    "def count_iyou(row): \n",
    "    i_count, you_count = 0,0 \n",
    "    x = 0\n",
    "    while x < len(row):\n",
    "        if x == 0 and row[x] == \"you\": \n",
    "            you_count += 1\n",
    "        if x == 0 and row[x] == \"i\":\n",
    "            i_count += 1 \n",
    "        if x < len(row) - 1: \n",
    "            if row[x] == \"\\n\" and row[x + 1] == \"i\": \n",
    "                i_count += 1 \n",
    "            if row[x] == \"\\n\" and row[x + 1] == \"you\": \n",
    "                you_count += 1\n",
    "        x += 1 \n",
    "\n",
    "    return (i_count - you_count)\n",
    "\n",
    "def i_you(df): \n",
    "    result = df['output'].apply(count_iyou).to_list()\n",
    "    return mean(result)\n",
    "# the more positive, the more i's there are. \n",
    "\n",
    "# METRIC 5: Word reptition \n",
    "# if the word is the same as the one that came before it \n",
    "def count_s(row): \n",
    "    count, x = 0, 0\n",
    "    while x < len(row): \n",
    "        if x < len(row) - 1: \n",
    "            if row[x] == row[x+1]: \n",
    "                count += 1 \n",
    "        x += 1 \n",
    "    return count \n",
    "def count_succession(df): \n",
    "    result = df['output'].apply(count_s).to_list()\n",
    "    return mean(result)\n",
    "\n",
    "# METRIC 1: AVERAGE LINE LENGTH \n",
    "print(average_line_length(output))\n",
    "# METRIC 2: Word variation: # of Unique words divided by total # of words \n",
    "print(word_variation(output))\n",
    "# METRIC 3: Genre Word Variation \n",
    "print(genre_word_variation(output))\n",
    "# METRIC 4: % of I vs. You \n",
    "print(i_you(output))\n",
    "# METRIC 5: Word repetition \n",
    "print(count_succession(output)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(genre, sample_size):\n",
    "    random.seed(69)\n",
    "    data1 = data\n",
    "    data1 = data1[data1['genre'] == genre].sample(sample_size)\n",
    "    data1['lyrics'] = data1['lyrics'].astype(str)\n",
    "    data1['lyrics']= data1['lyrics'].apply(preprocessText)\n",
    "    return data1\n",
    "\n",
    "def tokenize_data(data):\n",
    "    newlines = re.sub(\"\\n\", \" \\n \", data.lower())\n",
    "    exclamation = re.sub(\"!\", \" ! \", newlines)\n",
    "    question = re.sub(\"!\", \" ! \", exclamation)\n",
    "    DP_text = re.findall(r'\\S+|\\n', question)\n",
    "    return(DP_text)\n",
    "\n",
    "r_data = sample_data('Jazz', 2000)\n",
    "r_data['output'] = r_data['lyrics'].apply(tokenize_data)\n",
    "\n",
    "# METRIC 1: AVERAGE LINE LENGTH \n",
    "print(average_line_length(r_data))\n",
    "# METRIC 2: Word variation: # of Unique words divided by total # of words \n",
    "print(word_variation(r_data))\n",
    "# METRIC 3: Genre Word Variation \n",
    "print(genre_word_variation(r_data))\n",
    "# METRIC 4: % of I vs. You \n",
    "print(i_you(r_data))\n",
    "# METRIC 5: Word repetition \n",
    "print(count_succession(r_data)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
