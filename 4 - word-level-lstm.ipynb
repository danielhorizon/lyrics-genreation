{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# https://github.com/petrosDemetrakopoulos/RNN-Beatles-lyrics-generator\n",
    "# https://github.com/starry91/Lyric-Generator#2-lyric-generator-based-on-word-level-rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssh -i \"ling380.pem\" ec2-user@ec2-3-21-233-161.us-east-2.compute.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in language CSV \n",
    "data = pd.read_csv(\"language-processed-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290501, 6)\n",
      "   Unnamed: 0           artist genre            title  \\\n",
      "0           0  beyonce-knowles   Pop        ego remix   \n",
      "1           1  beyonce-knowles   Pop     then tell me   \n",
      "2           2  beyonce-knowles   Pop          honesty   \n",
      "3           3  beyonce-knowles   Pop  you are my rock   \n",
      "4           4  beyonce-knowles   Pop    black culture   \n",
      "\n",
      "                                              lyrics language  \n",
      "0  Oh baby, how you doing?\\nYou know I'm gonna cu...       en  \n",
      "1  playin' everything so easy,\\nit's like you see...       en  \n",
      "2  If you search\\nFor tenderness\\nIt isn't hard t...       en  \n",
      "3  Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...       en  \n",
      "4  Party the people, the people the party it's po...       en  \n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User inputs a song title, and how many words they want the song to be. \n",
    "- Network does, for example, 100 predictions, and in the training phrase we know what word we need to generate. \n",
    "- (genre, song title); have a marker that it's the end of the title "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Level LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopChars = [',','(',')','.','-','[',']','\"']\n",
    "# preprocessing the corpus by converting all letters to lowercase, \n",
    "# replacing blank lines with blank string and removing special characters\n",
    "def preprocessText(text):\n",
    "#     text = text.replace('\\n', ' ').replace('\\t','')\n",
    "    processedText = text.lower()\n",
    "    for char in stopChars:\n",
    "        processedText = processedText.replace(char,'')\n",
    "    return processedText\n",
    "\n",
    "# tokenization \n",
    "def corpusToList(corpus):\n",
    "    corpusList = [w for w in corpus.split(' ')] \n",
    "    corpusList = [i for i in corpusList if i] #removing empty strings from list\n",
    "    return corpusList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0          artist    genre                    title  \\\n",
      "43566        67748     eddy-arnold  Country    then i ll be over you   \n",
      "18432        29535   bill-anderson  Country         before i met you   \n",
      "41121        63690  avett-brothers  Country       i and love and you   \n",
      "210452      318639    connie-smith  Country          god is abundant   \n",
      "49794        76742  dierks-bentley  Country  i can only think of one   \n",
      "\n",
      "                                                   lyrics language  \n",
      "43566   when i try to go to sleep and know\\nthat i won...       en  \n",
      "18432   well i thought i had seen good lookin' men in ...       en  \n",
      "41121   load the car and write the note\\ngrab your bag...       en  \n",
      "210452  god is abundant in mercy and love he died to r...       en  \n",
      "49794   pullin' into the fast lane\\non the leavin' sid...       en  \n",
      "(1000, 6)\n"
     ]
    }
   ],
   "source": [
    "data1 = data\n",
    "data1 = data1[data1['genre'] == 'Country'].sample(1000)\n",
    "data1['lyrics']= data1['lyrics'].apply(preprocessText)\n",
    "print(data1.head())\n",
    "print(data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 211784\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "newlines = re.sub(\"\\n\", \" \\n \", data1['lyrics'].str.cat(sep='\\n').lower())\n",
    "exclamation = re.sub(\"!\", \" ! \", newlines)\n",
    "question = re.sub(\"!\", \" ! \", exclamation)\n",
    "DP_text = re.findall(r'\\S+|\\n', question)\n",
    "print('corpus length:', len(DP_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 8835\n"
     ]
    }
   ],
   "source": [
    "# Counting characters appeared in all lyrics\n",
    "words = sorted(list(set(DP_text)))\n",
    "print('total words:', len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of characters, see the index of characters.\n",
    "char_to_int = dict((c, i) for i, c in enumerate(words))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Window\n",
      "[['when' 'i' 'try' 'to' 'go' 'to' 'sleep' 'and' 'know' '\\n']\n",
      " ['i' 'try' 'to' 'go' 'to' 'sleep' 'and' 'know' '\\n' 'that']\n",
      " ['try' 'to' 'go' 'to' 'sleep' 'and' 'know' '\\n' 'that' 'i']\n",
      " ['to' 'go' 'to' 'sleep' 'and' 'know' '\\n' 'that' 'i' \"won't\"]\n",
      " ['go' 'to' 'sleep' 'and' 'know' '\\n' 'that' 'i' \"won't\" 'lie']]\n",
      "Target characters\n",
      "['that' 'i' \"won't\" 'lie' 'awake']\n",
      "Number of sequences: 211774\n"
     ]
    }
   ],
   "source": [
    "seq_length = 10 # The sentence window size\n",
    "step = 1 # The steps between the windows\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "# Create Target and sentences window\n",
    "for i in range(0, len(DP_text) - seq_length, step):\n",
    "    # range from current index to sequence length charaters\n",
    "    sentences.append(DP_text[i: i + seq_length])  \n",
    "    next_chars.append(DP_text[i + seq_length]) # the next character\n",
    "    \n",
    "sentences = np.array(sentences)\n",
    "next_chars = np.array(next_chars)\n",
    "\n",
    "#Print Sentence Window and next charaters\n",
    "print('Sentence Window')\n",
    "print (sentences[:5])\n",
    "print('Target characters')\n",
    "print (next_chars[:5])\n",
    "print('Number of sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transferring the character to index \n",
    "def getdata(sentences, next_chars):\n",
    "    X = np.zeros((len(sentences),seq_length))\n",
    "    y = np.zeros((len(sentences)))\n",
    "    length = len(sentences)\n",
    "    index = 0\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t] = char_to_int[char]\n",
    "        y[i] = char_to_int[next_chars[i]]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8477. 3889. 8053. ...  362. 4291.    0.]\n",
      " [3889. 8053. 7866. ... 4291.    0. 7709.]\n",
      " [8053. 7866. 3261. ...    0. 7709. 3889.]\n",
      " ...\n",
      " [   0. 5227. 3889. ... 1195. 3889. 1262.]\n",
      " [5227. 3889. 1263. ... 3889. 1262.  213.]\n",
      " [3889. 1263. 1753. ... 1262.  213. 7716.]]\n",
      "Shape of training_x: (211774, 10)\n",
      "Shape of training_y: (211774,)\n"
     ]
    }
   ],
   "source": [
    "train_x,train_y = getdata(sentences, next_chars)\n",
    "print(train_x)\n",
    "print('Shape of training_x:', train_x.shape)\n",
    "print('Shape of training_y:', train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Simple_LSTM(nn.Module):\n",
    "    def __init__(self,n_vocab,hidden_dim, embedding_dim,dropout = 0.2):\n",
    "        super(Simple_LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,dropout = dropout,num_layers = 2)\n",
    "        self.embeddings = nn.Embedding(n_vocab, embedding_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, n_vocab)\n",
    "    \n",
    "    def forward(self, seq_in):\n",
    "        # for LSTM, input should be (Sequnce_length,batchsize,hidden_layer), so we need to transpose the input\n",
    "        embedded = self.embeddings(seq_in.t()) \n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        # Only need to keep the last character \n",
    "        ht=lstm_out[-1] \n",
    "        out = self.fc(ht)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training_x: torch.Size([211774, 10])\n",
      "Shape of training_y: torch.Size([211774])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.tensor(train_x, dtype=torch.long)\n",
    "Y_train_tensor = torch.tensor(train_y, dtype=torch.long)\n",
    "print('Shape of training_x:', X_train_tensor.shape)\n",
    "print('Shape of training_y:', Y_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "train = torch.utils.data.TensorDataset(X_train_tensor,Y_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Simple_LSTM(len(words),256,256)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.002) # Using Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-333579d2451d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# checking if we are using cuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;34mr\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m             raise RuntimeError(\n\u001b[1;32m    148\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             raise AssertionError(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# checking if we are using cuda \n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    }
   ],
   "source": [
    "import time # Add time counter\n",
    "avg_losses_f = []\n",
    "n_epochs=30\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    avg_loss = 0.\n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        y_pred = model(x_batch)\n",
    "        \n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        avg_loss+= loss.item()/len(train_loader)\n",
    "        \n",
    "    elapsed_time = time.time() - start_time \n",
    "    print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
    "        epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
    "    \n",
    "    avg_losses_f.append(avg_loss)    \n",
    "    \n",
    "print('All \\t loss={:.4f} \\t '.format(np.average(avg_losses_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(avg_losses_f)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i remember dad walking out that door \n",
      " but i know the power of a song when you would have to try \n",
      " he's not someone from the scene \n",
      " but from the crowd let me rest and dream awhile say be home \n",
      " and shows my lady down the moon \n",
      " he took her off the block take \n",
      " put a little love in your heart each and every love you say \n",
      " id walk in home \n",
      " chorus \n",
      " now just just love that goodbye old friend farewell it took \n",
      " but when you hold me when you punch that way \n",
      " when i know the power of a song \n",
      " when a song hits you right \n",
      " poured my soul into stories of day \n",
      " when i truck on your tombstone \n",
      " one thing that i would \n",
      " do my happiness for me \n",
      " next good love makes you leave \n",
      " raise some hell or hit your knees \n",
      " all i love you and i know why i said \n",
      " i wanna know \n",
      " if i could have you back again \n",
      " time when i don't want \n",
      " goodbye old friend farewell it seems \n",
      " we'll dance again in my dreams \n",
      " goodbye old friend farewell it seems \n",
      " we'll dance again in my dreams \n",
      " goodbye old friend farewell it seems \n",
      " we'll dance again in my dreams \n",
      " goodbye old friend farewell it seems \n",
      " we'll dance again in my dreams \n",
      " goodbye old friend farewell it seems \n",
      " we'll dance again in my dreams \n",
      " goodbye old friend farewell it seems \n",
      " we'll dance again in my dreams \n",
      " goodbye old rig has touched me to go \n",
      " nobody else can you know \n",
      " so please let me rest and more my name and i was on \n",
      " i don't want the money i just want any until the time \n",
      " my head sings and the constellation \n",
      " from now on the year drumbeat \n",
      " the sound of a million dreams \n",
      " straight up strong and steady \n",
      " hard falls i don't take any \n",
      " red lips you'll be leaving \n",
      " goodbye old friend farewell it seems \n",
      " we'll dance again in my dreams \n",
      " goodbye old friend farewell it seems \n",
      " we'll dance again in my dreams \n",
      " goodbye old friend farewell it seems \n",
      " we'll dance again in my dreams \n",
      " goodbye old friend farewell it seems \n",
      " we'll dance again in\n"
     ]
    }
   ],
   "source": [
    "# Define the start sentence\n",
    "# sentence = 'i read in the news\\nthat the average man\\nplease kis'\n",
    "sentence = [\"i\", \"remember\", \"dad\", \"walking\", \"out\", \"that\", \"door\", \"\\n\", \"but\", \"i\"]\n",
    "variance = .5\n",
    "generated = []\n",
    "original = sentence\n",
    "window = sentence\n",
    "\n",
    "for i in range(400):\n",
    "    x = np.zeros((1, seq_length))\n",
    "    for t, char in enumerate(window):\n",
    "        x[0, t] = char_to_int[char] # Change the sentence to index vector shape (1,50)\n",
    "        \n",
    "    x_in = Variable(torch.LongTensor(x))\n",
    "    pred = model(x_in)\n",
    "    pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
    "    next_index = sample(pred, variance)\n",
    "    next_char = int_to_char[next_index] # index to char\n",
    "\n",
    "    generated = generated + [next_char]\n",
    "    window = window[1:] + [next_char] # Update Window for next char predict\n",
    "    \n",
    "print(\" \".join(original + generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
