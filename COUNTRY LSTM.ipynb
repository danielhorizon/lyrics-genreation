{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "# https://github.com/petrosDemetrakopoulos/RNN-Beatles-lyrics-generator\n",
    "# https://github.com/starry91/Lyric-Generator#2-lyric-generator-based-on-word-level-rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssh -i \"ling380.pem\" ec2-user@ec2-3-21-233-161.us-east-2.compute.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "Country           20115\n",
      "Electronic         7009\n",
      "Folk               5777\n",
      "Hip-Hop           23045\n",
      "Indie              2971\n",
      "Jazz              12247\n",
      "Metal             29418\n",
      "Not Available     17582\n",
      "Other              3985\n",
      "Pop               43211\n",
      "R&B                7704\n",
      "Rap               10105\n",
      "Rock             110690\n",
      "Soul               4069\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Reading in language CSV \n",
    "data = pd.read_csv(\"language-processed-data.csv\")\n",
    "data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
    "data[\"genre\"].replace({\"country\": \"Country\", \"soul\": \"Soul\", \"jazz\":\"Jazz\", \n",
    "                            \"folk\":\"Folk\", \"pop\":\"Pop\", \"metal\":\"Metal\", \"rb\":\"R&B\", \n",
    "                            \"rock\":\"Rock\", \"rap\":\"Rap\"}, inplace=True)\n",
    "print(data.groupby(['genre']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297928, 6)\n",
      "            artist genre            title  \\\n",
      "0  beyonce-knowles   Pop        ego remix   \n",
      "1  beyonce-knowles   Pop     then tell me   \n",
      "2  beyonce-knowles   Pop          honesty   \n",
      "3  beyonce-knowles   Pop  you are my rock   \n",
      "4  beyonce-knowles   Pop    black culture   \n",
      "\n",
      "                                              lyrics  word_num language  \n",
      "0  Oh baby, how you doing?\\nYou know I'm gonna cu...       NaN       en  \n",
      "1  playin' everything so easy,\\nit's like you see...       NaN       en  \n",
      "2  If you search\\nFor tenderness\\nIt isn't hard t...       NaN       en  \n",
      "3  Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...       NaN       en  \n",
      "4  Party the people, the people the party it's po...       NaN       en  \n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- User inputs a song title, and how many words they want the song to be. \n",
    "- Network does, for example, 100 predictions, and in the training phrase we know what word we need to generate. \n",
    "- (genre, song title); have a marker that it's the end of the title "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Level LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopChars = [',','(',')','.','-','[',']','\"']\n",
    "# preprocessing the corpus by converting all letters to lowercase, \n",
    "# replacing blank lines with blank string and removing special characters\n",
    "def preprocessText(text):\n",
    "#     text = text.replace('\\n', ' ').replace('\\t','')\n",
    "    processedText = text.lower()\n",
    "    for char in stopChars:\n",
    "        processedText = processedText.replace(char,'')\n",
    "    return processedText\n",
    "\n",
    "# tokenization \n",
    "def corpusToList(corpus):\n",
    "    corpusList = [w for w in corpus.split(' ')] \n",
    "    corpusList = [i for i in corpusList if i] #removing empty strings from list\n",
    "    return corpusList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(genre, sample_size):\n",
    "    random.seed(69)\n",
    "    data1 = data\n",
    "    data1 = data1[data1['genre'] == genre].sample(sample_size)\n",
    "    data1['lyrics'] = data1['lyrics'].astype(str)\n",
    "    data1['lyrics']= data1['lyrics'].apply(preprocessText)\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(data):\n",
    "    newlines = re.sub(\"\\n\", \" \\n \", data['lyrics'].str.cat(sep='\\n').lower())\n",
    "    exclamation = re.sub(\"!\", \" ! \", newlines)\n",
    "    question = re.sub(\"!\", \" ! \", exclamation)\n",
    "    DP_text = re.findall(r'\\S+|\\n', question)\n",
    "    print('corpus length:', len(DP_text))\n",
    "    return(DP_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of characters, see the index of characters.\n",
    "def dictionary_maker(words):\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(words))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(words))\n",
    "    return(char_to_int, int_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentences_and_next_chars(seq_length, DP_text, step):\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "\n",
    "    # Create Target and sentences window\n",
    "    for i in range(0, len(DP_text) - seq_length, step):\n",
    "        # range from current index to sequence length charaters\n",
    "        sentences.append(DP_text[i: i + seq_length])  \n",
    "        next_chars.append(DP_text[i + seq_length]) # the next character\n",
    "    \n",
    "    sentences = np.array(sentences)\n",
    "    next_chars = np.array(next_chars)\n",
    "    return(sentences, next_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 6)\n",
      "['Country']\n"
     ]
    }
   ],
   "source": [
    "rap_data = sample_data('Country', 6000)\n",
    "print(rap_data.shape)\n",
    "print(rap_data.genre.unique())\n",
    "#pop_data = sample_data('pop', 2000)\n",
    "#country_data = sample_data('country', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 1322915\n"
     ]
    }
   ],
   "source": [
    "DP_rap = tokenize_data(rap_data)\n",
    "#DP_pop = tokenize_data(pop_data)\n",
    "#DP_country = tokenize_data(country_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting characters appeared in all lyrics\n",
    "rap_words = sorted(list(set(DP_rap)))\n",
    "#pop_words = sorted(list(set(DP_pop)))\n",
    "#country_words = sorted(list(set(DP_country)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rap_char_to_int, rap_int_to_char = dictionary_maker(rap_words)\n",
    "#pop_char_to_int, pop_int_to_char = dictionary_maker(pop_words)\n",
    "#country_char_to_int, country_int_to_char = dictionary_maker(country_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rap_sentences, rap_next_chars = make_sentences_and_next_chars(16, DP_rap, 1)\n",
    "#pop_sentences, pop_next_chars = make_sentences_and_next_chars(16, DP_pop, 1)\n",
    "#country_sentences, country_next_chars = make_sentences_and_next_chars(16, DP_country, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transferring the character to index \n",
    "def getdata(sentences, next_chars, seq_length, char_to_int):\n",
    "    X = np.zeros((len(sentences),seq_length))\n",
    "    y = np.zeros((len(sentences)))\n",
    "    length = len(sentences)\n",
    "    index = 0\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t] = char_to_int[char]\n",
    "        y[i] = char_to_int[next_chars[i]]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple_LSTM(nn.Module):\n",
    "    def __init__(self,n_vocab,hidden_dim, embedding_dim,dropout = 0.2):\n",
    "        super(Simple_LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,dropout = dropout,num_layers = 2)\n",
    "        self.embeddings = nn.Embedding(n_vocab, embedding_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, n_vocab)\n",
    "    \n",
    "    def forward(self, seq_in):\n",
    "        # for LSTM, input should be (Sequnce_length,batchsize,hidden_layer), so we need to transpose the input\n",
    "        embedded = self.embeddings(seq_in.t()) \n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        # Only need to keep the last character \n",
    "        ht=lstm_out[-1] \n",
    "        out = self.fc(ht)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(sentences, next_chars, epoch_count, words, seq_length, char_to_int):\n",
    "    train_x, train_y = getdata(sentences, next_chars, seq_length, char_to_int)\n",
    "    \n",
    "    X_train_tensor = torch.tensor(train_x, dtype=torch.long).to(device)\n",
    "    Y_train_tensor = torch.tensor(train_y, dtype=torch.long).to(device)\n",
    "    \n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    train = torch.utils.data.TensorDataset(X_train_tensor,Y_train_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size = 128)\n",
    "    \n",
    "    model = Simple_LSTM(len(words),256,256).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.002)\n",
    "    \n",
    "    import time # Add time counter\n",
    "    avg_losses_f = []\n",
    "    n_epochs = epoch_count\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch: \", epoch)\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        avg_loss = 0.\n",
    "        for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        \n",
    "            y_pred = model(x_batch)\n",
    "        \n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "            avg_loss+= loss.item()/len(train_loader)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time \n",
    "        print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
    "            epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
    "    \n",
    "        avg_losses_f.append(avg_loss)    \n",
    "    \n",
    "    print('All \\t loss={:.4f} \\t '.format(np.average(avg_losses_f)))\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.plot(avg_losses_f)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss value')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch 1/20 \t loss=5.3292 \t time=886.26s\n",
      "Epoch:  1\n",
      "Epoch 2/20 \t loss=4.7777 \t time=890.42s\n",
      "Epoch:  2\n",
      "Epoch 3/20 \t loss=4.5453 \t time=892.83s\n",
      "Epoch:  3\n",
      "Epoch 4/20 \t loss=4.3881 \t time=899.44s\n",
      "Epoch:  4\n",
      "Epoch 5/20 \t loss=4.2731 \t time=896.12s\n",
      "Epoch:  5\n",
      "Epoch 6/20 \t loss=4.1825 \t time=897.03s\n",
      "Epoch:  6\n",
      "Epoch 7/20 \t loss=4.1108 \t time=896.70s\n",
      "Epoch:  7\n",
      "Epoch 8/20 \t loss=4.0513 \t time=895.74s\n",
      "Epoch:  8\n",
      "Epoch 9/20 \t loss=4.0030 \t time=895.30s\n",
      "Epoch:  9\n",
      "Epoch 10/20 \t loss=3.9614 \t time=897.43s\n",
      "Epoch:  10\n",
      "Epoch 11/20 \t loss=3.9269 \t time=895.70s\n",
      "Epoch:  11\n",
      "Epoch 12/20 \t loss=3.8976 \t time=895.38s\n",
      "Epoch:  12\n",
      "Epoch 13/20 \t loss=3.8714 \t time=895.13s\n",
      "Epoch:  13\n",
      "Epoch 14/20 \t loss=3.8501 \t time=894.80s\n",
      "Epoch:  14\n",
      "Epoch 15/20 \t loss=3.8310 \t time=894.49s\n",
      "Epoch:  15\n",
      "Epoch 16/20 \t loss=3.8124 \t time=895.64s\n",
      "Epoch:  16\n",
      "Epoch 17/20 \t loss=3.7959 \t time=896.18s\n",
      "Epoch:  17\n",
      "Epoch 18/20 \t loss=3.7790 \t time=896.02s\n",
      "Epoch:  18\n",
      "Epoch 19/20 \t loss=3.7637 \t time=754.03s\n",
      "Epoch:  19\n",
      "Epoch 20/20 \t loss=3.7496 \t time=619.29s\n",
      "All \t loss=4.0950 \t \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country done\n"
     ]
    }
   ],
   "source": [
    "country_model = train_model(rap_sentences, rap_next_chars, 20, rap_words, 16, rap_char_to_int)\n",
    "torch.save(country_model.state_dict(), 'country_checkpoint.pth')\n",
    "print(\"country done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pop_model = train_model(pop_sentences, pop_next_chars, 5, pop_words, 16, pop_char_to_int)\n",
    "# print(\"pop done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country_model = train_model(country_sentences, country_next_chars, 5, country_words, 16, country_char_to_int)\n",
    "# print(\"country done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on god i love the blow \n",
      " on god i love the pussy \n",
      " but more than hank \n",
      " i still want to leave the shirt \n",
      " and i haven't said but i just can't be \n",
      " and just a little longer \n",
      " and i'll show you you want me \n",
      " i know you can't be \n",
      " i can't live without love you \n",
      " and if i could walk away from you \n",
      " i don't know what you're gonna do \n",
      " don't go back to me \n",
      " if you're gonna be \n",
      " if you forget it \n",
      " a heart can always be a redneck love song \n",
      " the happiest day is gone \n",
      " in the midst of a gun we'll be forgotten \n",
      " and all of my worries in my heart \n",
      " with a love song \n",
      " and i can feel like kindness \n",
      " sometimes i \n",
      " i really need you \n",
      " i know it's over \n",
      " and decide i hope you know your love is all my head \n",
      " and the music that i needed \n",
      " you say i was there \n",
      " just like a tree with a constant exhibition \n",
      " i was raised to the barroom \n",
      " and i got a little baby \n",
      " i was born to a mess \n",
      " i was a young little bit of my love \n",
      " i took a little kid \n",
      " i was hoping i was wrong \n",
      " and i had to find myself \n",
      " and i can't say it again \n",
      " i know i love you \n",
      " i know that it's wrong \n",
      " i can't do it with you \n",
      " i don't want to be \n",
      " well i don't know why \n",
      " \n",
      " \n",
      " i don't have to live again \n",
      " \n",
      " and i don't want to care \n",
      " 'cause i can't let the mem'ries \n",
      " only you can blame me \n",
      " i think about you \n",
      " i don't care who i am \n",
      " i want to be happy to let you go \n",
      " 'cause i don't know what to do \n",
      " all the heartaches that i have to be \n",
      " and i guess i love you \n",
      " i can't believe your love is true \n",
      " but i don't want to be alone \n",
      " i can live with you \n",
      " i know it's all right \n",
      " i love you \n",
      " i know you love me \n",
      " i love you forever \n",
      " you're always on my mind \n",
      " and you will be my baby \n",
      " i can't say\n"
     ]
    }
   ],
   "source": [
    "# Define the start sentence\n",
    "# sentence = 'i read in the news\\nthat the average man\\nplease kis'\n",
    "seq_length = 16\n",
    "char_to_int = rap_char_to_int\n",
    "int_to_char = rap_int_to_char\n",
    "sentence = [\"on\", \"god\", \"i\", \"love\", \"the\", \"blow\", \"\\n\", \"on\", \"god\", \"i\",\n",
    "           \"love\", \"the\", \"pussy\", \"\\n\", \"but\", \"more\"]\n",
    "variance = .5\n",
    "generated = []\n",
    "original = sentence\n",
    "window = sentence\n",
    "\n",
    "for i in range(400):\n",
    "    x = np.zeros((1, seq_length))\n",
    "    for t, char in enumerate(window):\n",
    "        x[0, t] = char_to_int[char] # Change the sentence to index vector shape (1,50)\n",
    "        \n",
    "    x_in = Variable(torch.LongTensor(x).to(device))\n",
    "    pred = country_model(x_in)\n",
    "    pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
    "    next_index = sample(pred, variance)\n",
    "    next_char = int_to_char[next_index] # index to char\n",
    "\n",
    "    generated = generated + [next_char]\n",
    "    window = window[1:] + [next_char] # Update Window for next char predict\n",
    "    \n",
    "print(\" \".join(original + generated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sentence:  0\n",
      "In sentence:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sentence:  2\n",
      "In sentence:  3\n",
      "In sentence:  4\n",
      "In sentence:  5\n",
      "In sentence:  6\n",
      "In sentence:  7\n",
      "In sentence:  8\n",
      "In sentence:  9\n",
      "In sentence:  10\n",
      "In sentence:  11\n",
      "In sentence:  12\n",
      "In sentence:  13\n",
      "In sentence:  14\n",
      "In sentence:  15\n",
      "In sentence:  16\n",
      "In sentence:  17\n",
      "In sentence:  18\n",
      "In sentence:  19\n",
      "                                             starter  \\\n",
      "0  [i, like, long, walk, on, the, beach, \\n, and,...   \n",
      "1  [it, was, a, dark, day, when, he, died, \\n, my...   \n",
      "2  [yeah, \\n, yeah, \\n, yeah, \\n, this, is, the, ...   \n",
      "3  [drive, forever, \\n, baby, i, need, your, hear...   \n",
      "4  [the, way, that, you, love, me, \\n, is, hard, ...   \n",
      "\n",
      "                                              output  \n",
      "0  [hope, \\n, i, will, be, your, salty, stone, \\n...  \n",
      "1  [\\n, and, he, was, right, \\n, and, i, was, rai...  \n",
      "2  [and, also, like, a, kick, drum, \\n, the, sky,...  \n",
      "3  [train, \\n, and, i, don't, need, a, thing, \\n,...  \n",
      "4  [love, \\n, will, i, love, you, \\n, and, none, ...  \n"
     ]
    }
   ],
   "source": [
    "starters = [[\"i\", \"like\", \"long\", \"walk\", \"on\", \"the\", \"beach\", \"\\n\", \"and\", \"shopping\", \"runs\", \"in\", \"paris\", \"\\n\", \"i\", \"sometimes\"],\n",
    "[\"it\", \"was\", \"a\", \"dark\", \"day\", \"when\", \"he\", \"died\", \"\\n\", \"my\", \"mom\",  \"had\", \"tears\", \"in\", \"her\", \"eyes\"],\n",
    "[\"yeah\", \"\\n\", \"yeah\", \"\\n\", \"yeah\", \"\\n\", \"this\", \"is\", \"the\", \"way\", \"i\", \"talk\", \"when\", \"i’m\", \"mad\", \"\\n\"],\n",
    "[\"drive\", \"forever\", \"\\n\", \"baby\", \"i\", \"need\", \"your\", \"heart\", \"\\n\", \"free\", \"car\", \"\\n\", \"just\", \"another\", \"a\", \"wild\"],\n",
    "[\"the\", \"way\", \"that\", \"you\", \"love\", \"me\", \"\\n\", \"is\", \"hard\", \"to\", \"explain\", \"\\n\", \"i’m\", \"addicted\", \"to\", \"your\"],\n",
    "[\"love\", \"women\", \"\\n\", \"get\", \"money\", \"\\n\", \"love\", \"women\", \"\\n\", \"get\", \"money\", \"\\n\", \"makes\", \"a\", \"lot\", \"of\"],\n",
    "[\"baby\", \"you\", \"are\", \"crazy\", \"\\n\", \"you\", \"make\", \"no\", \"sense\", \"\\n\", \"talking\", \"to\", \"you\", \"\\n\", \"is\", \"like\"],\n",
    "[\"it’s\", \"been\", \"a\", \"while\", \"since\", \"you\", \"spoke\", \"to\", \"me\", \"\\n\", \"turned\", \"your\", \"head\", \"\\n\", \"cracked\", \"a\"],\n",
    "[\"lies\", \"spreading\", \"round\", \"\\n\", \"that\", \"you've\", \"been\", \"seen\", \"with\", \"him\", \"\\n\", \"guess\", \"i\", \"wasn’t\", \"enough\", \"for\"],\n",
    "[\"i\", \"been\", \"all\", \"over\", \"this\", \"god\", \"damn\", \"town\", \"\\n\", \"under\", \"the\", \"bridges\", \"and\", \"up\", \"in\", \"the\"],\n",
    "[\"oh\", \"oh\", \"oh\", \"\\n\", \"yeah\", \"yeah\", \"yeah\", \"\\n\", \"that’s\", \"what\", \"i’m\", \"talkin\", \"about\", \"\\n\", \"look\", \"at\"],\n",
    "[\"well\", \"i\", \"was\", \"walking\", \"round\", \"town\", \"with\", \"this\", \"girl\", \"i\", \"knew\", \"\\n\", \"when\", \"a\", \"man\", \"came\"],\n",
    "[\"fire\", \"and\", \"flames\", \"\\n\", \"passing\", \"tongues\", \"once\", \"bright\", \"with\", \"life\", \"\\n\", \"this\", \"is\", \"the\", \"world\", \"as\"],\n",
    "[\"on\", \"god\", \"i\", \"love\", \"the\", \"women\", \"\\n\", \"on\", \"god\", \"i\", \"love\", \"the\", \"blow\", \"\\n\", \"on\", \"god\"],\n",
    "[\"i\", \"can\", \"take\", \"you\", \"to\", \"the\", \"west\", \"coast\", \"best\", \"coast\", \"with\", \"a\", \"piece\", \"of\", \"toast\", \"yeah\"],\n",
    "[\"the\", \"stars\", \"were\", \"golden\", \"\\n\", \"the\", \"sky\", \"was\", \"dark\", \"\\n\", \"it\", \"was\", \"just\", \"you\", \"and\", \"me\"],\n",
    "[\"please\", \"baby\", \"please\", \"\\n\", \"please\", \"baby\", \"please\", \"\\n\", \"the\", \"things\", \"you\", \"do\", \"to\", \"me\", \"\\n\", \"you\"],\n",
    "[\"sweet\", \"adam\", \"\\n\", \"your\", \"tender\", \"touch\", \"\\n\", \"all\", \"i\", \"need\", \"when\", \"the\", \"weather\", \"gets\", \"cold\", \"\\n\"],\n",
    "[\"hello\", \"there\", \"\\n\", \"the\", \"toy\", \"from\", \"my\", \"nightmare\", \"\\n\", \"the\", \"figure\", \"in\", \"front\", \"of\", \"me\", \"\\n\"],\n",
    "[\"i\", \"like\", \"to\", \"spit\", \"\\n\", \"in\", \"the\", \"morning\", \"when\", \"i’m\", \"done\", \"taking\", \"my\", \"shit\", \"\\n\", \"i\"]]\n",
    "\n",
    "seq_length = 16\n",
    "char_to_int = rap_char_to_int\n",
    "int_to_char = rap_int_to_char\n",
    "\n",
    "def generate_sentence(input_sentences): \n",
    "    starter = [] \n",
    "    generation = [] \n",
    "    \n",
    "    for i in range(len(input_sentences)): \n",
    "        print(\"In sentence: \", i)\n",
    "        variance = .5\n",
    "        generated = []\n",
    "        original = input_sentences[i]\n",
    "        window = input_sentences[i]\n",
    "\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, seq_length))\n",
    "            for t, char in enumerate(window):\n",
    "                x[0, t] = char_to_int[char] # Change the sentence to index vector shape (1,50)\n",
    "\n",
    "            x_in = Variable(torch.LongTensor(x).to(device))\n",
    "            pred = country_model(x_in)\n",
    "            pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
    "            next_index = sample(pred, variance)\n",
    "            next_char = int_to_char[next_index] # index to char\n",
    "\n",
    "            generated = generated + [next_char]\n",
    "            window = window[1:] + [next_char] # Update Window for next char predict\n",
    "        \n",
    "        starter.append(original) \n",
    "        generation.append(generated)\n",
    "\n",
    "    lyrics = pd.DataFrame({'starter': starter, 'output': generation})\n",
    "    print(lyrics.head())\n",
    "    return lyrics \n",
    "output = generate_sentence(starters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.852499999999999\n",
      "0.3597756705308712\n",
      "0.34017595307917886\n",
      "17.65\n",
      "2.35\n"
     ]
    }
   ],
   "source": [
    "# METRIC 1: AVERAGE LINE LENGTH \n",
    "import math\n",
    "def mean(numbers):\n",
    "    return float(sum(numbers)) / max(len(numbers), 1)\n",
    "def single_length_length(output): \n",
    "    newline_count = output.count('\\n')\n",
    "    return round((len(output) - newline_count) / (newline_count + 1), 2)\n",
    "def average_line_length(df): \n",
    "    # (length of the list - # of new lines) / (# new lines + 1 )\n",
    "    result = df['output'].apply(single_length_length).tolist()\n",
    "    return mean(result)\n",
    "\n",
    "# METRIC 2: Word variation: # of Unique words divided by total # of words \n",
    "def variation(output): \n",
    "    line = [value for value in output if value != \"\\n\"]\n",
    "    unique_num = len(list(set(line)))\n",
    "    return unique_num/len(line)\n",
    "def word_variation(df): \n",
    "    result = df['output'].apply(variation).tolist()\n",
    "    return mean(result)\n",
    "\n",
    "# METRIC 3: Genre Word Variation \n",
    "def genre_word_variation(df): \n",
    "    output_list = df['output'].tolist()\n",
    "    return variation(output_list[0])\n",
    "\n",
    "# METRIC 4: % of I vs. You \n",
    "def count_iyou(row): \n",
    "    i_count, you_count = 0,0 \n",
    "    x = 0\n",
    "    while x < len(row):\n",
    "        if x == 0 and row[x] == \"you\": \n",
    "            you_count += 1\n",
    "        if x == 0 and row[x] == \"i\":\n",
    "            i_count += 1 \n",
    "        if x < len(row) - 1: \n",
    "            if row[x] == \"\\n\" and row[x + 1] == \"i\": \n",
    "                i_count += 1 \n",
    "            if row[x] == \"\\n\" and row[x + 1] == \"you\": \n",
    "                you_count += 1\n",
    "        x += 1 \n",
    "\n",
    "    return (i_count - you_count)\n",
    "\n",
    "def i_you(df): \n",
    "    result = df['output'].apply(count_iyou).to_list()\n",
    "    return mean(result)\n",
    "# the more positive, the more i's there are. \n",
    "\n",
    "# METRIC 5: Word reptition \n",
    "# if the word is the same as the one that came before it \n",
    "def count_s(row): \n",
    "    count, x = 0, 0\n",
    "    while x < len(row): \n",
    "        if x < len(row) - 1: \n",
    "            if row[x] == row[x+1]: \n",
    "                count += 1 \n",
    "        x += 1 \n",
    "    return count \n",
    "def count_succession(df): \n",
    "    result = df['output'].apply(count_s).to_list()\n",
    "    return mean(result)\n",
    "\n",
    "# METRIC 1: AVERAGE LINE LENGTH \n",
    "print(average_line_length(output))\n",
    "# METRIC 2: Word variation: # of Unique words divided by total # of words \n",
    "print(word_variation(output))\n",
    "# METRIC 3: Genre Word Variation \n",
    "print(genre_word_variation(output))\n",
    "# METRIC 4: % of I vs. You \n",
    "print(i_you(output))\n",
    "# METRIC 5: Word repetition \n",
    "print(count_succession(output)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.154649999999982\n",
      "0.48793800070489546\n",
      "0.4604651162790698\n",
      "1.5715\n",
      "1.543\n"
     ]
    }
   ],
   "source": [
    "def sample_data(genre, sample_size):\n",
    "    random.seed(69)\n",
    "    data1 = data\n",
    "    data1 = data1[data1['genre'] == genre].sample(sample_size)\n",
    "    data1['lyrics'] = data1['lyrics'].astype(str)\n",
    "    data1['lyrics']= data1['lyrics'].apply(preprocessText)\n",
    "    return data1\n",
    "\n",
    "def tokenize_data(data):\n",
    "    newlines = re.sub(\"\\n\", \" \\n \", data.lower())\n",
    "    exclamation = re.sub(\"!\", \" ! \", newlines)\n",
    "    question = re.sub(\"!\", \" ! \", exclamation)\n",
    "    DP_text = re.findall(r'\\S+|\\n', question)\n",
    "    return(DP_text)\n",
    "\n",
    "r_data = sample_data('Country', 2000)\n",
    "r_data['output'] = r_data['lyrics'].apply(tokenize_data)\n",
    "\n",
    "# METRIC 1: AVERAGE LINE LENGTH \n",
    "print(average_line_length(r_data))\n",
    "# METRIC 2: Word variation: # of Unique words divided by total # of words \n",
    "print(word_variation(r_data))\n",
    "# METRIC 3: Genre Word Variation \n",
    "print(genre_word_variation(r_data))\n",
    "# METRIC 4: % of I vs. You \n",
    "print(i_you(r_data))\n",
    "# METRIC 5: Word repetition \n",
    "print(count_succession(r_data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
